{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78f5522e",
   "metadata": {},
   "source": [
    "# Chap8の前半で学ぶこと\n",
    "* 多くの問題では、ネットワークを深くすることで、性能の向上が期待できる。\n",
    "* ILSVRCと呼ばれる画像認識のコンペティションの最近の動向は、ディープラーニングによる手法が上位を独占し、使われるネットワークもディープ化している。\n",
    "* 有名なネットワークには、VGG、GoogLeNet、ResNetがある。\n",
    "* GPUや分散学習、ビット精度の削減などによってディープラーニングの高速化を実現できる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7568c80e",
   "metadata": {},
   "source": [
    "# よりディープなネットワークの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a060e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from common.layers import *\n",
    "\n",
    "\n",
    "class DeepConvNet:\n",
    "    \"\"\"認識率99%以上の高精度なConvNet\n",
    "\n",
    "    ネットワーク構成は下記の通り\n",
    "        conv - relu - conv- relu - pool -\n",
    "        conv - relu - conv- relu - pool -\n",
    "        conv - relu - conv- relu - pool -\n",
    "        affine - relu - dropout - affine - dropout - softmax\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=(1, 28, 28),\n",
    "                 conv_param_1 = {'filter_num':16, 'filter_size':3, 'pad':1, 'stride':1}, #チャンネル数は16\n",
    "                 conv_param_2 = {'filter_num':16, 'filter_size':3, 'pad':1, 'stride':1}, #チャンネル数は16\n",
    "                 conv_param_3 = {'filter_num':32, 'filter_size':3, 'pad':1, 'stride':1}, #チャンネル数は32\n",
    "                 conv_param_4 = {'filter_num':32, 'filter_size':3, 'pad':2, 'stride':1}, #チャンネル数は32\n",
    "                 conv_param_5 = {'filter_num':64, 'filter_size':3, 'pad':1, 'stride':1}, #チャンネル数は64\n",
    "                 conv_param_6 = {'filter_num':64, 'filter_size':3, 'pad':1, 'stride':1}, #チャンネル数は64\n",
    "                 hidden_size=50, output_size=10): #隠れ層のニューロン数：50、出力層のニューロン数：10\n",
    "        # 重みの初期化===========\n",
    "        # 各層のニューロンひとつあたりが、前層のニューロンといくつのつながりがあるか（TODO:自動で計算する）\n",
    "        pre_node_nums = np.array([1*3*3, 16*3*3, 16*3*3, 32*3*3, 32*3*3, 64*3*3, 64*4*4, hidden_size])\n",
    "        weight_init_scales = np.sqrt(2.0 / pre_node_nums)  # ReLUを使う場合に推奨される初期値\n",
    "        \n",
    "        self.params = {}\n",
    "        pre_channel_num = input_dim[0]\n",
    "        for idx, conv_param in enumerate([conv_param_1, conv_param_2, conv_param_3, conv_param_4, conv_param_5, conv_param_6]):\n",
    "            self.params['W' + str(idx+1)] = weight_init_scales[idx] * np.random.randn(conv_param['filter_num'], pre_channel_num, conv_param['filter_size'], conv_param['filter_size'])\n",
    "            self.params['b' + str(idx+1)] = np.zeros(conv_param['filter_num'])\n",
    "            pre_channel_num = conv_param['filter_num']\n",
    "        self.params['W7'] = weight_init_scales[6] * np.random.randn(64*4*4, hidden_size)\n",
    "        self.params['b7'] = np.zeros(hidden_size)\n",
    "        self.params['W8'] = weight_init_scales[7] * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b8'] = np.zeros(output_size)\n",
    "\n",
    "        # レイヤの生成===========\n",
    "        '''\n",
    "        * self.layersリストにレイヤーを追加する順番がそのままネットワークの構造になる\n",
    "        * predictメソッドでfor layer in self.layers:として順番に処理される\n",
    "        * 最後のSoftmax層だけはself.last_layerとして別に管理されている\n",
    "        '''\n",
    "        self.layers = []\n",
    "        self.layers.append(Convolution(self.params['W1'], self.params['b1'], \n",
    "                           conv_param_1['stride'], conv_param_1['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Convolution(self.params['W2'], self.params['b2'], \n",
    "                           conv_param_2['stride'], conv_param_2['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))\n",
    "\n",
    "        self.layers.append(Convolution(self.params['W3'], self.params['b3'], \n",
    "                           conv_param_3['stride'], conv_param_3['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Convolution(self.params['W4'], self.params['b4'],\n",
    "                           conv_param_4['stride'], conv_param_4['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))\n",
    "\n",
    "        self.layers.append(Convolution(self.params['W5'], self.params['b5'],\n",
    "                           conv_param_5['stride'], conv_param_5['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Convolution(self.params['W6'], self.params['b6'],\n",
    "                           conv_param_6['stride'], conv_param_6['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))\n",
    "\n",
    "        self.layers.append(Affine(self.params['W7'], self.params['b7']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Dropout(0.5))\n",
    "        \n",
    "        self.layers.append(Affine(self.params['W8'], self.params['b8']))\n",
    "        self.layers.append(Dropout(0.5))\n",
    "        \n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x, train_flg=False):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, Dropout):\n",
    "                x = layer.forward(x, train_flg)\n",
    "            else:\n",
    "                x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x, train_flg=True)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "\n",
    "        acc = 0.0\n",
    "\n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx, train_flg=False)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt)\n",
    "\n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        tmp_layers = self.layers.copy()\n",
    "        tmp_layers.reverse()\n",
    "        for layer in tmp_layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 設定\n",
    "        grads = {}\n",
    "        for i, layer_idx in enumerate((0, 2, 5, 7, 10, 12, 15, 18)):\n",
    "            grads['W' + str(i+1)] = self.layers[layer_idx].dW\n",
    "            grads['b' + str(i+1)] = self.layers[layer_idx].db\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def save_params(self, file_name=\"params.pkl\"):\n",
    "        params = {}\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "\n",
    "    def load_params(self, file_name=\"params.pkl\"):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "\n",
    "        for i, layer_idx in enumerate((0, 2, 5, 7, 10, 12, 15, 18)):\n",
    "            self.layers[layer_idx].W = self.params['W' + str(i+1)]\n",
    "            self.layers[layer_idx].b = self.params['b' + str(i+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cb87a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.2702400210195477\n",
      "=== epoch:1, train acc:0.099, test acc:0.104 ===\n",
      "train loss:2.2869748415832554\n",
      "train loss:2.325626686413584\n",
      "train loss:2.2026127812034084\n",
      "train loss:2.256364573149047\n",
      "train loss:2.275997023896389\n",
      "train loss:2.2301847237225694\n",
      "train loss:2.2372891966559534\n",
      "train loss:2.1934879111798757\n",
      "train loss:2.0962439105031248\n",
      "train loss:2.212988383233301\n",
      "train loss:2.141151829984635\n",
      "train loss:2.0489500712176936\n",
      "train loss:2.030571861060726\n",
      "train loss:2.1333111916611673\n",
      "train loss:2.110424168824256\n",
      "train loss:2.088856063020338\n",
      "train loss:1.9823707897701064\n",
      "train loss:2.0514704656267515\n",
      "train loss:2.088269273512255\n",
      "train loss:2.0591503031056497\n",
      "train loss:2.146317684865091\n",
      "train loss:1.9398894179106885\n",
      "train loss:1.9713697024263832\n",
      "train loss:1.9079930215135203\n",
      "train loss:1.9472480966174432\n",
      "train loss:1.951958256637464\n",
      "train loss:1.723044226820951\n",
      "train loss:1.753785135346979\n",
      "train loss:1.8307913690217104\n",
      "train loss:1.914130315725152\n",
      "train loss:1.7913663253898335\n",
      "train loss:1.934362145143673\n",
      "train loss:1.7818328698843582\n",
      "train loss:1.819874543280519\n",
      "train loss:1.9616747888558421\n",
      "train loss:1.8319610513786355\n",
      "train loss:1.894851666365916\n",
      "train loss:1.7919291880747221\n",
      "train loss:1.8454284754269568\n",
      "train loss:1.7749527744754376\n",
      "train loss:1.6950221655621194\n",
      "train loss:1.8734728091678843\n",
      "train loss:1.8173956903672304\n",
      "train loss:1.9564550760885318\n",
      "train loss:1.7913723636685526\n",
      "train loss:1.8427731403098653\n",
      "train loss:1.726713212817657\n",
      "train loss:1.6432461208000744\n",
      "train loss:1.620179858451815\n",
      "train loss:1.7740321123294536\n",
      "train loss:1.6201874950521735\n",
      "train loss:1.7226494290263863\n",
      "train loss:1.840064941484397\n",
      "train loss:1.654226711640125\n",
      "train loss:1.8001730835558698\n",
      "train loss:1.7021285304687408\n",
      "train loss:1.707008685473964\n",
      "train loss:1.677410557469801\n",
      "train loss:1.7087822783332618\n",
      "train loss:1.6766849440748115\n",
      "train loss:1.5977817497612623\n",
      "train loss:1.692933082145713\n",
      "train loss:1.6890518245764463\n",
      "train loss:1.885688500280659\n",
      "train loss:1.8028999730989017\n",
      "train loss:1.8341096304750741\n",
      "train loss:1.6368966257712625\n",
      "train loss:1.8320848318269103\n",
      "train loss:1.6443461797504795\n",
      "train loss:1.7067712637453374\n",
      "train loss:1.725100164391979\n",
      "train loss:1.692482221206799\n",
      "train loss:1.5826511201780775\n",
      "train loss:1.6522833556414986\n",
      "train loss:1.7079566753404014\n",
      "train loss:1.52880511095614\n",
      "train loss:1.6330221659215636\n",
      "train loss:1.4261107184719588\n",
      "train loss:1.7244334257843508\n",
      "train loss:1.5864111073047718\n",
      "train loss:1.569709709500802\n",
      "train loss:1.5071568078739193\n",
      "train loss:1.5308416798058582\n",
      "train loss:1.7768399582345995\n",
      "train loss:1.5799657163769762\n",
      "train loss:1.6695488453599492\n",
      "train loss:1.511003776599397\n",
      "train loss:1.3358397848486345\n",
      "train loss:1.3607763573400755\n",
      "train loss:1.577096418159277\n",
      "train loss:1.4971090917900007\n",
      "train loss:1.4697368346879833\n",
      "train loss:1.5294332166845663\n",
      "train loss:1.4788173318383806\n",
      "train loss:1.5187732872666135\n",
      "train loss:1.386489144566454\n",
      "train loss:1.7874199028125108\n",
      "train loss:1.60367384965898\n",
      "train loss:1.6322491368426864\n",
      "train loss:1.5429965432570756\n",
      "train loss:1.5800500307240717\n",
      "train loss:1.445359312203551\n",
      "train loss:1.4663090690508471\n",
      "train loss:1.6417951451162256\n",
      "train loss:1.5611664186979934\n",
      "train loss:1.6031853600176365\n",
      "train loss:1.6937682937129106\n",
      "train loss:1.443855813970614\n",
      "train loss:1.5167721657069893\n",
      "train loss:1.6876418707618273\n",
      "train loss:1.5064308746678683\n",
      "train loss:1.3679638367694116\n",
      "train loss:1.4010527481874582\n",
      "train loss:1.5660954062221746\n",
      "train loss:1.4853182313435875\n",
      "train loss:1.4387697350092998\n",
      "train loss:1.4329065169790025\n",
      "train loss:1.4904485970362549\n",
      "train loss:1.4243301019674723\n",
      "train loss:1.250701008899089\n",
      "train loss:1.475161168102245\n",
      "train loss:1.5489383016985507\n",
      "train loss:1.361166259366987\n",
      "train loss:1.4541101457752403\n",
      "train loss:1.6039693713117111\n",
      "train loss:1.5754659712066326\n",
      "train loss:1.2326272336433908\n",
      "train loss:1.4582900833446137\n",
      "train loss:1.5357129224136086\n",
      "train loss:1.4155599655096558\n",
      "train loss:1.503973945792496\n",
      "train loss:1.591291363156149\n",
      "train loss:1.4077820856696228\n",
      "train loss:1.3811786129044479\n",
      "train loss:1.267973422527633\n",
      "train loss:1.5208027932267842\n",
      "train loss:1.5153037856518736\n",
      "train loss:1.2835363292543278\n",
      "train loss:1.4751734025452925\n",
      "train loss:1.4977579461064128\n",
      "train loss:1.474453765899844\n",
      "train loss:1.5602853393019012\n",
      "train loss:1.5616549117771592\n",
      "train loss:1.5091281780965324\n",
      "train loss:1.427740893336555\n",
      "train loss:1.314471309082424\n",
      "train loss:1.5270402444290172\n",
      "train loss:1.3476439663400956\n",
      "train loss:1.3961284944099466\n",
      "train loss:1.4155478806555915\n",
      "train loss:1.3676521314766519\n",
      "train loss:1.5859832307818513\n",
      "train loss:1.1879471936700097\n",
      "train loss:1.5764221388819248\n",
      "train loss:1.2903428912886228\n",
      "train loss:1.2776595788166674\n",
      "train loss:1.3388172345824898\n",
      "train loss:1.3021323408583525\n",
      "train loss:1.4228646174170771\n",
      "train loss:1.4038075860862798\n",
      "train loss:1.5442306320836507\n",
      "train loss:1.3697586551412224\n",
      "train loss:1.1349087244851217\n",
      "train loss:1.2774577039965866\n",
      "train loss:1.374064757765596\n",
      "train loss:1.4738580119460223\n",
      "train loss:1.2292133352203536\n",
      "train loss:1.3895517657994092\n",
      "train loss:1.515323409705592\n",
      "train loss:1.4578070905422718\n",
      "train loss:1.4589092617009363\n",
      "train loss:1.4093091190305964\n",
      "train loss:1.2486709470656077\n",
      "train loss:1.3395006779635201\n",
      "train loss:1.2839683613192725\n",
      "train loss:1.3359741161857424\n",
      "train loss:1.4301545094445205\n",
      "train loss:1.468135568241735\n",
      "train loss:1.2404081330079166\n",
      "train loss:1.307166904370563\n",
      "train loss:1.5336604946629406\n",
      "train loss:1.4122880484139873\n",
      "train loss:1.4164312411948985\n",
      "train loss:1.4533069448220868\n",
      "train loss:1.4055251826341646\n",
      "train loss:1.6268759876348824\n",
      "train loss:1.4194620458888016\n",
      "train loss:1.4630368763652344\n",
      "train loss:1.3526223326367428\n",
      "train loss:1.451685050862639\n",
      "train loss:1.3210126787782708\n",
      "train loss:1.355748709399458\n",
      "train loss:1.3903852153169485\n",
      "train loss:1.3215546057443723\n",
      "train loss:1.2813772928960443\n",
      "train loss:1.3446136753801377\n",
      "train loss:1.3026190495362646\n",
      "train loss:1.3623954499210993\n",
      "train loss:1.209971945431489\n",
      "train loss:1.2682167185323332\n",
      "train loss:1.1807234082557978\n",
      "train loss:1.3531722232799024\n",
      "train loss:1.2649472584483141\n",
      "train loss:1.1237095612641002\n",
      "train loss:1.2780044231578065\n",
      "train loss:1.4443525111069742\n",
      "train loss:1.3779704394758228\n",
      "train loss:1.1722295286575366\n",
      "train loss:1.134529320068027\n",
      "train loss:1.419422531457042\n",
      "train loss:1.4507293841511748\n",
      "train loss:1.356981351486607\n",
      "train loss:1.4122315107568404\n",
      "train loss:1.4173497292173942\n",
      "train loss:1.3892120894986626\n",
      "train loss:1.3486092469024757\n",
      "train loss:1.2278123883470824\n",
      "train loss:1.543564834545721\n",
      "train loss:1.3781480371296126\n",
      "train loss:1.3206384346769797\n",
      "train loss:1.52908405660597\n",
      "train loss:1.147341133286476\n",
      "train loss:1.1489126720628233\n",
      "train loss:1.425940110804253\n",
      "train loss:1.3557408994674214\n",
      "train loss:1.490575361448081\n",
      "train loss:1.1357713850723612\n",
      "train loss:1.3129458373723608\n",
      "train loss:1.2615070926300342\n",
      "train loss:1.3487520345754953\n",
      "train loss:1.157133786726563\n",
      "train loss:1.123541242505739\n",
      "train loss:1.1667812882631798\n",
      "train loss:1.2351880129190926\n",
      "train loss:1.4189570444905002\n",
      "train loss:1.1392696951913572\n",
      "train loss:1.2560675423931693\n",
      "train loss:1.2784747565546708\n",
      "train loss:1.3339265416076755\n",
      "train loss:1.2570226331926744\n",
      "train loss:1.0378606011639577\n",
      "train loss:1.2934164863300521\n",
      "train loss:1.2481491334543804\n",
      "train loss:1.235299698722156\n",
      "train loss:1.1387065877875016\n",
      "train loss:1.3445031932961382\n",
      "train loss:1.1598544374545818\n",
      "train loss:1.1524230459766232\n",
      "train loss:1.202969876286901\n",
      "train loss:1.0832536598665947\n",
      "train loss:1.351417097984772\n",
      "train loss:1.264582720937705\n",
      "train loss:1.2126382179419206\n",
      "train loss:1.0456744289190012\n",
      "train loss:1.413540397528987\n",
      "train loss:1.2866055183205674\n",
      "train loss:1.0184559564241384\n",
      "train loss:1.2446112866396326\n",
      "train loss:1.275085204416838\n",
      "train loss:1.2892515882257851\n",
      "train loss:1.1642617286526586\n",
      "train loss:1.2108059396333564\n",
      "train loss:1.339674704387174\n",
      "train loss:1.2504424375523018\n",
      "train loss:1.112480779515276\n",
      "train loss:1.1794597760870489\n",
      "train loss:1.2655959976275946\n",
      "train loss:1.2994202596032622\n",
      "train loss:1.249558705251819\n",
      "train loss:1.196684559473827\n",
      "train loss:1.4833178272219165\n",
      "train loss:1.246917203436454\n",
      "train loss:1.167866884472787\n",
      "train loss:1.1635887605283086\n",
      "train loss:1.1440027898235896\n",
      "train loss:1.2727802856651917\n",
      "train loss:1.114261218941735\n",
      "train loss:1.0651992343035648\n",
      "train loss:1.2466253666177969\n",
      "train loss:1.0582808779408823\n",
      "train loss:1.2799518955785556\n",
      "train loss:1.140702927843734\n",
      "train loss:1.202454113215192\n",
      "train loss:1.4087390554420194\n",
      "train loss:1.2115787669891402\n",
      "train loss:1.2021781674980077\n",
      "train loss:1.0139988829367135\n",
      "train loss:1.2047220078624827\n",
      "train loss:1.1962115893041938\n",
      "train loss:1.2520475723954272\n",
      "train loss:1.2501698277200393\n",
      "train loss:1.4884204387454514\n",
      "train loss:1.2373645053116709\n",
      "train loss:1.2307510958288739\n",
      "train loss:1.2750318611229674\n",
      "train loss:1.409020868216678\n",
      "train loss:1.3130740979062328\n",
      "train loss:1.1617727412361862\n",
      "train loss:1.1480691805329946\n",
      "train loss:1.0777239906283562\n",
      "train loss:1.2764080894878798\n",
      "train loss:1.0721153094346143\n",
      "train loss:1.088491820198822\n",
      "train loss:1.228099667433877\n",
      "train loss:1.3297381838214233\n",
      "train loss:1.2075686698287216\n",
      "train loss:1.1738116808494867\n",
      "train loss:1.3189849540401029\n",
      "train loss:1.356207289757086\n",
      "train loss:1.393519632335414\n",
      "train loss:1.2730106400522978\n",
      "train loss:1.1313971513617924\n",
      "train loss:1.2969964499337059\n",
      "train loss:1.1829525165730912\n",
      "train loss:1.109285700096296\n",
      "train loss:1.214456707644746\n",
      "train loss:1.113432434538029\n",
      "train loss:1.0529155940310282\n",
      "train loss:1.0984478547146557\n",
      "train loss:1.2238054659975146\n",
      "train loss:1.1186363686303158\n",
      "train loss:1.1528839025030588\n",
      "train loss:1.1905063992999834\n",
      "train loss:1.107922950691115\n",
      "train loss:1.277963503029925\n",
      "train loss:0.9782572831482476\n",
      "train loss:1.3232207151889788\n",
      "train loss:1.2007064105485932\n",
      "train loss:1.0739387547764594\n",
      "train loss:1.4978641546127576\n",
      "train loss:1.25166182647973\n",
      "train loss:0.9711627726844257\n",
      "train loss:1.141363761963995\n",
      "train loss:1.2600202228952917\n",
      "train loss:1.176609605777231\n",
      "train loss:1.1205595410312137\n",
      "train loss:1.196494617082171\n",
      "train loss:1.162998827981099\n",
      "train loss:1.2197989946126826\n",
      "train loss:1.0349073096600236\n",
      "train loss:1.2194389137208839\n",
      "train loss:1.2612487276507738\n",
      "train loss:1.3077792871789513\n",
      "train loss:1.210352186371254\n",
      "train loss:1.0887991635078504\n",
      "train loss:1.1316316952494418\n",
      "train loss:1.1378879300880163\n",
      "train loss:0.9373126039795103\n",
      "train loss:1.204280181282153\n",
      "train loss:1.3172624288398749\n",
      "train loss:1.1293305901533104\n",
      "train loss:1.2103094801756702\n",
      "train loss:1.2254754622478292\n",
      "train loss:1.0800231562534017\n",
      "train loss:1.15080284527575\n",
      "train loss:1.1432030120809225\n",
      "train loss:1.220651256474579\n",
      "train loss:1.23695900402104\n",
      "train loss:1.4813178173990575\n",
      "train loss:1.1933307189614932\n",
      "train loss:1.0868157516777341\n",
      "train loss:1.0792269631028244\n",
      "train loss:1.20777281229632\n",
      "train loss:1.0663976671559374\n",
      "train loss:1.2509672928816062\n",
      "train loss:1.2695086234822575\n",
      "train loss:1.2499173952194134\n",
      "train loss:1.0583317848418874\n",
      "train loss:1.042487375763253\n",
      "train loss:1.1589616271010488\n",
      "train loss:1.1804794387596893\n",
      "train loss:1.1663401028841884\n",
      "train loss:1.101121829266111\n",
      "train loss:1.3399101762318544\n",
      "train loss:1.1202772290441174\n",
      "train loss:1.288767046084523\n",
      "train loss:1.2358650716465864\n",
      "train loss:0.9917649682158358\n",
      "train loss:1.1841501102757868\n",
      "train loss:1.275525547104204\n",
      "train loss:1.2077254818977785\n",
      "train loss:1.235878230625943\n",
      "train loss:1.1685979739166261\n",
      "train loss:1.2253128991366062\n",
      "train loss:1.0808700150066894\n",
      "train loss:1.1136102069767846\n",
      "train loss:1.3916001442649952\n",
      "train loss:1.1651051336197282\n",
      "train loss:1.0844699495963162\n",
      "train loss:1.1947395872604831\n",
      "train loss:1.2579391974534064\n",
      "train loss:1.157804716735082\n",
      "train loss:1.26492668999135\n",
      "train loss:1.2941747029636121\n",
      "train loss:1.0924490651219716\n",
      "train loss:1.0663369455462093\n",
      "train loss:1.1598675457225418\n",
      "train loss:1.0609538098246047\n",
      "train loss:0.9618832761476677\n",
      "train loss:1.1464334492947115\n",
      "train loss:1.0321946141703389\n",
      "train loss:1.0156703125911362\n",
      "train loss:1.2789263744406902\n",
      "train loss:0.9543074881561524\n",
      "train loss:1.2595181527389276\n",
      "train loss:1.2387367989510534\n",
      "train loss:1.188818496378985\n",
      "train loss:1.1642451319564706\n",
      "train loss:1.181204243642288\n",
      "train loss:1.1035497175487932\n",
      "train loss:1.1491948085926256\n",
      "train loss:1.0744005193494874\n",
      "train loss:1.3137177868135512\n",
      "train loss:1.219263289069094\n",
      "train loss:1.1556497668143861\n",
      "train loss:0.9509626488276846\n",
      "train loss:1.2197773363836346\n",
      "train loss:1.0761322171610537\n",
      "train loss:1.0486332013537898\n",
      "train loss:1.1273873035655337\n",
      "train loss:1.1144149046998386\n",
      "train loss:1.1623459591932483\n",
      "train loss:1.122747192224239\n",
      "train loss:1.1028663674523356\n",
      "train loss:1.247720277288169\n",
      "train loss:1.2345337875187987\n",
      "train loss:1.0746038806269\n",
      "train loss:1.1718812218178032\n",
      "train loss:1.0473389263752966\n",
      "train loss:0.9801945984177891\n",
      "train loss:1.1170230546866875\n",
      "train loss:0.9809873959200914\n",
      "train loss:1.0989751262347967\n",
      "train loss:1.247608263119061\n",
      "train loss:1.148381159177363\n",
      "train loss:1.1650105431744842\n",
      "train loss:1.1174395094545597\n",
      "train loss:1.206111683170927\n",
      "train loss:1.2324658250578353\n",
      "train loss:1.2443993554972312\n",
      "train loss:1.167887402684352\n",
      "train loss:1.172786210786383\n",
      "train loss:1.2082859125605168\n",
      "train loss:1.2360122598667203\n",
      "train loss:1.1509087863927545\n",
      "train loss:1.035306163235951\n",
      "train loss:1.0019518479711063\n",
      "train loss:1.1300330173803894\n",
      "train loss:1.1295941071174604\n",
      "train loss:0.9652136341696843\n",
      "train loss:1.2892771996943873\n",
      "train loss:0.9177837083194328\n",
      "train loss:1.229378469767645\n",
      "train loss:1.0950313971908583\n",
      "train loss:1.0274503180341474\n",
      "train loss:1.0990598641564489\n",
      "train loss:0.9269733284804224\n",
      "train loss:1.1345484002971362\n",
      "train loss:1.1745954994623495\n",
      "train loss:1.132862368023784\n",
      "train loss:1.1713427525251152\n",
      "train loss:1.2655527967075852\n",
      "train loss:1.2017443823184975\n",
      "train loss:1.2906001866948826\n",
      "train loss:1.1604519255400716\n",
      "train loss:1.2609156327878497\n",
      "train loss:1.0785867000991305\n",
      "train loss:1.3463986402758514\n",
      "train loss:1.1310256188124939\n",
      "train loss:1.0917287260767081\n",
      "train loss:1.1460411187605783\n",
      "train loss:1.2592182198284578\n",
      "train loss:0.9894245634809212\n",
      "train loss:1.179520046283159\n",
      "train loss:1.0367890469188663\n",
      "train loss:1.2116650894793393\n",
      "train loss:1.0413867153573089\n",
      "train loss:1.2206129429574997\n",
      "train loss:1.091115404533568\n",
      "train loss:1.2134221058245693\n",
      "train loss:1.0854859855793442\n",
      "train loss:1.0127467949697424\n",
      "train loss:1.2230846853701427\n",
      "train loss:1.2493838783060895\n",
      "train loss:1.0571586237613602\n",
      "train loss:1.264672496119119\n",
      "train loss:1.0953035474774593\n",
      "train loss:1.0895405513977867\n",
      "train loss:1.1204647864317754\n",
      "train loss:1.057275977219675\n",
      "train loss:1.0141620825536939\n",
      "train loss:1.0555886374981673\n",
      "train loss:1.1997272898163054\n",
      "train loss:1.1113361296766697\n",
      "train loss:1.0135684152796367\n",
      "train loss:1.0860860629314928\n",
      "train loss:1.212538679864685\n",
      "train loss:1.0101951092111898\n",
      "train loss:0.974964086754538\n",
      "train loss:1.2176296724985125\n",
      "train loss:1.2339961578374945\n",
      "train loss:1.0424915443176668\n",
      "train loss:1.0561103291216176\n",
      "train loss:1.1791905524054511\n",
      "train loss:1.16990016944706\n",
      "train loss:1.0434134180455668\n",
      "train loss:1.1440675298953582\n",
      "train loss:1.1367814743960458\n",
      "train loss:1.0034288498293091\n",
      "train loss:1.0488271869437273\n",
      "train loss:0.9458954730127013\n",
      "train loss:1.139254657057001\n",
      "train loss:0.8946784325571419\n",
      "train loss:1.1067642934537723\n",
      "train loss:1.1358160783979134\n",
      "train loss:1.182329106825096\n",
      "train loss:1.2750612545659095\n",
      "train loss:1.1706400567279762\n",
      "train loss:0.9419582216563966\n",
      "train loss:1.154926791978495\n",
      "train loss:1.0353384181024752\n",
      "train loss:1.1636982885650626\n",
      "train loss:1.086763581217568\n",
      "train loss:1.094413384558524\n",
      "train loss:1.345987851742291\n",
      "train loss:1.065715629538097\n",
      "train loss:0.9053455647792964\n",
      "train loss:0.8824806607776519\n",
      "train loss:1.104112806113531\n",
      "train loss:1.156320297100336\n",
      "train loss:1.1581846434679053\n",
      "train loss:1.1856980011159417\n",
      "train loss:1.0495305443824905\n",
      "train loss:1.0069250287244982\n",
      "train loss:1.086918953980656\n",
      "train loss:1.1918611046610914\n",
      "train loss:1.0463443640935854\n",
      "train loss:0.982165995407337\n",
      "train loss:1.0829045416779208\n",
      "train loss:0.9917389471771169\n",
      "train loss:1.0803476252742634\n",
      "train loss:1.0238519929767131\n",
      "train loss:1.1176217275765767\n",
      "train loss:1.2061103270314846\n",
      "train loss:1.0778797468149128\n",
      "train loss:1.09221345756072\n",
      "train loss:1.0664181468594751\n",
      "train loss:0.8840998117001787\n",
      "train loss:0.9454152432964402\n",
      "train loss:1.1366297940736958\n",
      "train loss:1.0655702067525872\n",
      "train loss:1.0387721898958364\n",
      "train loss:1.0921689077567671\n",
      "train loss:1.3078993540840997\n",
      "train loss:1.0753206122181738\n",
      "train loss:1.1917844102733344\n",
      "train loss:1.2031813778126317\n",
      "train loss:1.0084633591483365\n",
      "train loss:1.1620825181239198\n",
      "train loss:1.0317355825310452\n",
      "train loss:0.9903679223979388\n",
      "train loss:1.1501059619437726\n",
      "train loss:0.9615050042252463\n",
      "train loss:1.1098537200256389\n",
      "train loss:0.9898962099281599\n",
      "train loss:1.0944506028201162\n",
      "train loss:1.1443739841039742\n",
      "train loss:1.1030085425864453\n",
      "train loss:0.9612706479268102\n",
      "train loss:0.9751112495928076\n",
      "train loss:1.1930848904325524\n",
      "train loss:1.012964377502097\n",
      "train loss:1.2446986589901927\n",
      "train loss:1.2503515632479327\n",
      "train loss:1.1353799267681364\n",
      "train loss:1.158580831609408\n",
      "train loss:1.1471125841685388\n",
      "train loss:1.1668594503842544\n",
      "train loss:1.0023316979387316\n",
      "train loss:0.9636809871329919\n",
      "train loss:1.177399193381124\n",
      "train loss:1.1292036515935633\n",
      "train loss:0.9914727767208302\n",
      "train loss:1.1654437846882826\n",
      "train loss:1.2516501526911967\n",
      "train loss:1.1113781780347336\n",
      "train loss:0.9967088926952888\n",
      "train loss:1.0606671427725824\n",
      "train loss:1.0235494103616967\n",
      "train loss:1.2257601781777954\n",
      "train loss:1.0582321265060441\n",
      "train loss:1.114699038645827\n",
      "train loss:1.20886875980783\n",
      "train loss:1.0467897655760614\n",
      "train loss:0.9563616133290226\n",
      "train loss:1.0030479568180812\n",
      "train loss:1.1529061665095601\n",
      "train loss:1.0625755256202556\n",
      "train loss:1.1127815332466575\n",
      "train loss:1.0482005944598636\n",
      "=== epoch:2, train acc:0.974, test acc:0.972 ===\n",
      "train loss:1.061593803942962\n",
      "train loss:0.9724078497366158\n",
      "train loss:1.0648903658954953\n",
      "train loss:1.041082111972007\n",
      "train loss:1.0494081599405487\n",
      "train loss:1.1130704815574461\n",
      "train loss:1.0640487254106312\n",
      "train loss:1.2299210263230622\n",
      "train loss:0.9403904675775813\n",
      "train loss:1.1075082190578587\n",
      "train loss:1.1458855090100561\n",
      "train loss:1.2369185012801729\n",
      "train loss:1.142486313263244\n",
      "train loss:1.1413340553189533\n",
      "train loss:1.1706761221500512\n",
      "train loss:1.1781286977717842\n",
      "train loss:1.096320813758593\n",
      "train loss:1.343262295504785\n",
      "train loss:0.8335558447156042\n",
      "train loss:1.1581629989282696\n",
      "train loss:1.019973360680067\n",
      "train loss:1.1215438927392123\n",
      "train loss:1.0586262124339603\n",
      "train loss:1.1031380964129212\n",
      "train loss:0.9601092863323644\n",
      "train loss:1.066662317758519\n",
      "train loss:1.0215159490427583\n",
      "train loss:1.0101341706074407\n",
      "train loss:0.9880332116376068\n",
      "train loss:1.1207595785633873\n",
      "train loss:1.099310450400556\n",
      "train loss:1.0376438314323262\n",
      "train loss:1.1523844016582476\n",
      "train loss:0.8902493249912453\n",
      "train loss:1.1396876968767784\n",
      "train loss:0.9937018844463779\n",
      "train loss:1.0488585403510602\n",
      "train loss:0.9469632625316149\n",
      "train loss:1.1687570262885325\n",
      "train loss:0.9787831125462434\n",
      "train loss:1.0611344202502822\n",
      "train loss:1.0566285472935208\n",
      "train loss:1.03899434744428\n",
      "train loss:1.044432231516308\n",
      "train loss:1.1176731985699073\n",
      "train loss:1.0905529053172234\n",
      "train loss:1.0403031044640445\n",
      "train loss:1.073853575593802\n",
      "train loss:1.344450633421539\n",
      "train loss:1.2055944912206786\n",
      "train loss:1.009823529964189\n",
      "train loss:1.1430516962413602\n",
      "train loss:1.3021423687649867\n",
      "train loss:1.1917171969660385\n",
      "train loss:1.0807012176674229\n",
      "train loss:0.9305516348179633\n",
      "train loss:1.1710437167411423\n",
      "train loss:1.2347466229701933\n",
      "train loss:0.9542679178249568\n",
      "train loss:1.2337245840574405\n",
      "train loss:0.9944524648477825\n",
      "train loss:1.0476305001807353\n",
      "train loss:1.1327292061028065\n",
      "train loss:1.098518998803818\n",
      "train loss:1.0076753937797407\n",
      "train loss:1.236455268568156\n",
      "train loss:1.2923642962962916\n",
      "train loss:1.2464009588627065\n",
      "train loss:1.2811774875834359\n",
      "train loss:1.0709051595116084\n",
      "train loss:0.9605676235441756\n",
      "train loss:1.0886812234894174\n",
      "train loss:1.179724466119712\n",
      "train loss:0.8613006245502729\n",
      "train loss:0.870387517597728\n",
      "train loss:1.0242764808613851\n",
      "train loss:0.9210444472667195\n",
      "train loss:0.9548126850141159\n",
      "train loss:1.0930144082360242\n",
      "train loss:0.8814633366582462\n",
      "train loss:1.1647668435980973\n",
      "train loss:1.0014124865346092\n",
      "train loss:1.1907231593199186\n",
      "train loss:1.0305721022684666\n",
      "train loss:0.9849257451845373\n",
      "train loss:0.9566640616368092\n",
      "train loss:0.905287275527768\n",
      "train loss:0.9727983545958537\n",
      "train loss:1.0802576580784737\n",
      "train loss:1.3413944681410697\n",
      "train loss:0.9510575214639282\n",
      "train loss:0.9609988865670307\n",
      "train loss:1.2624155556741496\n",
      "train loss:1.0294132335543933\n",
      "train loss:1.145890568119955\n",
      "train loss:1.1018202605368785\n",
      "train loss:1.1343636402718553\n",
      "train loss:1.0367934776580312\n",
      "train loss:1.108471074232936\n",
      "train loss:1.0227336716987248\n",
      "train loss:1.0104283304942414\n",
      "train loss:1.0301601409634795\n",
      "train loss:1.0360943510944514\n",
      "train loss:1.1271226301608492\n",
      "train loss:1.0036391759486454\n",
      "train loss:1.1415439613458984\n",
      "train loss:1.151329427968522\n",
      "train loss:0.9953340752799247\n",
      "train loss:1.0416975102339174\n",
      "train loss:1.004617420778227\n",
      "train loss:1.0288343204171952\n",
      "train loss:1.1149794914484321\n",
      "train loss:1.1931716012350004\n",
      "train loss:1.1244120351728613\n",
      "train loss:1.096838735191063\n",
      "train loss:1.0365750123298294\n",
      "train loss:0.9075284646818035\n",
      "train loss:1.0926950157731619\n",
      "train loss:1.2246128499938547\n",
      "train loss:1.1930499848206204\n",
      "train loss:1.06206790879196\n",
      "train loss:0.9380032231065669\n",
      "train loss:0.9993644574683722\n",
      "train loss:1.0294142404708981\n",
      "train loss:1.1984848784126516\n",
      "train loss:1.0563459917380953\n",
      "train loss:0.911620404288213\n",
      "train loss:0.893759270464422\n",
      "train loss:1.141761049195035\n",
      "train loss:0.9401956009000181\n",
      "train loss:1.1089900707555045\n",
      "train loss:1.060389080420772\n",
      "train loss:1.2888022830314538\n",
      "train loss:0.9272393713511121\n",
      "train loss:1.1887978831883987\n",
      "train loss:1.0367379158792573\n",
      "train loss:1.0101027319812612\n",
      "train loss:0.9549302645347731\n",
      "train loss:1.0967892877520535\n",
      "train loss:1.0085717760846151\n",
      "train loss:1.0671450692671751\n",
      "train loss:1.048406455410035\n",
      "train loss:1.0162327384200198\n",
      "train loss:1.0296862404808498\n",
      "train loss:0.9322667133134982\n",
      "train loss:0.9818799606337428\n",
      "train loss:0.9711726925905818\n",
      "train loss:1.0695985915986144\n",
      "train loss:1.0093384770341922\n",
      "train loss:0.9895574240529649\n",
      "train loss:1.0927301957338822\n",
      "train loss:1.0461527433881488\n",
      "train loss:1.065413186520049\n",
      "train loss:1.0569741943124458\n",
      "train loss:1.0202612482355877\n",
      "train loss:1.0384396559422728\n",
      "train loss:1.1746512589593001\n",
      "train loss:1.1811333192195577\n",
      "train loss:1.0967399918247864\n",
      "train loss:1.0994001985788364\n",
      "train loss:1.0616079093136448\n",
      "train loss:1.0950525780450742\n",
      "train loss:1.0234457466180928\n",
      "train loss:1.0368542893737496\n",
      "train loss:1.0830143898045528\n",
      "train loss:1.0627121046105603\n",
      "train loss:0.9475193514012815\n",
      "train loss:1.0972562668623047\n",
      "train loss:0.9960799694238764\n",
      "train loss:0.9872427377326897\n",
      "train loss:1.1676449251603354\n",
      "train loss:1.1145389675829\n",
      "train loss:1.0499709991120105\n",
      "train loss:0.9999919121385829\n",
      "train loss:0.9329969397043024\n",
      "train loss:1.0805986369398375\n",
      "train loss:0.9982706485636246\n",
      "train loss:1.0997279655458114\n",
      "train loss:1.163994744597552\n",
      "train loss:1.1404250110859846\n",
      "train loss:1.0675798468397029\n",
      "train loss:1.0696602538776623\n",
      "train loss:0.9882773692131189\n",
      "train loss:1.1234211566223538\n",
      "train loss:1.0682627475356696\n",
      "train loss:1.12341974964527\n",
      "train loss:0.9852254541860802\n",
      "train loss:1.0257394375246887\n",
      "train loss:1.0209296878131895\n",
      "train loss:0.9105631607775736\n",
      "train loss:1.0298622663378365\n",
      "train loss:1.1290750443007886\n",
      "train loss:1.0351779844906641\n",
      "train loss:1.1313885669451897\n",
      "train loss:0.9875050336911488\n",
      "train loss:1.1468891583520806\n",
      "train loss:1.0784920068703194\n",
      "train loss:1.078084158898162\n",
      "train loss:1.1390815145754312\n",
      "train loss:1.26500844498189\n",
      "train loss:0.9500293084600608\n",
      "train loss:1.0967864227708062\n",
      "train loss:1.223938766147527\n",
      "train loss:1.0594272172896826\n",
      "train loss:1.005510472309692\n",
      "train loss:0.9225635916070161\n",
      "train loss:0.8436199246875234\n",
      "train loss:1.075326111772242\n",
      "train loss:1.0996406412842263\n",
      "train loss:1.0692905943105253\n",
      "train loss:1.1842273387646653\n",
      "train loss:1.2200738421222332\n",
      "train loss:1.1086105468339225\n",
      "train loss:1.0573279266182807\n",
      "train loss:1.0530473667114513\n",
      "train loss:1.139273963517341\n",
      "train loss:0.8822509661859321\n",
      "train loss:1.0398835284636319\n",
      "train loss:0.9654948886434778\n",
      "train loss:1.1651919534459676\n",
      "train loss:1.204111301271715\n",
      "train loss:1.0507861532251495\n",
      "train loss:1.0433709271447098\n",
      "train loss:1.0227682498490842\n",
      "train loss:1.1239106406987158\n",
      "train loss:1.1505620556063412\n",
      "train loss:1.3248179898802648\n",
      "train loss:1.063656342313819\n",
      "train loss:0.9954351789562336\n",
      "train loss:0.9640698445855357\n",
      "train loss:1.0523108836994302\n",
      "train loss:0.9473543326402362\n",
      "train loss:1.037442688052\n",
      "train loss:1.1344549919209794\n",
      "train loss:1.1870399855500429\n",
      "train loss:1.0724153169733615\n",
      "train loss:0.9460903143933476\n",
      "train loss:1.0510982322653641\n",
      "train loss:1.115126390262093\n",
      "train loss:0.9975659017176881\n",
      "train loss:1.0113643179463785\n",
      "train loss:1.116529198948964\n",
      "train loss:0.924652258990842\n",
      "train loss:1.0523663117670727\n",
      "train loss:1.149344050471025\n",
      "train loss:1.078972796941167\n",
      "train loss:1.331080479914178\n",
      "train loss:0.9466063390106352\n",
      "train loss:1.0987100647488726\n",
      "train loss:1.0938113775790894\n",
      "train loss:1.0563832037074383\n",
      "train loss:1.0092676476884102\n",
      "train loss:1.0093842754773907\n",
      "train loss:1.0359181827064714\n",
      "train loss:0.9557115698375702\n",
      "train loss:1.223069907457795\n",
      "train loss:1.1352858846464655\n",
      "train loss:1.0047985633220682\n",
      "train loss:1.0837615483114993\n",
      "train loss:0.8105032008274303\n",
      "train loss:1.0091039488964402\n",
      "train loss:1.0149856384857872\n",
      "train loss:1.061329689461973\n",
      "train loss:0.9326197602160273\n",
      "train loss:1.0607383267203685\n",
      "train loss:1.09574156154034\n",
      "train loss:1.0500397970807385\n",
      "train loss:1.0521013956077154\n",
      "train loss:1.236217183267512\n",
      "train loss:0.9009776319086182\n",
      "train loss:1.0286826429802205\n",
      "train loss:0.9738760532160229\n",
      "train loss:0.9661919702186218\n",
      "train loss:0.9677200068856315\n",
      "train loss:0.9555389374969869\n",
      "train loss:1.001223706476794\n",
      "train loss:1.237081872945185\n",
      "train loss:1.1125501942130456\n",
      "train loss:1.1282782069550623\n",
      "train loss:0.979262078552647\n",
      "train loss:1.0207132601499156\n",
      "train loss:1.0015286053566543\n",
      "train loss:1.0436438472773522\n",
      "train loss:1.1476322978881381\n",
      "train loss:1.0529711159096617\n",
      "train loss:1.0369476788269352\n",
      "train loss:1.0125543963478914\n",
      "train loss:1.1342854881271094\n",
      "train loss:0.8303210566922351\n",
      "train loss:1.0484267091125388\n",
      "train loss:1.0885715133172198\n",
      "train loss:0.9033771983697655\n",
      "train loss:0.982987723377262\n",
      "train loss:1.1503832056134073\n",
      "train loss:1.1024719547195583\n",
      "train loss:1.1398292215009884\n",
      "train loss:1.1184737391503672\n",
      "train loss:1.081458690468007\n",
      "train loss:0.966566286971476\n",
      "train loss:1.0894575666274149\n",
      "train loss:1.0034649878757835\n",
      "train loss:0.9597867643380164\n",
      "train loss:0.8254921199859924\n",
      "train loss:0.9089736429032211\n",
      "train loss:0.9842189002139737\n",
      "train loss:1.0098755817829532\n",
      "train loss:0.8607624056983978\n",
      "train loss:1.0018849035376531\n",
      "train loss:1.1657557978767192\n",
      "train loss:0.998896639934615\n",
      "train loss:1.191234284381242\n",
      "train loss:0.9205136617074782\n",
      "train loss:0.9944729846942585\n",
      "train loss:0.858989967065954\n",
      "train loss:1.0921902258156337\n",
      "train loss:1.0459128610757904\n",
      "train loss:1.1811403047167983\n",
      "train loss:1.0277283413680431\n",
      "train loss:0.832774096259522\n",
      "train loss:0.9887073673299694\n",
      "train loss:0.9489841151590797\n",
      "train loss:1.0575311722016638\n",
      "train loss:1.194723252085093\n",
      "train loss:0.9124243559778045\n",
      "train loss:1.1181306160829614\n",
      "train loss:1.0218707922026546\n",
      "train loss:0.9976950974720498\n",
      "train loss:1.058273743888884\n",
      "train loss:0.9663235744714411\n",
      "train loss:1.013091070429925\n",
      "train loss:1.1199247672891393\n",
      "train loss:1.0993908310997431\n",
      "train loss:0.9847601932828374\n",
      "train loss:1.0315651104972963\n",
      "train loss:1.016674104781767\n",
      "train loss:0.8834016631778254\n",
      "train loss:0.9421315058104061\n",
      "train loss:1.1453414451907638\n",
      "train loss:1.041774601591597\n",
      "train loss:0.941563402308205\n",
      "train loss:0.8885474358006878\n",
      "train loss:1.013835244919523\n",
      "train loss:0.9113921255406947\n",
      "train loss:1.0594673324629533\n",
      "train loss:0.9801935001870842\n",
      "train loss:1.01522638083241\n",
      "train loss:0.9745121896735008\n",
      "train loss:0.9902189515128396\n",
      "train loss:1.0497096890215405\n",
      "train loss:1.1082729798935882\n",
      "train loss:0.9584665898824993\n",
      "train loss:1.0899684138625674\n",
      "train loss:0.9661518606214894\n",
      "train loss:1.0211271179302501\n",
      "train loss:1.0937367380495415\n",
      "train loss:1.1216379106472198\n",
      "train loss:1.22872195038515\n",
      "train loss:1.1504502272230317\n",
      "train loss:0.9378817518594164\n",
      "train loss:0.930426000553254\n",
      "train loss:0.8614910488140847\n",
      "train loss:1.0433666638225838\n",
      "train loss:1.0927044106963555\n",
      "train loss:1.1603037894006973\n",
      "train loss:1.006346294846503\n",
      "train loss:0.9608949824713494\n",
      "train loss:1.0169971644532614\n",
      "train loss:1.0983898802762428\n",
      "train loss:1.0308987065959048\n",
      "train loss:0.9595104391565137\n",
      "train loss:0.9963629073633657\n",
      "train loss:1.2237840761436773\n",
      "train loss:1.0036419485239716\n",
      "train loss:1.0097729863027312\n",
      "train loss:0.9722488189050783\n",
      "train loss:1.039646258110337\n",
      "train loss:0.9966807964082338\n",
      "train loss:0.9144618224303187\n",
      "train loss:1.1291399610381567\n",
      "train loss:0.9893654309842228\n",
      "train loss:1.0539983819349918\n",
      "train loss:0.9940324616114848\n",
      "train loss:0.8256429593941553\n",
      "train loss:1.073204825516926\n",
      "train loss:1.0713712504454052\n",
      "train loss:0.7909570325269771\n",
      "train loss:0.9213977654744129\n",
      "train loss:0.8961148499472109\n",
      "train loss:0.9849374186502456\n",
      "train loss:1.0538271720778394\n",
      "train loss:0.9380643507591866\n",
      "train loss:1.0003757195978513\n",
      "train loss:1.1321764939066035\n",
      "train loss:1.0483673061658345\n",
      "train loss:0.9060703769474401\n",
      "train loss:1.0712397753063398\n",
      "train loss:1.0288610394066837\n",
      "train loss:1.216676508630113\n",
      "train loss:0.8836671591779016\n",
      "train loss:1.0868992429323148\n",
      "train loss:1.0828244271016367\n",
      "train loss:0.9895821493820026\n",
      "train loss:1.0799614119827752\n",
      "train loss:0.925446025686616\n",
      "train loss:1.295459062410512\n",
      "train loss:0.9113656901783596\n",
      "train loss:1.0052952383987261\n",
      "train loss:1.1161052823346653\n",
      "train loss:1.1703020771077544\n",
      "train loss:0.9362075330426457\n",
      "train loss:0.7911906012086236\n",
      "train loss:1.0070510096659764\n",
      "train loss:0.9765880470090247\n",
      "train loss:0.9013959542969563\n",
      "train loss:0.8278963179389541\n",
      "train loss:0.9887171786132272\n",
      "train loss:0.8325706961791651\n",
      "train loss:0.9971402148681342\n",
      "train loss:0.9440066563410017\n",
      "train loss:1.1450104461012727\n",
      "train loss:0.9878908537745298\n",
      "train loss:1.0111546734051453\n",
      "train loss:0.9823912542855543\n",
      "train loss:1.0566195507497078\n",
      "train loss:1.0199255883341458\n",
      "train loss:0.9876439870338392\n",
      "train loss:0.9081251587934505\n",
      "train loss:1.212870268268648\n",
      "train loss:1.1364959290938843\n",
      "train loss:0.9746309565599935\n",
      "train loss:1.091762674532915\n",
      "train loss:1.0166076683854781\n",
      "train loss:1.084431581461095\n",
      "train loss:0.900374019417921\n",
      "train loss:0.9772258687694176\n",
      "train loss:1.1740789459898737\n",
      "train loss:1.0484599168396571\n",
      "train loss:0.8152697116048587\n",
      "train loss:1.01572803242297\n",
      "train loss:0.9725124582100237\n",
      "train loss:1.025102301583187\n",
      "train loss:1.0734719764707945\n",
      "train loss:1.0813537265623472\n",
      "train loss:1.0937111394550865\n",
      "train loss:0.9802902877375526\n",
      "train loss:0.9755041344872417\n",
      "train loss:0.8796972714348857\n",
      "train loss:1.0072952572450569\n",
      "train loss:1.1332610654625546\n",
      "train loss:1.1982540046930277\n",
      "train loss:1.0539886238595253\n",
      "train loss:0.9608232307919082\n",
      "train loss:0.9331586961563139\n",
      "train loss:1.0791360227643694\n",
      "train loss:0.952279082589315\n",
      "train loss:0.8874628798188448\n",
      "train loss:1.0969193332570362\n",
      "train loss:1.0709232799022481\n",
      "train loss:0.7457777225188807\n",
      "train loss:1.2014215937804011\n",
      "train loss:0.9416185956598967\n",
      "train loss:1.0982359622844071\n",
      "train loss:0.8154357607234796\n",
      "train loss:0.9027007512827215\n",
      "train loss:0.9138202874249767\n",
      "train loss:1.032257180375068\n",
      "train loss:1.0140522227626116\n",
      "train loss:0.9795626781557486\n",
      "train loss:1.2233745279030017\n",
      "train loss:0.8441022645860846\n",
      "train loss:1.0164822934637612\n",
      "train loss:1.117624200007496\n",
      "train loss:1.1009970798933428\n",
      "train loss:1.1675052700342006\n",
      "train loss:1.0315043598419558\n",
      "train loss:1.128883073704847\n",
      "train loss:0.9903417224008383\n",
      "train loss:1.1656962716059787\n",
      "train loss:0.9818013432826527\n",
      "train loss:0.9788703928625838\n",
      "train loss:1.0666218205548963\n",
      "train loss:1.2388847898889448\n",
      "train loss:0.8913758351105515\n",
      "train loss:1.0178206468526951\n",
      "train loss:0.8845234315206381\n",
      "train loss:0.9810483329329402\n",
      "train loss:0.9261671880896603\n",
      "train loss:1.0550938802174\n",
      "train loss:0.9340123278105794\n",
      "train loss:1.043561603041896\n",
      "train loss:0.909478695246582\n",
      "train loss:0.9464683787715658\n",
      "train loss:0.8339689179337918\n",
      "train loss:1.050415320564101\n",
      "train loss:0.9406341652125535\n",
      "train loss:0.949230730997491\n",
      "train loss:1.1021876853996997\n",
      "train loss:0.7747612520594965\n",
      "train loss:0.9528684439279747\n",
      "train loss:0.9902578588855993\n",
      "train loss:0.8254653295730434\n",
      "train loss:0.9838982161151958\n",
      "train loss:0.8313499406377531\n",
      "train loss:1.0377847486215173\n",
      "train loss:0.8331158782887791\n",
      "train loss:0.9013837361691417\n",
      "train loss:1.0897347453924013\n",
      "train loss:1.0506493596698963\n",
      "train loss:1.137359013466184\n",
      "train loss:0.8611751852071263\n",
      "train loss:1.0048769357892073\n",
      "train loss:0.8609526950401127\n",
      "train loss:0.7971162598698371\n",
      "train loss:0.918831642934198\n",
      "train loss:0.9983294799032615\n",
      "train loss:0.9149000445851557\n",
      "train loss:0.9142006880433446\n",
      "train loss:1.0853694051038474\n",
      "train loss:1.0892267632952524\n",
      "train loss:0.9048265714388443\n",
      "train loss:0.9725065764793324\n",
      "train loss:0.8765546625348348\n",
      "train loss:1.020277549164474\n",
      "train loss:0.9037363512908029\n",
      "train loss:0.9767624694597958\n",
      "train loss:1.1338773446348596\n",
      "train loss:1.085038787936696\n",
      "train loss:0.9519016933590286\n",
      "train loss:0.9358996617766665\n",
      "train loss:0.9763579624176285\n",
      "train loss:1.0047533556986643\n",
      "train loss:1.0990166721511423\n",
      "train loss:1.1044936034103359\n",
      "train loss:1.000606510665769\n",
      "train loss:1.1098895954032288\n",
      "train loss:0.8885971580139441\n",
      "train loss:0.9340464124886588\n",
      "train loss:0.8938452918162845\n",
      "train loss:0.8941265889117648\n",
      "train loss:1.1006206520819037\n",
      "train loss:0.9359512410097547\n",
      "train loss:1.013544121193446\n",
      "train loss:1.1441245006345095\n",
      "train loss:0.9643427125777968\n",
      "train loss:1.2081715709724914\n",
      "train loss:1.0711338250139868\n",
      "train loss:1.11758233251563\n",
      "train loss:1.0354284920311596\n",
      "train loss:1.0123486934653236\n",
      "train loss:0.950165094102808\n",
      "train loss:1.0273193191356493\n",
      "train loss:0.9611210390273096\n",
      "train loss:0.9025385391682099\n",
      "train loss:0.9742459673292443\n",
      "train loss:0.9166782232804398\n",
      "train loss:0.9484870843201604\n",
      "train loss:1.0056566887984792\n",
      "train loss:1.0956680659394482\n",
      "train loss:1.0151666154130092\n",
      "train loss:1.079802120312\n",
      "train loss:1.2249980537423086\n",
      "train loss:0.8863535371684788\n",
      "train loss:1.050447941395315\n",
      "train loss:1.0536493421445756\n",
      "train loss:1.0829210890210448\n",
      "train loss:1.123178862147825\n",
      "train loss:0.850988706934194\n",
      "train loss:0.8777750181460252\n",
      "train loss:0.9501995847572674\n",
      "train loss:1.0900460810383463\n",
      "train loss:0.9221569449166859\n",
      "train loss:1.0678009256834193\n",
      "train loss:1.010793233140636\n",
      "train loss:0.9800818684775231\n",
      "train loss:0.9902163269216975\n",
      "train loss:0.8926694344581273\n",
      "train loss:0.8576702367617276\n",
      "train loss:1.1745810398625598\n",
      "train loss:1.0563141252120063\n",
      "train loss:1.061271923268326\n",
      "train loss:1.1080764364346491\n",
      "train loss:0.9753727315873958\n",
      "train loss:0.925238434994887\n",
      "train loss:0.9561930612074566\n",
      "train loss:0.9365184149863991\n",
      "train loss:0.950697392296028\n",
      "train loss:0.9801507894968128\n",
      "train loss:0.930109038379682\n",
      "train loss:0.9546978408545812\n",
      "train loss:0.9244871456036623\n",
      "train loss:0.9874229664135297\n",
      "train loss:0.8718209901789901\n",
      "train loss:1.130130262006071\n",
      "train loss:0.8660042535524453\n",
      "train loss:0.9534718473015953\n",
      "train loss:0.9149091256057693\n",
      "train loss:0.9792475557555425\n",
      "train loss:0.9734480394350749\n",
      "train loss:0.9942637408612626\n",
      "train loss:1.001571714551948\n",
      "=== epoch:3, train acc:0.985, test acc:0.981 ===\n",
      "train loss:1.0975256915963236\n",
      "train loss:0.994444425081915\n",
      "train loss:0.8459080724660508\n",
      "train loss:0.836937890566503\n",
      "train loss:1.216756527352726\n",
      "train loss:0.9615848781498445\n",
      "train loss:0.8487097093876886\n",
      "train loss:1.0612922224445034\n",
      "train loss:0.9779261409377904\n",
      "train loss:1.015706810969857\n",
      "train loss:1.0705810775980023\n",
      "train loss:0.8823033404761101\n",
      "train loss:1.0667194205421486\n",
      "train loss:1.072436407289719\n",
      "train loss:0.9080313948261143\n",
      "train loss:1.1189464471986035\n",
      "train loss:0.8419406242652563\n",
      "train loss:1.0314497431374618\n",
      "train loss:0.9337016312003338\n",
      "train loss:0.9910527410723029\n",
      "train loss:0.857380473653503\n",
      "train loss:0.9062460794104369\n",
      "train loss:0.9164608330677766\n",
      "train loss:1.0346213369756803\n",
      "train loss:1.0548921322576912\n",
      "train loss:1.1373857430502752\n",
      "train loss:0.8315606439626128\n",
      "train loss:0.8745271689394294\n",
      "train loss:0.8354722392708196\n",
      "train loss:1.0760834092347153\n",
      "train loss:0.859518622388306\n",
      "train loss:1.0252211933561237\n",
      "train loss:1.0794381001006652\n",
      "train loss:0.8694085702342798\n",
      "train loss:0.9967374316941694\n",
      "train loss:0.8896771285301373\n",
      "train loss:1.0473939858713828\n",
      "train loss:1.010822321028907\n",
      "train loss:1.0876532224291953\n",
      "train loss:0.9980173182880726\n",
      "train loss:1.0223566926069707\n",
      "train loss:0.9268165424107376\n",
      "train loss:0.9031065871282442\n",
      "train loss:1.1701315593831665\n",
      "train loss:0.998987966707537\n",
      "train loss:1.0490551913453134\n",
      "train loss:0.8458881798270528\n",
      "train loss:0.9771891366008194\n",
      "train loss:1.058734930884064\n",
      "train loss:0.9918137948074792\n",
      "train loss:0.9073902907829564\n",
      "train loss:0.9316900684935783\n",
      "train loss:0.8408753559777743\n",
      "train loss:1.096578790764286\n",
      "train loss:1.0228777071748174\n",
      "train loss:0.8514800489163085\n",
      "train loss:0.9729366694863457\n",
      "train loss:0.8981595220375013\n",
      "train loss:1.0643791293548437\n",
      "train loss:0.9220285903149051\n",
      "train loss:1.0098963198565634\n",
      "train loss:1.0556830847289864\n",
      "train loss:0.8993488370886484\n",
      "train loss:0.876410494024549\n",
      "train loss:0.9481481133954426\n",
      "train loss:1.003627831286257\n",
      "train loss:0.9992323491735756\n",
      "train loss:0.963670134189114\n",
      "train loss:1.0847883094077988\n",
      "train loss:0.9841762679393963\n",
      "train loss:0.9503658251114411\n",
      "train loss:0.9431241572720537\n",
      "train loss:0.8922989151280657\n",
      "train loss:0.9996340730216499\n",
      "train loss:0.9237151495327232\n",
      "train loss:0.8702531635954466\n",
      "train loss:0.8190201259354616\n",
      "train loss:1.1215648156772284\n",
      "train loss:1.1804089686929422\n",
      "train loss:1.0250561358891543\n",
      "train loss:1.1959639179277175\n",
      "train loss:0.9522223893387225\n",
      "train loss:0.8990367649833412\n",
      "train loss:1.0246630771596879\n",
      "train loss:1.125828673043482\n",
      "train loss:0.9558830909502091\n",
      "train loss:0.8831191127932805\n",
      "train loss:1.0538888484909839\n",
      "train loss:1.0392649356599035\n",
      "train loss:0.9046335556620012\n",
      "train loss:0.8761022668660721\n",
      "train loss:0.965592441599237\n",
      "train loss:0.975603190994726\n",
      "train loss:0.803291222693188\n",
      "train loss:1.0333976738292423\n",
      "train loss:1.025836790771999\n",
      "train loss:1.1216749054650454\n",
      "train loss:0.9788937240767831\n",
      "train loss:1.0463427870177915\n",
      "train loss:1.1153100708451489\n",
      "train loss:1.061460202364046\n",
      "train loss:1.0206023130167292\n",
      "train loss:0.954088226351674\n",
      "train loss:1.0159863333748027\n",
      "train loss:0.9878546607905137\n",
      "train loss:1.0860609620740984\n",
      "train loss:0.9291718858612296\n",
      "train loss:1.0623432344234158\n",
      "train loss:0.9465161861634399\n",
      "train loss:1.1054492125792548\n",
      "train loss:0.948158669342638\n",
      "train loss:1.1015731481263107\n",
      "train loss:1.0664643479054283\n",
      "train loss:0.9625972661705083\n",
      "train loss:1.0134290597378608\n",
      "train loss:1.1553592023537536\n",
      "train loss:1.122850462104087\n",
      "train loss:1.2386791976859075\n",
      "train loss:1.053170971194746\n",
      "train loss:0.9111240229309406\n",
      "train loss:0.8806939217532229\n",
      "train loss:1.1236182182301147\n",
      "train loss:1.020606475925952\n",
      "train loss:1.032561462730739\n",
      "train loss:1.025019143457256\n",
      "train loss:1.1515241487883254\n",
      "train loss:1.0122343441973845\n",
      "train loss:0.9733683250011999\n",
      "train loss:0.7903582650841219\n",
      "train loss:0.902791832194659\n",
      "train loss:0.9910903495759438\n",
      "train loss:1.0816710601959438\n",
      "train loss:0.9486786280064233\n",
      "train loss:1.0438087308114827\n",
      "train loss:1.0245553907210105\n",
      "train loss:0.9751683179765047\n",
      "train loss:1.1006529320616893\n",
      "train loss:1.0864860312167846\n",
      "train loss:1.059724443812132\n",
      "train loss:0.9402833635661733\n",
      "train loss:0.9080821296373768\n",
      "train loss:1.0529173391268294\n",
      "train loss:0.9471648177700245\n",
      "train loss:0.9866561826352138\n",
      "train loss:1.0940447224843732\n",
      "train loss:1.1386320608355276\n",
      "train loss:1.158035374032048\n",
      "train loss:1.0764694977994715\n",
      "train loss:0.930663793777425\n",
      "train loss:1.1136501549082516\n",
      "train loss:1.0148957381320252\n",
      "train loss:1.0087728789385098\n",
      "train loss:0.9614011997863833\n",
      "train loss:1.1508624596384083\n",
      "train loss:1.0414007203612379\n",
      "train loss:1.0902885970043672\n",
      "train loss:1.0237726721338318\n",
      "train loss:1.0898785017997832\n",
      "train loss:1.0093444715496735\n",
      "train loss:0.9101770753304969\n",
      "train loss:0.8835809090501574\n",
      "train loss:0.9187709794606397\n",
      "train loss:0.9757049008013199\n",
      "train loss:1.0136816637386317\n",
      "train loss:0.9696808418557495\n",
      "train loss:1.012706701550277\n",
      "train loss:1.0941077282260816\n",
      "train loss:1.1455625518993429\n",
      "train loss:0.9995907220430749\n",
      "train loss:0.9245797151940254\n",
      "train loss:0.7564566167526299\n",
      "train loss:0.9848174284416332\n",
      "train loss:0.9384498871671282\n",
      "train loss:1.0822490823897115\n",
      "train loss:0.9433001504887895\n",
      "train loss:1.0634377858759407\n",
      "train loss:0.9506273679975454\n",
      "train loss:0.8089867714162378\n",
      "train loss:1.0931127345867369\n",
      "train loss:1.0205166720696033\n",
      "train loss:0.924021519925915\n",
      "train loss:1.0589133350851394\n",
      "train loss:0.9790127443638972\n",
      "train loss:0.7236969691633504\n",
      "train loss:0.9211234910485502\n",
      "train loss:0.993731306072668\n",
      "train loss:0.8852548685226247\n",
      "train loss:0.8887262674159535\n",
      "train loss:0.9638022686647902\n",
      "train loss:1.042976702168065\n",
      "train loss:1.0447121308140153\n",
      "train loss:0.9058042470913615\n",
      "train loss:0.9748338666492076\n",
      "train loss:0.8861780030774158\n",
      "train loss:1.0375756258764108\n",
      "train loss:1.0092172920900364\n",
      "train loss:1.030587792869627\n",
      "train loss:0.9871279929726862\n",
      "train loss:0.8211181468342068\n",
      "train loss:0.9480388918082415\n",
      "train loss:0.8750869120400302\n",
      "train loss:1.055905361708062\n",
      "train loss:0.874780401484242\n",
      "train loss:1.0937488878236374\n",
      "train loss:1.1614714906001742\n",
      "train loss:1.1604989001708583\n",
      "train loss:0.8096242619330408\n",
      "train loss:1.008200330967895\n",
      "train loss:1.16129771963885\n",
      "train loss:0.8321593788706947\n",
      "train loss:0.8507580671161705\n",
      "train loss:0.8691160105715595\n",
      "train loss:1.0940412822642893\n",
      "train loss:1.0818463341603466\n",
      "train loss:0.90365586601297\n",
      "train loss:0.9773168181314495\n",
      "train loss:0.9864653287000275\n",
      "train loss:1.0624167519568868\n",
      "train loss:0.9433558128530489\n",
      "train loss:1.0359803413593498\n",
      "train loss:0.8414403879238909\n",
      "train loss:1.0647597860886224\n",
      "train loss:1.0529940769859\n",
      "train loss:0.861167294091409\n",
      "train loss:1.0051309067717764\n",
      "train loss:1.0020833318721811\n",
      "train loss:0.9840970057745143\n",
      "train loss:0.9154336312804675\n",
      "train loss:0.9760807742568082\n",
      "train loss:0.8078810277551447\n",
      "train loss:0.9367507157819785\n",
      "train loss:0.8499739904068692\n",
      "train loss:0.9949299033381933\n",
      "train loss:1.0471571684433507\n",
      "train loss:0.92710512460877\n",
      "train loss:0.8548145683974164\n",
      "train loss:1.0850661271083428\n",
      "train loss:0.9858637507115522\n",
      "train loss:0.8018701240987081\n",
      "train loss:1.0291457151437415\n",
      "train loss:1.3663554678094072\n",
      "train loss:0.9868056386215792\n",
      "train loss:0.9876951004536685\n",
      "train loss:0.8999862990560176\n",
      "train loss:0.9269813994406761\n",
      "train loss:1.0362265826620018\n",
      "train loss:1.1015718459642998\n",
      "train loss:0.8979387311587955\n",
      "train loss:1.1071739369780418\n",
      "train loss:1.100239147059974\n",
      "train loss:0.9246531817983119\n",
      "train loss:0.8636230675101741\n",
      "train loss:1.0600841760848436\n",
      "train loss:0.9437707188418827\n",
      "train loss:1.1005494348206988\n",
      "train loss:0.8773941820804996\n",
      "train loss:0.9023802475443946\n",
      "train loss:0.9544497460939911\n",
      "train loss:1.0086949244848729\n",
      "train loss:0.9109071467357371\n",
      "train loss:1.0806199373145013\n",
      "train loss:0.8296010606478393\n",
      "train loss:1.0705018621556592\n",
      "train loss:1.01379064810921\n",
      "train loss:1.0124978793489638\n",
      "train loss:1.1213906022265763\n",
      "train loss:0.867203786597717\n",
      "train loss:0.935881482586409\n",
      "train loss:1.0296164156336034\n",
      "train loss:1.1133545544106402\n",
      "train loss:0.8050702693683636\n",
      "train loss:1.1891974898052389\n",
      "train loss:0.9633639049129803\n",
      "train loss:1.1698382045049918\n",
      "train loss:0.9791664104850039\n",
      "train loss:0.9460373162610364\n",
      "train loss:1.0654549999606036\n",
      "train loss:1.0141782516011266\n",
      "train loss:1.1099313318073074\n",
      "train loss:0.9263005160898472\n",
      "train loss:0.8676254701993561\n",
      "train loss:0.9978697136040047\n",
      "train loss:1.0795731750194104\n",
      "train loss:0.95143683850882\n",
      "train loss:0.9173785648827892\n",
      "train loss:1.0233903839206662\n",
      "train loss:1.1541985126209255\n",
      "train loss:0.988291697215491\n",
      "train loss:1.0277542592992603\n",
      "train loss:1.0846490424954118\n",
      "train loss:1.114089926717383\n",
      "train loss:1.0482956160014105\n",
      "train loss:1.024270111108438\n",
      "train loss:1.0776138767370478\n",
      "train loss:1.0160422938049996\n",
      "train loss:1.1028293915456027\n",
      "train loss:1.0277609544996462\n",
      "train loss:0.987222840509178\n",
      "train loss:0.9315140989001711\n",
      "train loss:1.1584734849361111\n",
      "train loss:0.9548732629092094\n",
      "train loss:1.0191107971645643\n",
      "train loss:0.9395623209057665\n",
      "train loss:0.914834065304821\n",
      "train loss:0.7813061834219746\n",
      "train loss:0.9200193118318128\n",
      "train loss:0.8636005944532056\n",
      "train loss:0.8742115743172469\n",
      "train loss:1.1132121599861862\n",
      "train loss:1.0526699325723075\n",
      "train loss:1.0367375359215492\n",
      "train loss:1.083859611212269\n",
      "train loss:0.940594564493426\n",
      "train loss:1.1152759092501805\n",
      "train loss:1.0771737031121837\n",
      "train loss:0.8772914208572984\n",
      "train loss:0.9427334344668545\n",
      "train loss:1.0964444265052715\n",
      "train loss:1.0894361141614852\n",
      "train loss:1.0549786050376868\n",
      "train loss:0.9350194675828046\n",
      "train loss:0.9261546384395516\n",
      "train loss:1.0759180373386104\n",
      "train loss:1.0012652210334745\n",
      "train loss:0.9650526388075835\n",
      "train loss:1.0234981488248345\n",
      "train loss:0.9310301580074613\n",
      "train loss:1.0450848381877313\n",
      "train loss:0.821142455580292\n",
      "train loss:0.9401950354783305\n",
      "train loss:0.9084489900816858\n",
      "train loss:0.9384793239511418\n",
      "train loss:0.9611635547302961\n",
      "train loss:1.1410446712348403\n",
      "train loss:0.9857708044489665\n",
      "train loss:1.0989052572517932\n",
      "train loss:1.0537370930563392\n",
      "train loss:0.9802890543211739\n",
      "train loss:0.8776050204564966\n",
      "train loss:0.8909689788493038\n",
      "train loss:0.8470869415881138\n",
      "train loss:0.8660739907277548\n",
      "train loss:1.048773262812919\n",
      "train loss:0.7128830261359218\n",
      "train loss:0.8909158691374418\n",
      "train loss:0.851618889797583\n",
      "train loss:0.9048722188443581\n",
      "train loss:1.036152096209867\n",
      "train loss:0.9744394038299233\n",
      "train loss:1.1870459458870866\n",
      "train loss:0.8352474107696627\n",
      "train loss:0.8302608750469023\n",
      "train loss:0.9205863520925144\n",
      "train loss:1.0397761187534869\n",
      "train loss:0.7526393353200228\n",
      "train loss:1.0224455316377816\n",
      "train loss:0.9768911386861961\n",
      "train loss:0.9335489125261965\n",
      "train loss:0.8901440342440506\n",
      "train loss:0.986230737894665\n",
      "train loss:1.0655867955023635\n",
      "train loss:0.8984958196719868\n",
      "train loss:1.0427104984732607\n",
      "train loss:1.0087292881664738\n",
      "train loss:0.995275863925372\n",
      "train loss:0.9286668059561759\n",
      "train loss:0.9319354609559466\n",
      "train loss:0.908869737982549\n",
      "train loss:0.9923793749915452\n",
      "train loss:0.824108429885943\n",
      "train loss:0.9954468259600343\n",
      "train loss:0.9110515632520456\n",
      "train loss:0.8505947706348279\n",
      "train loss:1.1055725290757652\n",
      "train loss:0.9019570452437793\n",
      "train loss:1.0055724811538689\n",
      "train loss:1.0147918835796697\n",
      "train loss:0.7750361400872906\n",
      "train loss:0.9757431334962395\n",
      "train loss:0.9997873171561783\n",
      "train loss:0.9954893231472036\n",
      "train loss:1.0972058179052575\n",
      "train loss:0.8891193004026728\n",
      "train loss:0.959941688480842\n",
      "train loss:0.9516162337755516\n",
      "train loss:0.9359619055438952\n",
      "train loss:0.9490336821034421\n",
      "train loss:1.0078961189813922\n",
      "train loss:1.0135170739531951\n",
      "train loss:1.1860280288588383\n",
      "train loss:0.7111427930483414\n",
      "train loss:1.0053069473138827\n",
      "train loss:0.8704427111973496\n",
      "train loss:0.9060575948479623\n",
      "train loss:0.9268718137016417\n",
      "train loss:0.9509249184053188\n",
      "train loss:1.1291175541818648\n",
      "train loss:1.0398538315698744\n",
      "train loss:0.9938460102227825\n",
      "train loss:1.1226685950077218\n",
      "train loss:0.8661976260706444\n",
      "train loss:1.0856098836161072\n",
      "train loss:0.893626552660615\n",
      "train loss:0.9372025661832744\n",
      "train loss:1.0731199818817232\n",
      "train loss:0.8987370175984017\n",
      "train loss:0.9053083366275207\n",
      "train loss:1.1129000226080437\n",
      "train loss:1.0131645796172453\n",
      "train loss:0.8801938966661687\n",
      "train loss:0.8473737038816855\n",
      "train loss:1.105140708517261\n",
      "train loss:1.0275316793569802\n",
      "train loss:0.8007117458866511\n",
      "train loss:0.9267899311500414\n",
      "train loss:0.9560502056718881\n",
      "train loss:0.8989633001870929\n",
      "train loss:0.9471627801442958\n",
      "train loss:1.037499942791939\n",
      "train loss:0.8578156831546094\n",
      "train loss:0.9439009433882518\n",
      "train loss:1.0397174215459202\n",
      "train loss:0.8546384418864236\n",
      "train loss:0.9020544879252814\n",
      "train loss:1.054611172284679\n",
      "train loss:0.953206786760993\n",
      "train loss:0.8952679970412697\n",
      "train loss:0.9524800186715272\n",
      "train loss:0.8756699636266562\n",
      "train loss:1.0905602112976043\n",
      "train loss:1.0103762685331112\n",
      "train loss:0.7934625226768969\n",
      "train loss:0.9830083176921378\n",
      "train loss:1.0455497579819015\n",
      "train loss:0.9581732915960833\n",
      "train loss:1.0277933272559714\n",
      "train loss:0.9805271966880145\n",
      "train loss:1.081316360806789\n",
      "train loss:1.0602707009359837\n",
      "train loss:0.9429749212667059\n",
      "train loss:0.943668565537684\n",
      "train loss:0.9725639664113054\n",
      "train loss:0.9883194461487398\n",
      "train loss:0.8776272439005152\n",
      "train loss:1.0282616490902985\n",
      "train loss:1.086118339012989\n",
      "train loss:1.019822301018002\n",
      "train loss:0.9193346737459233\n",
      "train loss:0.9685979569529423\n",
      "train loss:0.8323700837825285\n",
      "train loss:1.0629347213583908\n",
      "train loss:0.9233411046727922\n",
      "train loss:0.9571929072624272\n",
      "train loss:0.8636377230344181\n",
      "train loss:0.9055166832347935\n",
      "train loss:0.8830971037785367\n",
      "train loss:0.9987519474387875\n",
      "train loss:0.8185935056427216\n",
      "train loss:0.9609143314899896\n",
      "train loss:1.0018924166138583\n",
      "train loss:0.9235985700517798\n",
      "train loss:0.7810370364734927\n",
      "train loss:0.8381574359092961\n",
      "train loss:0.8657375062469655\n",
      "train loss:0.9675177388558034\n",
      "train loss:0.944112923232573\n",
      "train loss:0.9346623372616082\n",
      "train loss:0.9532095295152071\n",
      "train loss:0.9293737230562032\n",
      "train loss:0.9206296120936165\n",
      "train loss:0.861049275236441\n",
      "train loss:1.0934526493687284\n",
      "train loss:0.9484174716050915\n",
      "train loss:0.8790626772673636\n",
      "train loss:1.070125840616172\n",
      "train loss:1.0701032028012614\n",
      "train loss:0.9264123301054952\n",
      "train loss:0.8860912911282746\n",
      "train loss:1.0671925458474476\n",
      "train loss:1.088850777932239\n",
      "train loss:0.863843305663983\n",
      "train loss:1.0796869855207767\n",
      "train loss:0.8341343552517294\n",
      "train loss:0.8722510284552867\n",
      "train loss:1.0343069092603419\n",
      "train loss:1.0092328451819372\n",
      "train loss:0.8970921595781906\n",
      "train loss:0.9376223915638882\n",
      "train loss:0.8784640485554083\n",
      "train loss:0.9027624305120239\n",
      "train loss:0.8188213434267184\n",
      "train loss:1.0083604746815145\n",
      "train loss:1.1524954700981334\n",
      "train loss:0.9836941339828412\n",
      "train loss:0.8349659854533305\n",
      "train loss:1.112187275487156\n",
      "train loss:1.1014426169921023\n",
      "train loss:0.8419574353276923\n",
      "train loss:1.0012649181814017\n",
      "train loss:0.8973729113955777\n",
      "train loss:1.054847779713648\n",
      "train loss:1.121485014536658\n",
      "train loss:0.9107801784899557\n",
      "train loss:1.0222348604264078\n",
      "train loss:1.0073557272775961\n",
      "train loss:1.0167340283733306\n",
      "train loss:0.9720151815212797\n",
      "train loss:0.8129851065817099\n",
      "train loss:0.9332826387305334\n",
      "train loss:0.997277326009848\n",
      "train loss:0.9101984855972007\n",
      "train loss:0.8896988154269859\n",
      "train loss:0.979310030881081\n",
      "train loss:1.0746576909806298\n",
      "train loss:1.0184546066384275\n",
      "train loss:0.9952617240746217\n",
      "train loss:1.0118626957115557\n",
      "train loss:0.90721626858348\n",
      "train loss:1.0738914835221853\n",
      "train loss:1.1008850974652342\n",
      "train loss:0.8787105256775569\n",
      "train loss:0.876915982731839\n",
      "train loss:0.821224759414551\n",
      "train loss:0.9941543721121257\n",
      "train loss:0.8607805539240821\n",
      "train loss:0.9621680179070615\n",
      "train loss:0.8952715605388802\n",
      "train loss:0.8670895102633034\n",
      "train loss:1.0315891856833987\n",
      "train loss:1.0056132969543412\n",
      "train loss:0.9839069141343788\n",
      "train loss:0.9851298453061377\n",
      "train loss:0.9644014321521743\n",
      "train loss:0.9872282340082568\n",
      "train loss:0.9466113934385342\n",
      "train loss:0.9451539028845828\n",
      "train loss:1.0202495180039395\n",
      "train loss:0.7637644941510244\n",
      "train loss:0.8559574628694882\n",
      "train loss:0.9515653811399014\n",
      "train loss:1.040218739864824\n",
      "train loss:0.9773156964484291\n",
      "train loss:1.0800255710770492\n",
      "train loss:0.8501380145873056\n",
      "train loss:0.9570093186784705\n",
      "train loss:0.9703828188223858\n",
      "train loss:0.9155207381424444\n",
      "train loss:1.1258720623310652\n",
      "train loss:0.9566295119999524\n",
      "train loss:0.8740026796939611\n",
      "train loss:1.0317390166319866\n",
      "train loss:0.8997457419875707\n",
      "train loss:1.0091853242112934\n",
      "train loss:0.7404852560237905\n",
      "train loss:0.8042477402993845\n",
      "train loss:1.0246921077408546\n",
      "train loss:1.0030295311928268\n",
      "train loss:1.0060255908806588\n",
      "train loss:0.9097334306726791\n",
      "train loss:1.0797344547153533\n",
      "train loss:0.9453548987197121\n",
      "train loss:1.0083352480393273\n",
      "train loss:1.0856026476792544\n",
      "train loss:0.840296812693917\n",
      "train loss:1.1518188919258163\n",
      "train loss:0.8837544365821871\n",
      "train loss:0.9731444757961745\n",
      "train loss:0.9591299034737889\n",
      "train loss:0.9688085952524195\n",
      "train loss:0.8086263850224608\n",
      "train loss:1.091045308320358\n",
      "train loss:1.0121054021679965\n",
      "train loss:0.9381390312463016\n",
      "train loss:1.00916588360993\n",
      "train loss:1.0155665902590634\n",
      "train loss:1.0334758479195765\n",
      "train loss:0.9465692881580471\n",
      "train loss:0.9665449322923166\n",
      "train loss:1.0029305600274347\n",
      "train loss:0.8694720881917742\n",
      "train loss:0.9097603082505487\n",
      "train loss:1.0882365183921847\n",
      "train loss:0.9942969344512089\n",
      "train loss:0.8739199509749214\n",
      "train loss:0.9904675139808012\n",
      "train loss:0.9836104013996618\n",
      "train loss:0.9601801968874732\n",
      "train loss:1.0349208045408163\n",
      "train loss:0.9635169198419886\n",
      "train loss:0.9873120873695665\n",
      "train loss:0.9033261649667029\n",
      "train loss:0.9982977710380645\n",
      "train loss:1.004579815272245\n",
      "train loss:0.8819859942284718\n",
      "train loss:1.0625286461177\n",
      "train loss:1.0990970821782908\n",
      "train loss:0.9572383044319328\n",
      "train loss:0.9597296842952148\n",
      "train loss:0.9531056047513176\n",
      "train loss:0.891543675512906\n",
      "=== epoch:4, train acc:0.989, test acc:0.987 ===\n",
      "train loss:1.0006342434493516\n",
      "train loss:1.1785837084275945\n",
      "train loss:1.0187792979232122\n",
      "train loss:0.9687447986442698\n",
      "train loss:0.9978533007561861\n",
      "train loss:0.9509875216536282\n",
      "train loss:0.9520578758955357\n",
      "train loss:1.1279307277103396\n",
      "train loss:0.9840165334411577\n",
      "train loss:1.0199763671884645\n",
      "train loss:0.9553591755201768\n",
      "train loss:0.8367983034898302\n",
      "train loss:0.8311665349299598\n",
      "train loss:1.0475946750512748\n",
      "train loss:0.8765765236473593\n",
      "train loss:1.095784781907282\n",
      "train loss:0.9849948254573456\n",
      "train loss:0.8858582160645746\n",
      "train loss:0.877863592186356\n",
      "train loss:0.8692386195344325\n",
      "train loss:0.9171609146906282\n",
      "train loss:1.043011564498056\n",
      "train loss:1.0673902844680219\n",
      "train loss:0.903627286596032\n",
      "train loss:0.8455122592003338\n",
      "train loss:0.9826463485800602\n",
      "train loss:1.0656785419583235\n",
      "train loss:0.8855373703300304\n",
      "train loss:1.1027891318533798\n",
      "train loss:1.0332114872920737\n",
      "train loss:1.0154440297023877\n",
      "train loss:0.9668144167427613\n",
      "train loss:0.8809468793334402\n",
      "train loss:0.9627074440818335\n",
      "train loss:0.9409177378286914\n",
      "train loss:0.8232571006207045\n",
      "train loss:0.9489981470179291\n",
      "train loss:0.8801558797367397\n",
      "train loss:0.7960887355432587\n",
      "train loss:0.9547573021018626\n",
      "train loss:0.9532284811282925\n",
      "train loss:0.8252836413683184\n",
      "train loss:0.9912757328437399\n",
      "train loss:0.982517037545646\n",
      "train loss:0.7963326865235065\n",
      "train loss:0.8575919537886605\n",
      "train loss:1.1164354756005213\n",
      "train loss:1.2042637731761083\n",
      "train loss:0.8841118798277537\n",
      "train loss:1.057856144845097\n",
      "train loss:0.8652991143956515\n",
      "train loss:0.8725644675747067\n",
      "train loss:0.9146897749104731\n",
      "train loss:1.0832138209914037\n",
      "train loss:0.8436369507608981\n",
      "train loss:0.8048539257765074\n",
      "train loss:0.9352914125199595\n",
      "train loss:0.9194503325921346\n",
      "train loss:1.0405225218186631\n",
      "train loss:1.1038753961656977\n",
      "train loss:0.8822758720692536\n",
      "train loss:1.0589783855261432\n",
      "train loss:1.088563628316649\n",
      "train loss:0.8448626212124758\n",
      "train loss:0.9045001485605215\n",
      "train loss:0.889996891136695\n",
      "train loss:1.121282544514452\n",
      "train loss:1.0515613105566506\n",
      "train loss:1.0390173223530474\n",
      "train loss:1.0402591321727295\n",
      "train loss:1.0526514374615108\n",
      "train loss:1.0379653573196617\n",
      "train loss:0.9565811781230904\n",
      "train loss:0.9214996053824305\n",
      "train loss:0.9970094199202694\n",
      "train loss:0.9098858776824814\n",
      "train loss:0.9150095380592771\n",
      "train loss:1.0310817874377662\n",
      "train loss:0.9475231747792909\n",
      "train loss:1.0161427071650848\n",
      "train loss:0.9690619734671376\n",
      "train loss:1.1158450501088537\n",
      "train loss:0.9770865405827707\n",
      "train loss:0.8560599347991585\n",
      "train loss:0.8549188881912894\n",
      "train loss:1.0197391742944324\n",
      "train loss:0.95454148503554\n",
      "train loss:0.8884209663250539\n",
      "train loss:0.9174727203440698\n",
      "train loss:0.9798961415902134\n",
      "train loss:1.134421543277478\n",
      "train loss:0.8736686442219151\n",
      "train loss:0.9458712903959067\n",
      "train loss:1.0103582529073112\n",
      "train loss:0.979269373488658\n",
      "train loss:0.8022758187386843\n",
      "train loss:0.9918836574458959\n",
      "train loss:1.0240878169712657\n",
      "train loss:0.9085744898383102\n",
      "train loss:0.9248538162982323\n",
      "train loss:0.9556635304312873\n",
      "train loss:0.7941223826524235\n",
      "train loss:1.1851540559225031\n",
      "train loss:0.9027769816509326\n",
      "train loss:0.8739520551873943\n",
      "train loss:0.9384360814515706\n",
      "train loss:0.9867335799567641\n",
      "train loss:0.9345371937981036\n",
      "train loss:1.1957685218852177\n",
      "train loss:1.0650647380340752\n",
      "train loss:0.9255886957163483\n",
      "train loss:0.7810080038011589\n",
      "train loss:0.9870498284332662\n",
      "train loss:1.222891062966616\n",
      "train loss:0.9923858639312259\n",
      "train loss:0.9475059462422322\n",
      "train loss:1.0102963408796755\n",
      "train loss:0.9947880222593248\n",
      "train loss:1.0564759303863698\n",
      "train loss:1.0018886644833243\n",
      "train loss:0.9674616713429813\n",
      "train loss:0.8710343036693345\n",
      "train loss:1.0157061355500918\n",
      "train loss:0.9580368750816186\n",
      "train loss:1.191370810508916\n",
      "train loss:1.093672819771768\n",
      "train loss:0.8521401387127358\n",
      "train loss:0.7738347664504259\n",
      "train loss:0.9252240227117434\n",
      "train loss:0.901193810703168\n",
      "train loss:0.9569206489664295\n",
      "train loss:0.9438145436036232\n",
      "train loss:1.0264689429601237\n",
      "train loss:0.769228614745177\n",
      "train loss:0.8568583969747793\n",
      "train loss:0.8471346982362526\n",
      "train loss:0.9225082343348617\n",
      "train loss:0.9917423074143962\n",
      "train loss:1.0273191157303427\n",
      "train loss:0.910344944279959\n",
      "train loss:0.9174467526328223\n",
      "train loss:0.9486196063813676\n",
      "train loss:1.166262832415525\n",
      "train loss:0.8690648499721548\n",
      "train loss:0.8950083923539159\n",
      "train loss:1.0712565217326726\n",
      "train loss:0.9072368610305722\n",
      "train loss:0.9313417227258121\n",
      "train loss:0.9918614110291692\n",
      "train loss:0.9255226640762235\n",
      "train loss:0.9674590399310431\n",
      "train loss:0.9218565989384147\n",
      "train loss:0.7245968144295408\n",
      "train loss:1.0440463683984835\n",
      "train loss:1.0287967843149073\n",
      "train loss:1.0433517993532184\n",
      "train loss:1.1085463573296714\n",
      "train loss:0.8353405644041346\n",
      "train loss:1.0212211451602875\n",
      "train loss:1.0351764274508732\n",
      "train loss:0.9946093918475327\n",
      "train loss:1.007299557578262\n",
      "train loss:0.8532379498173573\n",
      "train loss:0.8513474389025157\n",
      "train loss:0.9659401444121927\n",
      "train loss:0.8816428602249422\n",
      "train loss:0.8921587248463809\n",
      "train loss:1.0062331859118523\n",
      "train loss:0.9334854738313849\n",
      "train loss:0.8917398690475654\n",
      "train loss:0.9650825895188722\n",
      "train loss:0.8520279582222058\n",
      "train loss:0.9685884300186466\n",
      "train loss:0.9487402931692587\n",
      "train loss:0.9230893749548861\n",
      "train loss:1.013679483059308\n",
      "train loss:0.9334221254540073\n",
      "train loss:1.0457952020942534\n",
      "train loss:1.0863368097318473\n",
      "train loss:1.0867326664509216\n",
      "train loss:0.8788617482937611\n",
      "train loss:1.014156488340251\n",
      "train loss:0.9032436695013533\n",
      "train loss:1.1817006893576527\n",
      "train loss:0.8790793804796242\n",
      "train loss:0.9712522337657187\n",
      "train loss:1.1062301816281965\n",
      "train loss:0.9503933727793119\n",
      "train loss:0.8155281488362998\n",
      "train loss:1.0510054055386855\n",
      "train loss:1.066024227531302\n",
      "train loss:1.1163281633056803\n",
      "train loss:0.8767979190074838\n",
      "train loss:1.0530471572739704\n",
      "train loss:0.8888965036636814\n",
      "train loss:0.903695839321725\n",
      "train loss:1.0492456976630018\n",
      "train loss:0.9352796683862478\n",
      "train loss:0.9299482948247122\n",
      "train loss:1.109237363713033\n",
      "train loss:1.0498539531769255\n",
      "train loss:0.9455602694581016\n",
      "train loss:0.8543614999202295\n",
      "train loss:1.0554225036525806\n",
      "train loss:0.7912886603915199\n",
      "train loss:1.052397785272152\n",
      "train loss:0.9226985391509613\n",
      "train loss:0.9507054469326609\n",
      "train loss:0.9125830671734261\n",
      "train loss:0.8519964777782504\n",
      "train loss:0.783142976586285\n",
      "train loss:0.9840975711515852\n",
      "train loss:0.9101830650929127\n",
      "train loss:0.9448989996955163\n",
      "train loss:1.0285668878576038\n",
      "train loss:1.0981628862441672\n",
      "train loss:0.9506498289339071\n",
      "train loss:0.8723271024759182\n",
      "train loss:0.8126582026808982\n",
      "train loss:0.9524730247659321\n",
      "train loss:0.9024966882337294\n",
      "train loss:0.9199441664491721\n",
      "train loss:1.0747984878678065\n",
      "train loss:0.9698110702863225\n",
      "train loss:0.9852719524475124\n",
      "train loss:1.0835088751858648\n",
      "train loss:0.9525952842126508\n",
      "train loss:1.0104233920626866\n",
      "train loss:0.9561476301046987\n",
      "train loss:0.9799301709023854\n",
      "train loss:1.0328107997493419\n",
      "train loss:0.8784894479425001\n",
      "train loss:1.081307870638916\n",
      "train loss:0.8814482363432181\n",
      "train loss:0.9040847047377418\n",
      "train loss:0.8981491201073031\n",
      "train loss:0.8641476942791395\n",
      "train loss:1.1417964110414216\n",
      "train loss:0.8615537639694479\n",
      "train loss:1.0321663883719652\n",
      "train loss:1.0363804247643342\n",
      "train loss:0.9626801021144845\n",
      "train loss:0.9621343539580374\n",
      "train loss:0.9464483686197392\n",
      "train loss:1.0124414699124014\n",
      "train loss:0.9549584681524551\n",
      "train loss:0.9677287422094802\n",
      "train loss:0.8118467160803076\n",
      "train loss:1.1247334614677533\n",
      "train loss:0.8353457725366765\n",
      "train loss:1.0566932543655505\n",
      "train loss:0.8068872634688325\n",
      "train loss:0.9426247306413214\n",
      "train loss:0.8188407826620883\n",
      "train loss:1.053830784141291\n",
      "train loss:0.760537824881503\n",
      "train loss:0.7447502422698333\n",
      "train loss:1.0996563879122958\n",
      "train loss:1.212173277831773\n",
      "train loss:1.0126655608004402\n",
      "train loss:1.044918635649208\n",
      "train loss:1.0664115050390959\n",
      "train loss:1.0023497677876356\n",
      "train loss:0.9295238074137813\n",
      "train loss:0.9769981773513348\n",
      "train loss:0.9715046054090205\n",
      "train loss:0.8627050960426265\n",
      "train loss:0.9845394772404942\n",
      "train loss:0.8751472861424286\n",
      "train loss:1.103491073471829\n",
      "train loss:0.9282029839075874\n",
      "train loss:1.0092959146057856\n",
      "train loss:1.0195524164702554\n",
      "train loss:0.9151903611985328\n",
      "train loss:0.9214355054014106\n",
      "train loss:0.9180182381487796\n",
      "train loss:0.7373496003534314\n",
      "train loss:0.8904569960971978\n",
      "train loss:0.9371524079641396\n",
      "train loss:0.947019336444426\n",
      "train loss:0.9000602270690604\n",
      "train loss:0.96726803008724\n",
      "train loss:1.0003616165861693\n",
      "train loss:1.0244806133026731\n",
      "train loss:1.2547833123251233\n",
      "train loss:0.9867367977656243\n",
      "train loss:0.93978218950086\n",
      "train loss:1.0066551423690866\n",
      "train loss:1.039879385424881\n",
      "train loss:0.8410613247351005\n",
      "train loss:0.8962489604330602\n",
      "train loss:0.9401386949257088\n",
      "train loss:1.0174142819755108\n",
      "train loss:0.885709106806139\n",
      "train loss:1.0354506602933242\n",
      "train loss:0.97040415835057\n",
      "train loss:0.973564530073096\n",
      "train loss:1.056943728595404\n",
      "train loss:0.9716671098159346\n",
      "train loss:0.9915794244819794\n",
      "train loss:1.048397742006404\n",
      "train loss:0.9364471978026547\n",
      "train loss:0.9255836201300883\n",
      "train loss:0.8068135184514453\n",
      "train loss:0.9785638370884242\n",
      "train loss:0.9387349864914148\n",
      "train loss:0.8925765923527547\n",
      "train loss:1.035313089894973\n",
      "train loss:0.9758657144971451\n",
      "train loss:0.8703614810543125\n",
      "train loss:1.016696357917449\n",
      "train loss:0.9723732076923529\n",
      "train loss:1.0121180536121812\n",
      "train loss:0.9290537998352215\n",
      "train loss:0.8388258947136238\n",
      "train loss:1.1195465331216383\n",
      "train loss:0.9590061587001331\n",
      "train loss:0.8707771169448635\n",
      "train loss:1.1080456698508427\n",
      "train loss:0.8652780772471138\n",
      "train loss:1.0108423683902468\n",
      "train loss:1.0817033747269205\n",
      "train loss:1.007145648019968\n",
      "train loss:0.8361680126271952\n",
      "train loss:0.9339657987986669\n",
      "train loss:0.9102988001154166\n",
      "train loss:0.9586045841126385\n",
      "train loss:0.8671895037440963\n",
      "train loss:0.8646006741339815\n",
      "train loss:0.7819799431967592\n",
      "train loss:0.9219419042979259\n",
      "train loss:0.939974450231766\n",
      "train loss:1.0812337336555806\n",
      "train loss:0.8192873350003944\n",
      "train loss:0.8388426977289513\n",
      "train loss:0.8856790526937628\n",
      "train loss:1.0756633305595433\n",
      "train loss:0.9724541489885006\n",
      "train loss:0.9491892888836744\n",
      "train loss:0.8873295534488124\n",
      "train loss:0.992419124429019\n",
      "train loss:1.060493944492255\n",
      "train loss:1.1131266056382805\n",
      "train loss:0.9018952567527256\n",
      "train loss:0.8876727764255122\n",
      "train loss:0.9631660228692769\n",
      "train loss:1.0255246727787293\n",
      "train loss:0.9615893652473424\n",
      "train loss:1.0389659590540024\n",
      "train loss:0.7988859708695982\n",
      "train loss:1.1041915154309743\n",
      "train loss:1.0842346149574342\n",
      "train loss:1.0186287270852694\n",
      "train loss:1.016974348327631\n",
      "train loss:0.9863585755098728\n",
      "train loss:0.9116102203208014\n",
      "train loss:0.9452767818646826\n",
      "train loss:1.0542625105767902\n",
      "train loss:0.9570828037219167\n",
      "train loss:1.095082943091593\n",
      "train loss:0.9775685253319121\n",
      "train loss:0.9290225636306033\n",
      "train loss:0.89886006934614\n",
      "train loss:1.0440323783794283\n",
      "train loss:0.9213144233965604\n",
      "train loss:1.114428008428724\n",
      "train loss:0.9343579413637131\n",
      "train loss:0.8987819866566794\n",
      "train loss:0.9042704595718518\n",
      "train loss:1.0158077401823862\n",
      "train loss:0.9053876679056139\n",
      "train loss:0.8020470755232266\n",
      "train loss:0.745019378860104\n",
      "train loss:0.8331720231727232\n",
      "train loss:1.1267702208277117\n",
      "train loss:0.8923096390882549\n",
      "train loss:0.8513506855382977\n",
      "train loss:1.0582236108660685\n",
      "train loss:0.871844286660246\n",
      "train loss:0.8955834525539408\n",
      "train loss:0.9849311560687442\n",
      "train loss:0.9715110527957164\n",
      "train loss:0.8767899696758754\n",
      "train loss:1.0667825267711906\n",
      "train loss:0.9643582002274613\n",
      "train loss:1.1756682384366675\n",
      "train loss:1.15425261532593\n",
      "train loss:1.0313456523547182\n",
      "train loss:1.0689850805954613\n",
      "train loss:0.9093045425155828\n",
      "train loss:0.9198828356239482\n",
      "train loss:0.7980789879435115\n",
      "train loss:1.0044973913234465\n",
      "train loss:1.0972015321501194\n",
      "train loss:0.98732099074921\n",
      "train loss:0.8132852696083351\n",
      "train loss:0.9436839107476916\n",
      "train loss:0.9167686865423764\n",
      "train loss:0.9939905321279425\n",
      "train loss:0.8893323334970559\n",
      "train loss:0.815169618155703\n",
      "train loss:0.8816451840914971\n",
      "train loss:0.8882025022777686\n",
      "train loss:0.8303568255508411\n",
      "train loss:0.9532468387715457\n",
      "train loss:1.0708160617352385\n",
      "train loss:0.8735876079751566\n",
      "train loss:0.7732123766414648\n",
      "train loss:0.939834808809727\n",
      "train loss:0.9528248627265858\n",
      "train loss:1.1525939242496355\n",
      "train loss:1.0318734496296436\n",
      "train loss:0.9374728644362982\n",
      "train loss:0.7531231844541346\n",
      "train loss:0.8608986057594366\n",
      "train loss:1.0279670138526165\n",
      "train loss:0.9695153071493314\n",
      "train loss:1.0093775234795883\n",
      "train loss:0.8183676160543867\n",
      "train loss:1.0787397205855214\n",
      "train loss:0.9634809826379253\n",
      "train loss:0.9644830153388664\n",
      "train loss:1.0074624716532232\n",
      "train loss:1.028573574623517\n",
      "train loss:0.8625510569511431\n",
      "train loss:0.7853297591431598\n",
      "train loss:0.8677383139558557\n",
      "train loss:0.887766907026982\n",
      "train loss:1.0174096427088413\n",
      "train loss:0.8824648183925656\n",
      "train loss:1.096944830019876\n",
      "train loss:0.830952079296822\n",
      "train loss:1.0349677840462423\n",
      "train loss:0.8613542668117661\n",
      "train loss:0.9621040584603358\n",
      "train loss:1.0110436689923636\n",
      "train loss:0.8066176156766467\n",
      "train loss:0.9236901511780858\n",
      "train loss:1.0298766691170198\n",
      "train loss:0.9192528124510564\n",
      "train loss:0.8393458172513121\n",
      "train loss:0.803230736665329\n",
      "train loss:1.1108780629895414\n",
      "train loss:0.8413932910078915\n",
      "train loss:1.0885744640669721\n",
      "train loss:1.041391947534775\n",
      "train loss:0.8639356146087813\n",
      "train loss:0.9530056880075486\n",
      "train loss:1.1618739928898072\n",
      "train loss:0.8022250576686993\n",
      "train loss:0.772370388856421\n",
      "train loss:0.9411955014720506\n",
      "train loss:0.939495530370746\n",
      "train loss:0.8145589794536455\n",
      "train loss:1.0798475285940103\n",
      "train loss:0.7577103346951258\n",
      "train loss:0.9991097712584697\n",
      "train loss:1.006786222196608\n",
      "train loss:0.9941894867873197\n",
      "train loss:0.9509438696311215\n",
      "train loss:1.0344832390902732\n",
      "train loss:0.7638426995092069\n",
      "train loss:0.9222632367677239\n",
      "train loss:0.9030147974092767\n",
      "train loss:1.0887042199275472\n",
      "train loss:0.8944883180645689\n",
      "train loss:1.1357471088552484\n",
      "train loss:1.0018628634859186\n",
      "train loss:0.8934464832872515\n",
      "train loss:0.856881266193882\n",
      "train loss:0.8682921810561811\n",
      "train loss:0.9343382324147594\n",
      "train loss:0.9414288290050314\n",
      "train loss:0.802894651050552\n",
      "train loss:1.1517107116406011\n",
      "train loss:0.8702611609924726\n",
      "train loss:0.8937258056622948\n",
      "train loss:0.9070174710860204\n",
      "train loss:0.8060446021073814\n",
      "train loss:1.0522027499346005\n",
      "train loss:0.9983128427511173\n",
      "train loss:1.027153667293483\n",
      "train loss:0.9494004631915998\n",
      "train loss:1.031436475794888\n",
      "train loss:0.8508308456622617\n",
      "train loss:0.9321843054775507\n",
      "train loss:0.8633326953091847\n",
      "train loss:1.0702639301725478\n",
      "train loss:0.9315661006568406\n",
      "train loss:0.9786274315240929\n",
      "train loss:0.8574795074569722\n",
      "train loss:0.9725574520628038\n",
      "train loss:0.8626085057100044\n",
      "train loss:0.9356083677328038\n",
      "train loss:1.0142370630858162\n",
      "train loss:1.0743098500901958\n",
      "train loss:0.9857836187613015\n",
      "train loss:0.9886980142529874\n",
      "train loss:0.9903382813599397\n",
      "train loss:1.056358236508365\n",
      "train loss:0.9970470140658285\n",
      "train loss:0.9680180232144877\n",
      "train loss:1.188411329524326\n",
      "train loss:0.8142097507966116\n",
      "train loss:0.9980688042191957\n",
      "train loss:0.7973815389564899\n",
      "train loss:0.9598142240865822\n",
      "train loss:0.9089116855481104\n",
      "train loss:1.021964491746984\n",
      "train loss:0.937394655113593\n",
      "train loss:0.9995890929971355\n",
      "train loss:1.1392762949411512\n",
      "train loss:0.9281257266238317\n",
      "train loss:0.9953033786296654\n",
      "train loss:1.109580773987807\n",
      "train loss:1.0018851608802717\n",
      "train loss:1.0413997925519\n",
      "train loss:0.9494855759559279\n",
      "train loss:0.9109535308090102\n",
      "train loss:0.8112161346954478\n",
      "train loss:0.8745816730060108\n",
      "train loss:0.9509291369071201\n",
      "train loss:0.830520498525421\n",
      "train loss:1.0459828570358285\n",
      "train loss:1.0318106290946694\n",
      "train loss:0.9663095778531676\n",
      "train loss:0.7678473702109272\n",
      "train loss:0.8043386000698374\n",
      "train loss:0.9654260386337531\n",
      "train loss:0.8913062798193438\n",
      "train loss:1.095305552268197\n",
      "train loss:1.2132433355211192\n",
      "train loss:1.0011234811775678\n",
      "train loss:0.9027365399660654\n",
      "train loss:0.9711397185507529\n",
      "train loss:0.8956363806147445\n",
      "train loss:0.908189728190722\n",
      "train loss:0.9263975910348502\n",
      "train loss:1.0584761666106097\n",
      "train loss:0.9071020392117519\n",
      "train loss:0.7864444481392938\n",
      "train loss:1.159004005652174\n",
      "train loss:0.9794886965892325\n",
      "train loss:0.8972019116202337\n",
      "train loss:1.0857276715251607\n",
      "train loss:0.7788088073943501\n",
      "train loss:0.8294595566875096\n",
      "train loss:0.8229859531371911\n",
      "train loss:1.14305738977778\n",
      "train loss:0.9205131446820299\n",
      "train loss:0.9667604931078838\n",
      "train loss:0.8510674966909336\n",
      "train loss:1.1071801705172655\n",
      "train loss:0.8215635328471064\n",
      "train loss:1.1630334027479905\n",
      "train loss:0.9831550059717619\n",
      "train loss:0.8909456519390159\n",
      "train loss:0.8811760408134899\n",
      "train loss:0.9262030356720926\n",
      "train loss:0.9072039654480121\n",
      "train loss:1.0097625665245313\n",
      "train loss:0.9705139174225479\n",
      "train loss:1.0413264608054233\n",
      "train loss:1.0091941989101367\n",
      "train loss:0.9185928874118329\n",
      "train loss:0.8928126938022074\n",
      "train loss:0.8840065806017654\n",
      "train loss:1.1314254279840368\n",
      "train loss:0.9519297880266663\n",
      "train loss:0.9264842244228759\n",
      "train loss:0.9369292084730647\n",
      "train loss:0.934609517852467\n",
      "train loss:1.0729083958281844\n",
      "train loss:1.0339687788926333\n",
      "train loss:0.976395512196661\n",
      "train loss:1.031594627770887\n",
      "train loss:0.9110228259950245\n",
      "train loss:0.9650456239527558\n",
      "train loss:1.0094810909050729\n",
      "train loss:0.9171489596940888\n",
      "train loss:0.9542004840324262\n",
      "train loss:1.0837555225815718\n",
      "train loss:0.9974925931674367\n",
      "train loss:0.80771779481412\n",
      "train loss:0.8689488830832839\n",
      "train loss:0.8348878065627965\n",
      "train loss:0.9412642946572124\n",
      "train loss:0.8502643107113248\n",
      "train loss:0.8303287590902793\n",
      "train loss:1.0202417584805235\n",
      "train loss:0.9920501250336371\n",
      "train loss:1.0551827479562603\n",
      "train loss:0.7021521341099398\n",
      "train loss:0.9110883547174354\n",
      "train loss:1.0337949046611574\n",
      "train loss:0.7555211687161365\n",
      "train loss:0.8114520307866545\n",
      "train loss:1.0233314810518528\n",
      "train loss:0.7323854268612264\n",
      "train loss:0.937473962368138\n",
      "=== epoch:5, train acc:0.991, test acc:0.988 ===\n",
      "train loss:0.9512524935630338\n",
      "train loss:1.0410558380876898\n",
      "train loss:0.8110510752722432\n",
      "train loss:0.9181641918043749\n",
      "train loss:0.8740718612202164\n",
      "train loss:0.9124317167262128\n",
      "train loss:0.9724733564887275\n",
      "train loss:1.07895741736184\n",
      "train loss:0.8671491316266003\n",
      "train loss:0.9482095516575503\n",
      "train loss:0.8340986120464141\n",
      "train loss:0.7921441855036891\n",
      "train loss:0.9941534396572986\n",
      "train loss:0.7825164407392591\n",
      "train loss:0.7990581036290972\n",
      "train loss:0.9300814075257056\n",
      "train loss:0.940616015434859\n",
      "train loss:0.9994822034981392\n",
      "train loss:0.9754108358086003\n",
      "train loss:0.9094217976330803\n",
      "train loss:0.9189267303668706\n",
      "train loss:1.0706434697161635\n",
      "train loss:0.9653915696434966\n",
      "train loss:0.8889843366864986\n",
      "train loss:0.9783304438484152\n",
      "train loss:1.033411320019647\n",
      "train loss:0.8875727829073433\n",
      "train loss:0.8688969645804082\n",
      "train loss:1.0428439479589269\n",
      "train loss:0.9783559518587562\n",
      "train loss:0.9689941444420171\n",
      "train loss:0.9669220686761371\n",
      "train loss:0.992450303027982\n",
      "train loss:0.8763565812549349\n",
      "train loss:0.982492947606548\n",
      "train loss:0.9748823947305063\n",
      "train loss:1.040586903083238\n",
      "train loss:0.9346538318345536\n",
      "train loss:1.0822850685918697\n",
      "train loss:0.9735411366995624\n",
      "train loss:1.127831465376469\n",
      "train loss:0.9871674800041091\n",
      "train loss:0.8204847164557647\n",
      "train loss:0.8433347626899577\n",
      "train loss:0.848927549991378\n",
      "train loss:0.87496770888284\n",
      "train loss:0.7664258097359656\n",
      "train loss:0.8785075396021075\n",
      "train loss:0.7870056732592687\n",
      "train loss:1.0539156290153815\n",
      "train loss:0.9270849007697484\n",
      "train loss:0.9731893993171632\n",
      "train loss:1.0325598128950433\n",
      "train loss:0.8920621683000998\n",
      "train loss:0.7355502248612334\n",
      "train loss:0.9460101527490411\n",
      "train loss:0.8045121143041731\n",
      "train loss:0.9492508783174881\n",
      "train loss:0.9103319253652229\n",
      "train loss:0.8134700862383218\n",
      "train loss:0.9453804093154113\n",
      "train loss:0.8052492377724164\n",
      "train loss:1.0324852484604297\n",
      "train loss:0.7833398817351777\n",
      "train loss:1.1898499129391806\n",
      "train loss:0.7953219533034027\n",
      "train loss:0.9758005560282692\n",
      "train loss:0.868831324111499\n",
      "train loss:0.8577958042211412\n",
      "train loss:0.9800184537919061\n",
      "train loss:0.995968399095719\n",
      "train loss:0.6860889451608874\n",
      "train loss:0.8892813074753531\n",
      "train loss:0.981724581960694\n",
      "train loss:0.9328887527786542\n",
      "train loss:0.9605123709383873\n",
      "train loss:0.8651826726221779\n",
      "train loss:0.8701209150762311\n",
      "train loss:1.0409984819976357\n",
      "train loss:0.8816186686666814\n",
      "train loss:0.7839917644229317\n",
      "train loss:0.7537098946424883\n",
      "train loss:0.8447856561411267\n",
      "train loss:1.0528289673087967\n",
      "train loss:0.8459124907900375\n",
      "train loss:0.833860294224671\n",
      "train loss:1.073819809547074\n",
      "train loss:1.0067850076645821\n",
      "train loss:1.0303491658532555\n",
      "train loss:0.9620326050775678\n",
      "train loss:0.7944721750333286\n",
      "train loss:1.012235250175193\n",
      "train loss:0.9785421126251783\n",
      "train loss:0.8269443272538439\n",
      "train loss:1.0481684279518098\n",
      "train loss:0.8012118376488645\n",
      "train loss:1.0914569189488377\n",
      "train loss:0.7630012932279352\n",
      "train loss:0.7891131605398821\n",
      "train loss:1.0173364580459723\n",
      "train loss:0.85583469415181\n",
      "train loss:0.7988507008193966\n",
      "train loss:0.9881338610576325\n",
      "train loss:0.974051492465109\n",
      "train loss:1.1277474142012307\n",
      "train loss:0.7883214261165622\n",
      "train loss:0.8737652753002834\n",
      "train loss:0.9303635939024326\n",
      "train loss:0.8024005658740964\n",
      "train loss:0.8918247667920239\n",
      "train loss:0.9913241894073423\n",
      "train loss:1.0574333451161184\n",
      "train loss:1.1122846710507526\n",
      "train loss:0.9456734584780182\n",
      "train loss:0.9736313165235814\n",
      "train loss:0.8964019592551518\n",
      "train loss:0.7971930634086998\n",
      "train loss:0.901119224241549\n",
      "train loss:0.9532839453492177\n",
      "train loss:0.8421263598483432\n",
      "train loss:1.0212129957278693\n",
      "train loss:1.0704582797910707\n",
      "train loss:0.8582557295344188\n",
      "train loss:1.0654185185185774\n",
      "train loss:0.918846799926514\n",
      "train loss:0.9177096688713706\n",
      "train loss:1.0065726263276356\n",
      "train loss:0.9899973331726324\n",
      "train loss:0.973829091356321\n",
      "train loss:0.8571698475337288\n",
      "train loss:0.8388084198779933\n",
      "train loss:0.7931571613861637\n",
      "train loss:0.9399286716544728\n",
      "train loss:0.9587991674490566\n",
      "train loss:0.9524443972553158\n",
      "train loss:0.9703639380840808\n",
      "train loss:0.9234646194584147\n",
      "train loss:0.8991519298380979\n",
      "train loss:1.0750671162277294\n",
      "train loss:0.9700296360644342\n",
      "train loss:0.7298956783147935\n",
      "train loss:0.9902778641100154\n",
      "train loss:0.9984252970666345\n",
      "train loss:1.0200587748767693\n",
      "train loss:0.8749829588767492\n",
      "train loss:0.9844623593580241\n",
      "train loss:0.8113797434680764\n",
      "train loss:0.8577099475215018\n",
      "train loss:0.8462051987275724\n",
      "train loss:0.8855049295801684\n",
      "train loss:0.9230651359808961\n",
      "train loss:0.9816691735820744\n",
      "train loss:1.1572376909433522\n",
      "train loss:0.8295422880755692\n",
      "train loss:1.0151880364685328\n",
      "train loss:0.7732934710143549\n",
      "train loss:0.8221485145990333\n",
      "train loss:0.7270939322412613\n",
      "train loss:0.979691357475868\n",
      "train loss:0.8906573414691722\n",
      "train loss:1.0889851432177842\n",
      "train loss:1.1135043103073565\n",
      "train loss:0.980083567719649\n",
      "train loss:0.8919891827372756\n",
      "train loss:0.9801965420714467\n",
      "train loss:0.9644896234187331\n",
      "train loss:0.9107896636226357\n",
      "train loss:1.0374696165316244\n",
      "train loss:0.9857357136254605\n",
      "train loss:0.8423056258120463\n",
      "train loss:0.9837502330835807\n",
      "train loss:0.8440721932804006\n",
      "train loss:0.8516393512205823\n",
      "train loss:0.796882373828127\n",
      "train loss:0.8746964396105121\n",
      "train loss:0.9912060243981784\n",
      "train loss:0.8292465180692922\n",
      "train loss:0.9838963099348694\n",
      "train loss:0.9750546775019331\n",
      "train loss:0.9692240472866521\n",
      "train loss:1.0826665449313295\n",
      "train loss:0.8406686327909542\n",
      "train loss:0.9870173584825376\n",
      "train loss:0.8413070232715762\n",
      "train loss:0.8634534907455053\n",
      "train loss:0.9026031010799378\n",
      "train loss:0.8250960348726786\n",
      "train loss:1.060332849612931\n",
      "train loss:0.9412549624996625\n",
      "train loss:0.9382516707099715\n",
      "train loss:0.9844511401563035\n",
      "train loss:1.0157944754630972\n",
      "train loss:0.9792875147042982\n",
      "train loss:0.9183125634915428\n",
      "train loss:1.1386246757435081\n",
      "train loss:1.0848771524559957\n",
      "train loss:0.8846939693056736\n",
      "train loss:0.8984242442021277\n",
      "train loss:0.7617248531678834\n",
      "train loss:0.9955050314157478\n",
      "train loss:0.8882958869342596\n",
      "train loss:0.8238990490301894\n",
      "train loss:0.9579294517534186\n",
      "train loss:0.9609777491112139\n",
      "train loss:0.8853666257393324\n",
      "train loss:0.7948060660565599\n",
      "train loss:1.0061263523580768\n",
      "train loss:0.9272407835429936\n",
      "train loss:0.9135363939618195\n",
      "train loss:0.9463592772302384\n",
      "train loss:0.9687646064079312\n",
      "train loss:1.0298646449201616\n",
      "train loss:1.0882643868126247\n",
      "train loss:0.9129689374436541\n",
      "train loss:1.0150095263176724\n",
      "train loss:0.9058150032764304\n",
      "train loss:1.1116589644917259\n",
      "train loss:0.8463354922100362\n",
      "train loss:1.0073682359868708\n",
      "train loss:0.9529448521002435\n",
      "train loss:0.850661643700124\n",
      "train loss:0.9915911869247445\n",
      "train loss:0.8456773411932405\n",
      "train loss:0.9137683280308749\n",
      "train loss:1.0909607821031913\n",
      "train loss:1.0685415769431679\n",
      "train loss:0.82079696406973\n",
      "train loss:1.0939148303738022\n",
      "train loss:0.9299914923638047\n",
      "train loss:0.9949314209096901\n",
      "train loss:0.814680794370486\n",
      "train loss:0.9730170665917076\n",
      "train loss:0.9637405065882833\n",
      "train loss:1.0282122032602776\n",
      "train loss:0.9427114280041496\n",
      "train loss:0.7729186087011205\n",
      "train loss:0.9765597288744509\n",
      "train loss:0.8307663167257877\n",
      "train loss:0.9282513095259405\n",
      "train loss:0.9868300048266808\n",
      "train loss:1.0277422070380478\n",
      "train loss:0.9980485408280763\n",
      "train loss:1.049688292561418\n",
      "train loss:0.8724464370899766\n",
      "train loss:1.041516802883712\n",
      "train loss:1.02411569274913\n",
      "train loss:0.8697794863053003\n",
      "train loss:1.1467648969992614\n",
      "train loss:0.8965600615551026\n",
      "train loss:1.0643864294148428\n",
      "train loss:0.834749652230375\n",
      "train loss:0.867223327400776\n",
      "train loss:0.8267479296101906\n",
      "train loss:1.0418322102584814\n",
      "train loss:0.8854005445593802\n",
      "train loss:0.9364016992299081\n",
      "train loss:0.7385131017042348\n",
      "train loss:1.1148898960453288\n",
      "train loss:0.8926232158114121\n",
      "train loss:1.0549832877103842\n",
      "train loss:0.8948691959623983\n",
      "train loss:1.0696250989352913\n",
      "train loss:0.8372919431731437\n",
      "train loss:1.1089130575066073\n",
      "train loss:0.8808220144829926\n",
      "train loss:0.9340760277583245\n",
      "train loss:0.8520585033958423\n",
      "train loss:0.9494901227051085\n",
      "train loss:1.2376775876783919\n",
      "train loss:0.970791821929164\n",
      "train loss:1.0181887436317636\n",
      "train loss:0.9072609094108595\n",
      "train loss:0.9265261811147469\n",
      "train loss:0.9606045826328199\n",
      "train loss:0.8033038788282438\n",
      "train loss:0.9779653912777354\n",
      "train loss:1.0554092801815216\n",
      "train loss:0.8288604304362918\n",
      "train loss:1.0056405684996705\n",
      "train loss:1.0201370538504677\n",
      "train loss:1.1651173866356934\n",
      "train loss:0.7742250867002576\n",
      "train loss:0.9665583166762258\n",
      "train loss:0.9114064491191977\n",
      "train loss:0.985860049943325\n",
      "train loss:0.9999406344960619\n",
      "train loss:0.996977418799322\n",
      "train loss:0.9664163723504577\n",
      "train loss:0.90842864211197\n",
      "train loss:0.9055606261023789\n",
      "train loss:1.0763806956032242\n",
      "train loss:0.9436768223010958\n",
      "train loss:0.82656883921782\n",
      "train loss:0.9904686708659844\n",
      "train loss:1.0104251346045212\n",
      "train loss:0.8581477487753069\n",
      "train loss:0.9936858982846403\n",
      "train loss:0.8295459117184804\n",
      "train loss:1.0698625438259501\n",
      "train loss:1.106459098455593\n",
      "train loss:0.971682341179914\n",
      "train loss:1.082990631353562\n",
      "train loss:0.8993344268165608\n",
      "train loss:1.059293929130133\n",
      "train loss:0.9943198392072432\n",
      "train loss:0.9155552127759127\n",
      "train loss:0.9503753744846847\n",
      "train loss:0.9989398932474003\n",
      "train loss:1.0694094333355215\n",
      "train loss:0.9569434942436237\n",
      "train loss:0.819089979383645\n",
      "train loss:0.7234291725574397\n",
      "train loss:0.9629821388805568\n",
      "train loss:1.0471942867578072\n",
      "train loss:0.7195730025595278\n",
      "train loss:0.8632007986294395\n",
      "train loss:1.0430742834895352\n",
      "train loss:0.9940514171820533\n",
      "train loss:0.9347381989445522\n",
      "train loss:0.8090737437098706\n",
      "train loss:0.9595563780242529\n",
      "train loss:0.8534292707261809\n",
      "train loss:0.8928159886161433\n",
      "train loss:1.124745271732429\n",
      "train loss:0.8846035459030994\n",
      "train loss:0.9694208598980256\n",
      "train loss:0.9182615972045955\n",
      "train loss:0.9298990198086728\n",
      "train loss:0.9013601165887998\n",
      "train loss:0.9441279400549741\n",
      "train loss:1.0316798835651693\n",
      "train loss:0.9428641151021169\n",
      "train loss:0.9194353200587915\n",
      "train loss:0.8127359971621363\n",
      "train loss:0.9535644468862146\n",
      "train loss:1.0111135996994582\n",
      "train loss:0.8993847758788224\n",
      "train loss:0.8737940298248357\n",
      "train loss:1.0132970146482945\n",
      "train loss:0.9719326174572716\n",
      "train loss:0.8490526875372056\n",
      "train loss:0.9100583412049343\n",
      "train loss:0.8531997804306998\n",
      "train loss:0.8612670724719697\n",
      "train loss:0.8859423254364707\n",
      "train loss:0.9260601935105585\n",
      "train loss:0.9035703592643384\n",
      "train loss:0.9697603441306317\n",
      "train loss:1.0289557768767068\n",
      "train loss:1.0226067146870155\n",
      "train loss:0.7675699538933854\n",
      "train loss:1.1285049910311664\n",
      "train loss:0.8331179656837671\n",
      "train loss:1.000000401903424\n",
      "train loss:0.7001784044180818\n",
      "train loss:0.8155143470445924\n",
      "train loss:0.9885537588085769\n",
      "train loss:0.958671803831913\n",
      "train loss:0.8569404015805542\n",
      "train loss:0.99488014470227\n",
      "train loss:0.8192145090549066\n",
      "train loss:1.0059799516155785\n",
      "train loss:0.9276855543488824\n",
      "train loss:0.9641966228514478\n",
      "train loss:0.8740491972470277\n",
      "train loss:0.9582657200064113\n",
      "train loss:0.8180443772142059\n",
      "train loss:0.9201920269139896\n",
      "train loss:1.02702534221106\n",
      "train loss:0.975588298289786\n",
      "train loss:0.8911371118290863\n",
      "train loss:0.9080854869115972\n",
      "train loss:0.7263732283895851\n",
      "train loss:0.8739501410385141\n",
      "train loss:0.9261081423841935\n",
      "train loss:1.059672611390079\n",
      "train loss:1.042678449199543\n",
      "train loss:0.9131426567825558\n",
      "train loss:0.9020504755843761\n",
      "train loss:0.8509576701532496\n",
      "train loss:1.0574492709539174\n",
      "train loss:0.9026538762035693\n",
      "train loss:0.8376995564550198\n",
      "train loss:0.9380342759383414\n",
      "train loss:0.9454152271907248\n",
      "train loss:0.953951186202221\n",
      "train loss:0.8672713271437342\n",
      "train loss:0.934910635668068\n",
      "train loss:1.020517733102529\n",
      "train loss:0.7537965065798439\n",
      "train loss:0.9060015073447353\n",
      "train loss:0.659999173570636\n",
      "train loss:0.8886934536892909\n",
      "train loss:0.9260080508093251\n",
      "train loss:0.9417591817815927\n",
      "train loss:1.0460738359318955\n",
      "train loss:0.9629869664817722\n",
      "train loss:1.0503803865296952\n",
      "train loss:1.0986667976204307\n",
      "train loss:0.9710880113413869\n",
      "train loss:0.8971176077399377\n",
      "train loss:0.8871871611697512\n",
      "train loss:0.9040214955938548\n",
      "train loss:0.8151055770287576\n",
      "train loss:0.9394163921807998\n",
      "train loss:0.9117604892410397\n",
      "train loss:0.9264187962965793\n",
      "train loss:1.0957092816681646\n",
      "train loss:0.9083462927751659\n",
      "train loss:1.1287769828802825\n",
      "train loss:0.7226706647479212\n",
      "train loss:0.8204345054623414\n",
      "train loss:1.0215750829673316\n",
      "train loss:1.030731410356832\n",
      "train loss:1.036493531661468\n",
      "train loss:0.7222983547666854\n",
      "train loss:1.0130785851730417\n",
      "train loss:0.9878405098598522\n",
      "train loss:1.0369995107836478\n",
      "train loss:1.0255092151363605\n",
      "train loss:0.8856903415141821\n",
      "train loss:0.8611290540865363\n",
      "train loss:1.0667012040479233\n",
      "train loss:0.9977535800511798\n",
      "train loss:0.8045622858479272\n",
      "train loss:0.9285744176062255\n",
      "train loss:0.916882444648225\n",
      "train loss:0.658831786693347\n",
      "train loss:0.8741365132485903\n",
      "train loss:0.8269654622490488\n",
      "train loss:0.8383715630441361\n",
      "train loss:0.8292521023812853\n",
      "train loss:1.2104375054143952\n",
      "train loss:0.9719021638830337\n",
      "train loss:1.0100418341746604\n",
      "train loss:0.8193216153998512\n",
      "train loss:1.0063688902318058\n",
      "train loss:0.771164732996193\n",
      "train loss:0.9561498236250963\n",
      "train loss:0.9455740448959302\n",
      "train loss:0.9020898551395536\n",
      "train loss:0.964667144224617\n",
      "train loss:1.0229393494821093\n",
      "train loss:1.0157047154949692\n",
      "train loss:0.9197026689847376\n",
      "train loss:1.069904198284669\n",
      "train loss:0.9480424581088853\n",
      "train loss:0.7439780773950541\n",
      "train loss:0.9662530413027042\n",
      "train loss:0.8967670127032739\n",
      "train loss:1.1461338970147876\n",
      "train loss:1.0275609569685293\n",
      "train loss:0.8955327935030085\n",
      "train loss:0.9301853006054975\n",
      "train loss:1.0556937566888491\n",
      "train loss:0.7913750150231845\n",
      "train loss:0.8862376652642204\n",
      "train loss:0.840967863107946\n",
      "train loss:1.0286809947568851\n",
      "train loss:0.936159859228134\n",
      "train loss:0.8907187102642444\n",
      "train loss:1.1182579381697544\n",
      "train loss:0.9943373586208706\n",
      "train loss:0.922332164319519\n",
      "train loss:0.9053343924368711\n",
      "train loss:1.0862904703248695\n",
      "train loss:0.9114980101962864\n",
      "train loss:1.1203921021748955\n",
      "train loss:0.8607662622042604\n",
      "train loss:0.8353449577821727\n",
      "train loss:0.9704883292896982\n",
      "train loss:0.9418962213598776\n",
      "train loss:0.8397530622952404\n",
      "train loss:1.0436820902122692\n",
      "train loss:0.9860084213531265\n",
      "train loss:0.9753946558621166\n",
      "train loss:1.171000838468102\n",
      "train loss:0.9208010834930009\n",
      "train loss:1.0934509115172262\n",
      "train loss:1.009416303634019\n",
      "train loss:1.100974674622747\n",
      "train loss:0.7439936080896744\n",
      "train loss:0.8794009324266131\n",
      "train loss:1.0740923406131353\n",
      "train loss:0.9607032850938743\n",
      "train loss:0.8796464913477806\n",
      "train loss:1.0754970976194198\n",
      "train loss:1.0622790378957678\n",
      "train loss:0.926759959045222\n",
      "train loss:1.0130304637026064\n",
      "train loss:0.9479820256820072\n",
      "train loss:0.9467320981938394\n",
      "train loss:0.869758358157559\n",
      "train loss:0.8503974046242462\n",
      "train loss:0.9199003372579416\n",
      "train loss:0.9250260278322717\n",
      "train loss:0.7990010804005169\n",
      "train loss:0.930933931543861\n",
      "train loss:0.8728117460836801\n",
      "train loss:0.7827212162316803\n",
      "train loss:0.7843855333667782\n",
      "train loss:0.7905610362627109\n",
      "train loss:1.1534933843749668\n",
      "train loss:0.9557553775979362\n",
      "train loss:0.9410948202649894\n",
      "train loss:0.8205767701011619\n",
      "train loss:0.9385974792691285\n",
      "train loss:0.8058778011489574\n",
      "train loss:0.9656164145814172\n",
      "train loss:1.012152696486634\n",
      "train loss:0.9597305454154577\n",
      "train loss:0.7759310872236352\n",
      "train loss:0.8571924451143024\n",
      "train loss:1.0126355081724805\n",
      "train loss:0.9704609148241358\n",
      "train loss:1.1242203052083368\n",
      "train loss:0.8967763989838461\n",
      "train loss:0.8496803164183439\n",
      "train loss:0.883978268434045\n",
      "train loss:0.9817892074891055\n",
      "train loss:0.8070579685105757\n",
      "train loss:0.7594399405699604\n",
      "train loss:0.9849678290288773\n",
      "train loss:0.8938319502427963\n",
      "train loss:0.9537589171880495\n",
      "train loss:1.0557147149764765\n",
      "train loss:0.9785154852651303\n",
      "train loss:1.0032803832391797\n",
      "train loss:1.1042179648804296\n",
      "train loss:1.0656568696064845\n",
      "train loss:1.0100351082226457\n",
      "train loss:1.154307506964322\n",
      "train loss:0.7352197993436336\n",
      "train loss:0.9474369438744447\n",
      "train loss:0.8893902444854439\n",
      "train loss:0.9191847415338142\n",
      "train loss:0.9769068746142807\n",
      "train loss:0.7712424191157008\n",
      "train loss:0.8268375902817721\n",
      "train loss:1.028077918272621\n",
      "train loss:0.868973502655818\n",
      "train loss:0.9428753945348768\n",
      "train loss:0.9547155784566718\n",
      "train loss:0.9729489943513524\n",
      "train loss:0.87624483950163\n",
      "train loss:1.2504948253949817\n",
      "train loss:1.023740968257418\n",
      "train loss:0.9930152997279187\n",
      "train loss:0.8788397347260797\n",
      "train loss:1.0040371583193428\n",
      "train loss:0.855167690974574\n",
      "train loss:0.907671654729857\n",
      "train loss:0.9438101521008025\n",
      "train loss:0.8924149717412032\n",
      "train loss:1.018569084149046\n",
      "train loss:1.0819845197748899\n",
      "train loss:0.9503608128369666\n",
      "train loss:1.0253289911061876\n",
      "train loss:0.8904120820956577\n",
      "train loss:0.9406497548136796\n",
      "train loss:0.9484061748939691\n",
      "train loss:0.8745455896373997\n",
      "train loss:1.0162050992290108\n",
      "train loss:0.9229265963934989\n",
      "train loss:0.9770272952855521\n",
      "train loss:0.916339127693847\n",
      "train loss:1.0918390998843883\n",
      "train loss:0.9727162761268715\n",
      "train loss:0.826598152145815\n",
      "train loss:0.9873131081899615\n",
      "train loss:0.7231055423018199\n",
      "train loss:0.7753712855158181\n",
      "train loss:1.011559376701621\n",
      "train loss:0.9621794136311403\n",
      "train loss:0.9734131276366804\n",
      "train loss:0.8317777817095907\n",
      "train loss:0.9216683382861609\n",
      "train loss:0.88941423853399\n",
      "train loss:0.8641957849494486\n",
      "train loss:0.9846882344788505\n",
      "train loss:1.0270303901739721\n",
      "train loss:1.0202476614128217\n",
      "train loss:0.9766427143179202\n",
      "train loss:0.790258486754054\n",
      "train loss:1.0564037626221363\n",
      "train loss:0.9164570097067525\n",
      "train loss:0.9753028616207022\n",
      "train loss:0.9376373981338577\n",
      "train loss:0.9515701679279716\n",
      "train loss:1.0384992110766003\n",
      "train loss:0.9401286407849948\n",
      "train loss:0.9010169132473882\n",
      "train loss:0.7766110571179499\n",
      "train loss:0.7749185911649746\n",
      "train loss:0.8778296185818917\n",
      "train loss:0.9084909386953189\n",
      "train loss:1.1128244575230253\n",
      "train loss:0.7944087026569568\n",
      "train loss:1.0140907841181488\n",
      "train loss:0.9174652471011013\n",
      "=== epoch:6, train acc:0.991, test acc:0.989 ===\n",
      "train loss:0.8847991192654547\n",
      "train loss:0.9107459823379525\n",
      "train loss:1.0007633739339312\n",
      "train loss:0.9198026906559652\n",
      "train loss:0.8809805949883796\n",
      "train loss:0.9436906993375496\n",
      "train loss:1.1249427278790993\n",
      "train loss:0.9623220225920402\n",
      "train loss:0.79789963183091\n",
      "train loss:0.9948651500630692\n",
      "train loss:0.8734234628501423\n",
      "train loss:1.0148649817207303\n",
      "train loss:0.9640500920874786\n",
      "train loss:0.9687696023432448\n",
      "train loss:0.95657638862193\n",
      "train loss:1.016350369464185\n",
      "train loss:0.8635067175404201\n",
      "train loss:0.978116967366491\n",
      "train loss:0.9781610845087348\n",
      "train loss:0.945411147403672\n",
      "train loss:1.000335512468597\n",
      "train loss:0.9631400770178391\n",
      "train loss:0.9278554234538493\n",
      "train loss:0.9926636811255679\n",
      "train loss:0.9366631448233302\n",
      "train loss:0.9721067092314202\n",
      "train loss:1.0240095880299203\n",
      "train loss:1.0619764247888503\n",
      "train loss:0.9735646353534058\n",
      "train loss:1.0464369832415705\n",
      "train loss:1.1474349006039501\n",
      "train loss:0.9970194641969301\n",
      "train loss:1.0367605108190103\n",
      "train loss:0.8652534358660965\n",
      "train loss:1.0279473215949728\n",
      "train loss:0.8352540979990875\n",
      "train loss:0.801051431957824\n",
      "train loss:1.1230156176680843\n",
      "train loss:0.8906656533256833\n",
      "train loss:0.8344353611583365\n",
      "train loss:1.071513502414347\n",
      "train loss:0.9578470506860844\n",
      "train loss:0.8132785456323727\n",
      "train loss:1.045428766639623\n",
      "train loss:1.002788980263007\n",
      "train loss:1.028536066317078\n",
      "train loss:0.7518197714071202\n",
      "train loss:0.7982613472068968\n",
      "train loss:0.9482228809153592\n",
      "train loss:1.0125424955598818\n",
      "train loss:0.9411080986695977\n",
      "train loss:0.9963900543890867\n",
      "train loss:0.936580638785707\n",
      "train loss:0.9076237768773376\n",
      "train loss:0.8700050677321187\n",
      "train loss:0.8221957191717402\n",
      "train loss:1.0185857353395178\n",
      "train loss:0.9151119331446743\n",
      "train loss:0.8865255163934083\n",
      "train loss:0.9418323451300813\n",
      "train loss:0.8649274409734682\n",
      "train loss:0.951910417683873\n",
      "train loss:0.831490393568878\n",
      "train loss:0.972162956377278\n",
      "train loss:1.006635195174294\n",
      "train loss:1.14427656100598\n",
      "train loss:0.9221045655464812\n",
      "train loss:0.8417805007668288\n",
      "train loss:0.8661661237964179\n",
      "train loss:1.0466284566665138\n",
      "train loss:0.9502735950885173\n",
      "train loss:0.8659454073241984\n",
      "train loss:0.9520249227066959\n",
      "train loss:0.9497697699159339\n",
      "train loss:0.988869315132036\n",
      "train loss:0.88031070616394\n",
      "train loss:1.0731842586158618\n",
      "train loss:0.8591623887892119\n",
      "train loss:0.9029838628343636\n",
      "train loss:0.9904724413284073\n",
      "train loss:0.8047318698037617\n",
      "train loss:0.9859693672748694\n",
      "train loss:0.9122600808105001\n",
      "train loss:1.064081897252022\n",
      "train loss:0.9241348267037217\n",
      "train loss:0.960833858671311\n",
      "train loss:1.008036431495497\n",
      "train loss:0.9300991404009699\n",
      "train loss:0.9446802388071474\n",
      "train loss:0.7864688146329023\n",
      "train loss:1.015158974327228\n",
      "train loss:0.7520102807605579\n",
      "train loss:1.042758204028334\n",
      "train loss:0.8345112075434951\n",
      "train loss:1.0058843767328405\n",
      "train loss:0.9805206873237912\n",
      "train loss:0.9645809671232144\n",
      "train loss:0.7600021492387331\n",
      "train loss:0.8789396726018472\n",
      "train loss:0.8604117269164719\n",
      "train loss:0.9464120130319641\n",
      "train loss:0.8667885743271279\n",
      "train loss:1.0663907898300524\n",
      "train loss:1.0790050414223904\n",
      "train loss:0.9283976050748605\n",
      "train loss:0.9432467333567502\n",
      "train loss:0.9375925126768445\n",
      "train loss:0.8899220221245214\n",
      "train loss:1.022196781531575\n",
      "train loss:1.0099174272437557\n",
      "train loss:0.8256328394151414\n",
      "train loss:0.982736615288\n",
      "train loss:0.8197415746581838\n",
      "train loss:0.9489599474288782\n",
      "train loss:0.9753822268935332\n",
      "train loss:1.1941481244413337\n",
      "train loss:0.9214564517314252\n",
      "train loss:0.8834921137741759\n",
      "train loss:1.1731934451267572\n",
      "train loss:1.088591729776587\n",
      "train loss:1.0537830386945801\n",
      "train loss:0.6552380646114195\n",
      "train loss:1.1336875823969177\n",
      "train loss:0.905919874862979\n",
      "train loss:0.7637427681055321\n",
      "train loss:0.9772276689387858\n",
      "train loss:0.8899702104793843\n",
      "train loss:0.9852237827082331\n",
      "train loss:0.9303430001348264\n",
      "train loss:0.8917949328751562\n",
      "train loss:0.9235333338526069\n",
      "train loss:0.8133516707791568\n",
      "train loss:0.9190581371582439\n",
      "train loss:0.8311804720089397\n",
      "train loss:0.7356590306525069\n",
      "train loss:0.9890134779250594\n",
      "train loss:0.940211147380772\n",
      "train loss:0.9194371222543241\n",
      "train loss:0.8571193305157476\n",
      "train loss:1.0146607091277011\n",
      "train loss:1.0289402812567054\n",
      "train loss:0.8648256977938366\n",
      "train loss:0.8634243355773121\n",
      "train loss:1.0910408379354666\n",
      "train loss:0.9137606760194592\n",
      "train loss:0.8124887830582475\n",
      "train loss:1.1159430078106123\n",
      "train loss:0.7753269418842464\n",
      "train loss:0.7371091875048221\n",
      "train loss:0.9923214708013802\n",
      "train loss:0.7724824749069451\n",
      "train loss:1.0419722490097774\n",
      "train loss:0.7593527124088095\n",
      "train loss:1.0280689428134424\n",
      "train loss:0.9570328879162088\n",
      "train loss:0.9526657426763656\n",
      "train loss:1.0670399841321696\n",
      "train loss:0.8951189690920175\n",
      "train loss:0.9701937696519639\n",
      "train loss:0.9874195249230635\n",
      "train loss:0.9742211507817842\n",
      "train loss:1.0319133433655399\n",
      "train loss:1.028972383938368\n",
      "train loss:0.8673976025152156\n",
      "train loss:0.8707877946255428\n",
      "train loss:0.9100900105527431\n",
      "train loss:0.9572440062952231\n",
      "train loss:0.9923606362030213\n",
      "train loss:1.1371165235306773\n",
      "train loss:0.9157763465628227\n",
      "train loss:0.9211703923626545\n",
      "train loss:1.0066036361123798\n",
      "train loss:0.9173048965080565\n",
      "train loss:0.8202874872291344\n",
      "train loss:0.8083769063734174\n",
      "train loss:0.8740224549950664\n",
      "train loss:0.9168170187363814\n",
      "train loss:0.9347755649491656\n",
      "train loss:0.8559080835189903\n",
      "train loss:0.9175658456840299\n",
      "train loss:0.9098021277012616\n",
      "train loss:0.9460309557635637\n",
      "train loss:0.7767249766482063\n",
      "train loss:0.968712809685057\n",
      "train loss:0.8460649194240807\n",
      "train loss:0.9149730663491188\n",
      "train loss:0.9062881602397407\n",
      "train loss:0.9503289893042637\n",
      "train loss:0.8996073670331554\n",
      "train loss:0.9483366363617156\n",
      "train loss:0.8929015264356402\n",
      "train loss:0.8560401441948505\n",
      "train loss:0.851273487233152\n",
      "train loss:0.8632594109052103\n",
      "train loss:0.6586603427925116\n",
      "train loss:0.9271136933504969\n",
      "train loss:0.9357144714219828\n",
      "train loss:0.8510909617648559\n",
      "train loss:0.9690285812806959\n",
      "train loss:0.8348544462944002\n",
      "train loss:1.1302156180927891\n",
      "train loss:0.7679631971703614\n",
      "train loss:0.8609406219874906\n",
      "train loss:1.0598021643120896\n",
      "train loss:1.0104283102839628\n",
      "train loss:0.9826141034533313\n",
      "train loss:1.0036818859276193\n",
      "train loss:0.9153532882435228\n",
      "train loss:0.9068780569027888\n",
      "train loss:0.908706286211922\n",
      "train loss:0.983945178269436\n",
      "train loss:0.9892372877757688\n",
      "train loss:0.990185949257669\n",
      "train loss:0.9687852392262939\n",
      "train loss:0.8487110878159585\n",
      "train loss:0.803851728407315\n",
      "train loss:0.876870559755956\n",
      "train loss:0.9944955630921427\n",
      "train loss:0.8714252306498719\n",
      "train loss:1.004234051230758\n",
      "train loss:0.7459797840805603\n",
      "train loss:0.8234125667612546\n",
      "train loss:0.8701272392354288\n",
      "train loss:0.8943922362304236\n",
      "train loss:0.9685819435856869\n",
      "train loss:0.9232744551486352\n",
      "train loss:0.885514175449108\n",
      "train loss:0.9931905726770043\n",
      "train loss:0.8895068933195853\n",
      "train loss:0.9021966829259221\n",
      "train loss:0.9042395044862432\n",
      "train loss:0.9855444396538711\n",
      "train loss:0.8221868082127678\n",
      "train loss:0.9863904248361434\n",
      "train loss:1.0457990118929201\n",
      "train loss:0.8803787138791851\n",
      "train loss:0.8321758294503048\n",
      "train loss:0.8220807077933788\n",
      "train loss:0.8940073717521758\n",
      "train loss:0.8219787494983828\n",
      "train loss:0.9417207348224954\n",
      "train loss:1.0063845861887792\n",
      "train loss:0.8849172041739795\n",
      "train loss:1.0220815896490871\n",
      "train loss:1.0900584730565845\n",
      "train loss:0.9875699328309996\n",
      "train loss:0.9863230910553723\n",
      "train loss:0.9383084355506175\n",
      "train loss:0.7924827284858657\n",
      "train loss:0.9388672187203242\n",
      "train loss:0.9469007801938422\n",
      "train loss:0.8222927711245454\n",
      "train loss:0.8676379832308428\n",
      "train loss:0.93771702590773\n",
      "train loss:0.7684668627491433\n",
      "train loss:0.890760854406625\n",
      "train loss:0.9170627498069222\n",
      "train loss:0.8226846533031105\n",
      "train loss:0.8500454189407357\n",
      "train loss:1.0078439560218184\n",
      "train loss:0.9196953426498216\n",
      "train loss:0.904907476629162\n",
      "train loss:0.8657234664924739\n",
      "train loss:0.8538733814661345\n",
      "train loss:0.9434532757288489\n",
      "train loss:0.8223758885719613\n",
      "train loss:0.8540848618804394\n",
      "train loss:0.9569997803336671\n",
      "train loss:0.9172066091950222\n",
      "train loss:0.7515569221515871\n",
      "train loss:1.0132447783638634\n",
      "train loss:0.9749629674031597\n",
      "train loss:0.9273884824589824\n",
      "train loss:1.0458187958068406\n",
      "train loss:1.005347531351336\n",
      "train loss:0.7884898165362864\n",
      "train loss:0.8812950204735692\n",
      "train loss:0.9163787834477191\n",
      "train loss:0.7552935609021106\n",
      "train loss:0.8661882710414608\n",
      "train loss:1.0841689845201896\n",
      "train loss:0.901307873193863\n",
      "train loss:1.0003674204884836\n",
      "train loss:0.8927855129250629\n",
      "train loss:1.1142679424607573\n",
      "train loss:0.9327091346795422\n",
      "train loss:0.9071143061590102\n",
      "train loss:0.8969947383668071\n",
      "train loss:1.0819017218205154\n",
      "train loss:0.8971372618062687\n",
      "train loss:0.804799809600094\n",
      "train loss:0.9838457192092079\n",
      "train loss:0.9111348626063362\n",
      "train loss:0.9165513187665313\n",
      "train loss:1.040473231892349\n",
      "train loss:1.0222431225773896\n",
      "train loss:0.7926397897280232\n",
      "train loss:0.9288612160742596\n",
      "train loss:1.0486776208584867\n",
      "train loss:0.8864095154454135\n",
      "train loss:0.9652232129355229\n",
      "train loss:0.855061086794409\n",
      "train loss:0.8914226402336193\n",
      "train loss:1.041774038961394\n",
      "train loss:0.9916483913993741\n",
      "train loss:1.2245796728557474\n",
      "train loss:0.8799609014045608\n",
      "train loss:0.7756161289164727\n",
      "train loss:0.9377808276131765\n",
      "train loss:0.8312591933403479\n",
      "train loss:0.9098742175856732\n",
      "train loss:1.123290560241219\n",
      "train loss:0.7443311368812178\n",
      "train loss:1.1073315369765087\n",
      "train loss:1.0049276643169278\n",
      "train loss:0.7443471783226967\n",
      "train loss:0.8224290463097735\n",
      "train loss:0.9617065026564936\n",
      "train loss:1.0126872612734419\n",
      "train loss:0.8636365957577605\n",
      "train loss:0.8558637120257799\n",
      "train loss:1.0328595051958214\n",
      "train loss:1.104505762129674\n",
      "train loss:0.8900294889967526\n",
      "train loss:0.9902791897311607\n",
      "train loss:0.8193186974673045\n",
      "train loss:0.9951840512952291\n",
      "train loss:0.9370461946073635\n",
      "train loss:1.0205501779987187\n",
      "train loss:0.9144463118587103\n",
      "train loss:1.0153375238722027\n",
      "train loss:0.7573040615075403\n",
      "train loss:0.9953043125583838\n",
      "train loss:0.9537930711275169\n",
      "train loss:0.9569389592277915\n",
      "train loss:0.9866756155868858\n",
      "train loss:0.7540896292948932\n",
      "train loss:0.8617904106062175\n",
      "train loss:0.7841451318910337\n",
      "train loss:0.88766702664467\n",
      "train loss:0.9123480880898572\n",
      "train loss:1.016930898108176\n",
      "train loss:0.7865403777266118\n",
      "train loss:0.9657026738132456\n",
      "train loss:0.9138559064596214\n",
      "train loss:0.9371139694326076\n",
      "train loss:0.9617502289380156\n",
      "train loss:0.9424256678065386\n",
      "train loss:0.9862550810680227\n",
      "train loss:0.8072423222428107\n",
      "train loss:0.9430267100443401\n",
      "train loss:0.9979775259607392\n",
      "train loss:1.1057081278539216\n",
      "train loss:0.8569389359991088\n",
      "train loss:0.8483936240849853\n",
      "train loss:0.8616580054398263\n",
      "train loss:0.8150606860440923\n",
      "train loss:0.8179296558104165\n",
      "train loss:1.1441100928062975\n",
      "train loss:0.9451398257791742\n",
      "train loss:0.8271525334601192\n",
      "train loss:0.8423768859353368\n",
      "train loss:0.872278682731047\n",
      "train loss:0.9788355958822901\n",
      "train loss:0.9916482607886035\n",
      "train loss:0.8771631004732429\n",
      "train loss:0.8509201224716287\n",
      "train loss:0.8993663397044823\n",
      "train loss:0.9421550743514422\n",
      "train loss:1.0969935216983673\n",
      "train loss:1.1073581095830043\n",
      "train loss:1.0730479490489866\n",
      "train loss:0.9581608886867211\n",
      "train loss:1.021833044106608\n",
      "train loss:1.108085073529239\n",
      "train loss:0.9213620249549939\n",
      "train loss:0.891154495851079\n",
      "train loss:0.9114911738671632\n",
      "train loss:0.8960321500434371\n",
      "train loss:0.9768767482397561\n",
      "train loss:0.9102060924997953\n",
      "train loss:0.9115617553225251\n",
      "train loss:0.9724479103242323\n",
      "train loss:1.0568981408422873\n",
      "train loss:0.9046326065967201\n",
      "train loss:1.006397864158684\n",
      "train loss:0.9469511235789164\n",
      "train loss:0.9565700794868328\n",
      "train loss:1.0766771204301884\n",
      "train loss:0.8097758210053057\n",
      "train loss:0.8932288023628334\n",
      "train loss:0.9670175346071307\n",
      "train loss:0.800020417751534\n",
      "train loss:0.9564490597594666\n",
      "train loss:0.8769177791629112\n",
      "train loss:1.0067724077198195\n",
      "train loss:0.860001439890388\n",
      "train loss:0.9434803292832324\n",
      "train loss:1.0461152305894361\n",
      "train loss:0.878030716239803\n",
      "train loss:0.8286162113848293\n",
      "train loss:0.8056968586968628\n",
      "train loss:0.8737180454927095\n",
      "train loss:0.9137369711410526\n",
      "train loss:0.8861631273859757\n",
      "train loss:0.8424838367777524\n",
      "train loss:0.9102103774558685\n",
      "train loss:0.7611881233235609\n",
      "train loss:0.7802463970212037\n",
      "train loss:0.9551064095871774\n",
      "train loss:0.7590445141487153\n",
      "train loss:0.9485044069086028\n",
      "train loss:0.9260891210854267\n",
      "train loss:0.8376277359349446\n",
      "train loss:0.7276897948047164\n",
      "train loss:0.9847462409474749\n",
      "train loss:0.858911775358536\n",
      "train loss:0.9444196179967945\n",
      "train loss:0.8469578113420932\n",
      "train loss:0.8489313333734831\n",
      "train loss:0.8196303588647821\n",
      "train loss:0.893619804744135\n",
      "train loss:0.9895108033558622\n",
      "train loss:0.9254045296515129\n",
      "train loss:0.8499136244758102\n",
      "train loss:0.8849132203674454\n",
      "train loss:0.878393248421927\n",
      "train loss:0.8311334357548463\n",
      "train loss:0.8704506044436066\n",
      "train loss:0.8432192547045563\n",
      "train loss:0.8115505210179638\n",
      "train loss:1.0139105930673367\n",
      "train loss:0.8769159871113339\n",
      "train loss:0.8989509147240843\n",
      "train loss:0.740312599708358\n",
      "train loss:0.8309077313498398\n",
      "train loss:1.0711390797403777\n",
      "train loss:0.8664961020290001\n",
      "train loss:0.8438137846891032\n",
      "train loss:0.8906130759945605\n",
      "train loss:1.0512041709195439\n",
      "train loss:0.8673083615478079\n",
      "train loss:0.8319963856593293\n",
      "train loss:1.0629403794389527\n",
      "train loss:1.0055756884182332\n",
      "train loss:0.9448723096808449\n",
      "train loss:0.927683239269532\n",
      "train loss:0.7465419052889121\n",
      "train loss:0.8066097236543159\n",
      "train loss:1.0326997787535424\n",
      "train loss:0.9376681823934515\n",
      "train loss:0.754256018052322\n",
      "train loss:0.9547658627704249\n",
      "train loss:0.8516372787496802\n",
      "train loss:1.0822201809010934\n",
      "train loss:0.8569968764706656\n",
      "train loss:1.0353569717991\n",
      "train loss:0.9209726983124827\n",
      "train loss:0.8617437022452019\n",
      "train loss:0.9609831414690657\n",
      "train loss:0.9546714101044239\n",
      "train loss:0.9350185328421864\n",
      "train loss:1.0894885890570096\n",
      "train loss:0.9181937914905507\n",
      "train loss:1.0395042704196917\n",
      "train loss:1.0081683410321556\n",
      "train loss:0.783876785067683\n",
      "train loss:1.0499515092122214\n",
      "train loss:0.9626327020679852\n",
      "train loss:0.8478312596256334\n",
      "train loss:0.8644745415069403\n",
      "train loss:1.0050715078378167\n",
      "train loss:0.9052413120472356\n",
      "train loss:0.8767527327312556\n",
      "train loss:0.9933806494056179\n",
      "train loss:0.8698171673087898\n",
      "train loss:0.9985913554576625\n",
      "train loss:0.7618667158957119\n",
      "train loss:0.9531191231629578\n",
      "train loss:0.9314637476514807\n",
      "train loss:0.8270866204767837\n",
      "train loss:0.9506723908235718\n",
      "train loss:0.9324031831861688\n",
      "train loss:0.9967619872034394\n",
      "train loss:0.725487878994459\n",
      "train loss:0.8262564402617459\n",
      "train loss:0.7963431585594201\n",
      "train loss:0.8849114016627122\n",
      "train loss:0.8862565062447844\n",
      "train loss:1.1100719215496604\n",
      "train loss:1.004543880387564\n",
      "train loss:0.9876401345005767\n",
      "train loss:0.8932088976896816\n",
      "train loss:0.9212383918298493\n",
      "train loss:0.8136287709776964\n",
      "train loss:1.038775688459125\n",
      "train loss:0.9082632507071007\n",
      "train loss:0.9647538946443258\n",
      "train loss:1.065991857383663\n",
      "train loss:0.8993254483739115\n",
      "train loss:0.9588343570711411\n",
      "train loss:0.8107620974563389\n",
      "train loss:1.1887405889725424\n",
      "train loss:0.9060356812869156\n",
      "train loss:0.863003614043461\n",
      "train loss:0.8584112718259543\n",
      "train loss:0.9395727340953057\n",
      "train loss:1.041112517895183\n",
      "train loss:0.9124676848030775\n",
      "train loss:0.9488205557054235\n",
      "train loss:0.9914081425567407\n",
      "train loss:0.9520482404505803\n",
      "train loss:0.6581637556186684\n",
      "train loss:0.969978519055504\n",
      "train loss:0.820493702927322\n",
      "train loss:1.0265570218288111\n",
      "train loss:0.8478434548414141\n",
      "train loss:0.901457605840268\n",
      "train loss:1.0252033329711028\n",
      "train loss:0.8652838458499332\n",
      "train loss:1.0734246257629223\n",
      "train loss:0.9870776661890865\n",
      "train loss:0.974165426630121\n",
      "train loss:0.8513950634442253\n",
      "train loss:0.9809568343708669\n",
      "train loss:0.8627817911496669\n",
      "train loss:0.9168634549663834\n",
      "train loss:0.8024052842672795\n",
      "train loss:0.8857956173182072\n",
      "train loss:0.9375887418973619\n",
      "train loss:1.0310337389784343\n",
      "train loss:1.0360522484426107\n",
      "train loss:0.9703792618956482\n",
      "train loss:0.7360470219566959\n",
      "train loss:0.9448405747230255\n",
      "train loss:1.0849623460703102\n",
      "train loss:0.7312948496563625\n",
      "train loss:0.7588348326557117\n",
      "train loss:0.8248587007001309\n",
      "train loss:1.054798090604418\n",
      "train loss:0.9147482313794193\n",
      "train loss:0.964530988043551\n",
      "train loss:0.9386871898017763\n",
      "train loss:0.9704043532951151\n",
      "train loss:0.8058948970820049\n",
      "train loss:1.0277493309148322\n",
      "train loss:0.9379702902858057\n",
      "train loss:0.8220828295602933\n",
      "train loss:0.9969686081497241\n",
      "train loss:0.9324116455706111\n",
      "train loss:0.9945061994769201\n",
      "train loss:0.9344481042034479\n",
      "train loss:0.8840251198204669\n",
      "train loss:0.8825319220707238\n",
      "train loss:0.8443626076336895\n",
      "train loss:0.8094068513274436\n",
      "train loss:0.822676359475573\n",
      "train loss:1.0480460075954467\n",
      "train loss:0.7918361665639004\n",
      "train loss:0.7949497192174132\n",
      "train loss:0.8013704426344275\n",
      "train loss:0.9603841516167898\n",
      "train loss:0.7872337481192627\n",
      "train loss:0.967760195250466\n",
      "train loss:0.8690846745758549\n",
      "train loss:0.8979774474482436\n",
      "train loss:0.8991793526507743\n",
      "train loss:0.7404566917460701\n",
      "train loss:0.987511386489961\n",
      "train loss:0.8983483439082853\n",
      "train loss:0.9442095366276484\n",
      "train loss:0.9746684043045313\n",
      "train loss:1.071061191753214\n",
      "train loss:0.9989010120346171\n",
      "train loss:0.9369730299107872\n",
      "train loss:1.0608127270441512\n",
      "train loss:1.02672293095358\n",
      "train loss:0.8355859815283583\n",
      "train loss:0.9491445967479554\n",
      "train loss:0.9158503750963781\n",
      "train loss:0.9442143820469434\n",
      "train loss:0.8890492208533428\n",
      "train loss:0.8770845510102809\n",
      "train loss:1.0521005534649885\n",
      "train loss:0.9592849664339604\n",
      "train loss:0.905488789134149\n",
      "train loss:0.9234923782189531\n",
      "train loss:0.8162202075623749\n",
      "train loss:1.0422835173756202\n",
      "train loss:1.0608370770883069\n",
      "train loss:0.8841300210307\n",
      "train loss:0.8878725883909279\n",
      "train loss:0.9085279225433193\n",
      "train loss:1.024102012742411\n",
      "train loss:0.9145581296721922\n",
      "train loss:0.8278426880016008\n",
      "train loss:0.8509597609175756\n",
      "train loss:0.9398986635924423\n",
      "train loss:0.9435321699126824\n",
      "train loss:0.8927740606541853\n",
      "=== epoch:7, train acc:0.992, test acc:0.99 ===\n",
      "train loss:1.0850678820435207\n",
      "train loss:0.859813412821238\n",
      "train loss:0.8355085461747759\n",
      "train loss:0.9640352759392815\n",
      "train loss:0.7464457967139372\n",
      "train loss:0.9023486278563633\n",
      "train loss:0.8897869508784464\n",
      "train loss:1.031776930820704\n",
      "train loss:1.1514684065704008\n",
      "train loss:0.8998665179661108\n",
      "train loss:1.016608432050435\n",
      "train loss:1.0597421913403218\n",
      "train loss:0.8337667297149118\n",
      "train loss:0.9452792261362226\n",
      "train loss:1.123509353289518\n",
      "train loss:0.7053713035599297\n",
      "train loss:0.8706297376517598\n",
      "train loss:0.9444095904391109\n",
      "train loss:1.0398679280243412\n",
      "train loss:0.8072953567001083\n",
      "train loss:0.9089082482127496\n",
      "train loss:0.799914079984591\n",
      "train loss:0.9091285145662492\n",
      "train loss:0.871295338216165\n",
      "train loss:0.864182825277206\n",
      "train loss:1.2172566341649231\n",
      "train loss:0.9917123678600654\n",
      "train loss:0.8631808168989688\n",
      "train loss:0.9682030040114337\n",
      "train loss:0.9400040925120298\n",
      "train loss:0.9813458786166841\n",
      "train loss:0.9329164184557353\n",
      "train loss:1.0764819943275388\n",
      "train loss:1.0303565686737501\n",
      "train loss:0.9772351025206912\n",
      "train loss:0.9561829678485277\n",
      "train loss:0.9026751563123594\n",
      "train loss:1.187766180943744\n",
      "train loss:0.9239823674473342\n",
      "train loss:1.042248336559742\n",
      "train loss:1.0483755783638733\n",
      "train loss:1.064439398155561\n",
      "train loss:0.9949886998943106\n",
      "train loss:0.811792708102854\n",
      "train loss:0.930063326543667\n",
      "train loss:0.852847631680997\n",
      "train loss:0.6887088389439441\n",
      "train loss:0.9563214030865896\n",
      "train loss:0.8148361532922279\n",
      "train loss:0.6759912003495395\n",
      "train loss:0.9581979505589838\n",
      "train loss:0.8850354306103797\n",
      "train loss:0.9557918002680323\n",
      "train loss:0.9414690835207671\n",
      "train loss:0.8839256681311367\n",
      "train loss:0.9543145032522482\n",
      "train loss:1.0066503813469432\n",
      "train loss:0.7522322848253528\n",
      "train loss:0.8760961600813623\n",
      "train loss:0.9780617053253046\n",
      "train loss:0.8760780933734514\n",
      "train loss:0.8425039240597642\n",
      "train loss:0.9657818731743169\n",
      "train loss:0.9279168610823265\n",
      "train loss:1.0153755928619426\n",
      "train loss:0.8957334301501185\n",
      "train loss:0.9389810039623403\n",
      "train loss:0.8163148621011938\n",
      "train loss:0.985877480270506\n",
      "train loss:0.871835858780497\n",
      "train loss:0.9401839212793132\n",
      "train loss:0.8116095054275263\n",
      "train loss:0.7553896625084247\n",
      "train loss:0.7586430299850764\n",
      "train loss:0.8382868104229857\n",
      "train loss:0.6932824596769213\n",
      "train loss:0.9800283082002785\n",
      "train loss:0.9166502386946327\n",
      "train loss:0.9431422867645898\n",
      "train loss:0.9309559424337693\n",
      "train loss:0.9096210177922336\n",
      "train loss:0.8579026708832816\n",
      "train loss:1.0955915628796487\n",
      "train loss:0.8803918504624826\n",
      "train loss:0.9680074114645392\n",
      "train loss:0.9944451307289932\n",
      "train loss:0.9753662719332502\n",
      "train loss:0.9575742933696173\n",
      "train loss:0.8652727877662117\n",
      "train loss:1.0251076609916518\n",
      "train loss:0.9494986004215954\n",
      "train loss:0.8268130482432625\n",
      "train loss:1.0012792995237805\n",
      "train loss:1.0285407140534588\n",
      "train loss:0.9575320955305853\n",
      "train loss:0.8279865235484298\n",
      "train loss:0.9297868929990903\n",
      "train loss:0.8560409627778786\n",
      "train loss:0.7112288659686793\n",
      "train loss:0.8545030338666162\n",
      "train loss:0.9785075101049766\n",
      "train loss:0.7329414580077156\n",
      "train loss:0.8685520120240631\n",
      "train loss:0.8079310864862147\n",
      "train loss:0.842955717925879\n",
      "train loss:0.8805207520849025\n",
      "train loss:0.9067781881316519\n",
      "train loss:0.8172831581947837\n",
      "train loss:0.8631731669500247\n",
      "train loss:0.8859151867897718\n",
      "train loss:0.8701056631542978\n",
      "train loss:0.8291160386018973\n",
      "train loss:0.8144854808173091\n",
      "train loss:0.9122555956247776\n",
      "train loss:0.9752146548759838\n",
      "train loss:0.8258130441845423\n",
      "train loss:0.710193410252439\n",
      "train loss:0.9543720825891155\n",
      "train loss:0.727541030998975\n",
      "train loss:0.930546663315038\n",
      "train loss:0.896910357345517\n",
      "train loss:0.9946165564163152\n",
      "train loss:0.8087519976761848\n",
      "train loss:0.8948509249246372\n",
      "train loss:0.9153584172057642\n",
      "train loss:1.0210144566766646\n",
      "train loss:0.9914693630854867\n",
      "train loss:1.1250750868256922\n",
      "train loss:0.9658146199036477\n",
      "train loss:0.9570339541257308\n",
      "train loss:0.9219725245882718\n",
      "train loss:1.0780876091420624\n",
      "train loss:1.0400683500490697\n",
      "train loss:1.1384681241322787\n",
      "train loss:1.1021526096759597\n",
      "train loss:0.8458612055577336\n",
      "train loss:0.8379947848249704\n",
      "train loss:0.9642724160009664\n",
      "train loss:0.9752987939015785\n",
      "train loss:0.878117093660701\n",
      "train loss:0.7689669304204162\n",
      "train loss:0.9427438141190011\n",
      "train loss:0.8469336545105786\n",
      "train loss:0.762886069078818\n",
      "train loss:0.9630761173640456\n",
      "train loss:1.0071882147392806\n",
      "train loss:0.7193815342721905\n",
      "train loss:0.9677464192290706\n",
      "train loss:1.038211862496802\n",
      "train loss:0.9266597246589399\n",
      "train loss:0.961338335488844\n",
      "train loss:0.9467456864016859\n",
      "train loss:0.8043565562674495\n",
      "train loss:0.975187869151911\n",
      "train loss:0.886695868079538\n",
      "train loss:0.8020919961448769\n",
      "train loss:0.8812585888141333\n",
      "train loss:0.9376885740402295\n",
      "train loss:0.8564326278780375\n",
      "train loss:1.0093126851587877\n",
      "train loss:0.9046808565753914\n",
      "train loss:1.106886601896583\n",
      "train loss:0.9931018371321286\n",
      "train loss:0.925845870677853\n",
      "train loss:0.8350803119460488\n",
      "train loss:1.0966857735250435\n",
      "train loss:0.930884523054021\n",
      "train loss:0.7515114048701109\n",
      "train loss:0.6436516329311048\n",
      "train loss:0.9646671256427161\n",
      "train loss:0.9294646162930951\n",
      "train loss:0.9377872553512957\n",
      "train loss:0.930213465543527\n",
      "train loss:0.8834342146720681\n",
      "train loss:0.9602135766596992\n",
      "train loss:0.9796739079196536\n",
      "train loss:0.9142805028139861\n",
      "train loss:1.0072865493979979\n",
      "train loss:0.9687705946336365\n",
      "train loss:0.9956324384853449\n",
      "train loss:0.9216562560625366\n",
      "train loss:0.9423936871232602\n",
      "train loss:0.9135469227961517\n",
      "train loss:0.7640131918129954\n",
      "train loss:0.9616645812570375\n",
      "train loss:1.035210763145627\n",
      "train loss:0.859178444531493\n",
      "train loss:0.945440228883508\n",
      "train loss:0.9318072279681463\n",
      "train loss:0.9065778046018429\n",
      "train loss:0.8088735732801032\n",
      "train loss:0.8883571100088562\n",
      "train loss:0.9033386563500223\n",
      "train loss:0.8628583449823455\n",
      "train loss:1.0734901268879498\n",
      "train loss:1.0897770752427818\n",
      "train loss:0.9819646101404035\n",
      "train loss:1.0228481534406455\n",
      "train loss:0.9217501731698036\n",
      "train loss:0.7601506541369965\n",
      "train loss:0.9758293201692149\n",
      "train loss:0.900423524728061\n",
      "train loss:1.1054594930110542\n",
      "train loss:0.894690644147694\n",
      "train loss:0.6843589088270996\n",
      "train loss:0.9368189744988351\n",
      "train loss:0.991860020103416\n",
      "train loss:1.013925227913408\n",
      "train loss:0.8614699433079153\n",
      "train loss:0.7020006463028942\n",
      "train loss:0.9467443137857902\n",
      "train loss:0.8470642344747422\n",
      "train loss:0.8205035887696817\n",
      "train loss:0.9839267034749852\n",
      "train loss:0.9336074735014611\n",
      "train loss:0.9105446982507519\n",
      "train loss:0.8675709822487236\n",
      "train loss:1.0017514646237675\n",
      "train loss:1.175776055938038\n",
      "train loss:0.8872677878625739\n",
      "train loss:0.8429733277824552\n",
      "train loss:0.6950871402643969\n",
      "train loss:0.8740216661441448\n",
      "train loss:1.0073249002476008\n",
      "train loss:0.9354747340572891\n",
      "train loss:0.8481695532838509\n",
      "train loss:0.8972690415731513\n",
      "train loss:0.9178344815253006\n",
      "train loss:0.9812148765062316\n",
      "train loss:0.8618784000786951\n",
      "train loss:0.9078999468137755\n",
      "train loss:1.0394799887556259\n",
      "train loss:0.9445837484681199\n",
      "train loss:0.928155852179185\n",
      "train loss:0.8159519196555813\n",
      "train loss:0.9090366348045055\n",
      "train loss:0.9506140207856463\n",
      "train loss:0.7353226960198924\n",
      "train loss:0.9733715297332941\n",
      "train loss:0.9345324884141866\n",
      "train loss:1.0269680953724964\n",
      "train loss:0.9220150884076136\n",
      "train loss:0.9156826172606768\n",
      "train loss:1.0010056456363794\n",
      "train loss:1.0064178480883463\n",
      "train loss:0.9122460747532124\n",
      "train loss:0.8513678046356341\n",
      "train loss:0.8739170563796632\n",
      "train loss:1.0039274968573937\n",
      "train loss:0.9105483100444246\n",
      "train loss:0.9171496864594018\n",
      "train loss:0.906159987853247\n",
      "train loss:1.0758070437978833\n",
      "train loss:0.7784296125556637\n",
      "train loss:0.9394009201746387\n",
      "train loss:0.8166417877734831\n",
      "train loss:0.923099556963633\n",
      "train loss:0.781918751371378\n",
      "train loss:1.0545318590500063\n",
      "train loss:0.7314237266942185\n",
      "train loss:0.9798104700480832\n",
      "train loss:1.0389353144311204\n",
      "train loss:0.8901458717134285\n",
      "train loss:0.8215219248364517\n",
      "train loss:0.7712054862621859\n",
      "train loss:0.8066825501417949\n",
      "train loss:0.9186309690190829\n",
      "train loss:0.9152981941766984\n",
      "train loss:0.9083428160050271\n",
      "train loss:0.9362438602778153\n",
      "train loss:0.9067185032995576\n",
      "train loss:0.8650286020407445\n",
      "train loss:0.9657687737846499\n",
      "train loss:0.9294324145365169\n",
      "train loss:0.8776433282641256\n",
      "train loss:1.0395597531053948\n",
      "train loss:1.0028931893719772\n",
      "train loss:0.9156386783996183\n",
      "train loss:0.8739747866577494\n",
      "train loss:0.8419454566889906\n",
      "train loss:0.7927247283997826\n",
      "train loss:0.9625259855762802\n",
      "train loss:1.0137484771361738\n",
      "train loss:0.9307986197000464\n",
      "train loss:0.8648251293713249\n",
      "train loss:0.7967757850636279\n",
      "train loss:0.8920524502607917\n",
      "train loss:0.9011521837739757\n",
      "train loss:0.7665296203151593\n",
      "train loss:0.9019043527779693\n",
      "train loss:0.9429473281447401\n",
      "train loss:0.9015888053576784\n",
      "train loss:0.9842841885047627\n",
      "train loss:0.98216074490422\n",
      "train loss:0.7759686899655073\n",
      "train loss:1.0513898765444183\n",
      "train loss:0.6672196752801882\n",
      "train loss:0.8525959909809291\n",
      "train loss:0.9600575304611474\n",
      "train loss:0.9412631338551384\n",
      "train loss:0.8314685311214929\n",
      "train loss:1.0180067368260055\n",
      "train loss:0.8590487091372404\n",
      "train loss:0.9452979637853984\n",
      "train loss:0.9088757818557909\n",
      "train loss:0.868434745510303\n",
      "train loss:1.1069986625897108\n",
      "train loss:1.218716022945603\n",
      "train loss:1.0719017782304108\n",
      "train loss:0.9912349330632787\n",
      "train loss:0.7749008827632536\n",
      "train loss:0.9434183225118298\n",
      "train loss:0.9411610719899167\n",
      "train loss:1.005082134713422\n",
      "train loss:0.8453141789527898\n",
      "train loss:0.8904082543794384\n",
      "train loss:0.9250018878349724\n",
      "train loss:0.833262207100085\n",
      "train loss:0.8725926747428682\n",
      "train loss:0.7714339970550005\n",
      "train loss:1.0012281923100919\n",
      "train loss:0.9393904071530759\n",
      "train loss:0.8009907882703702\n",
      "train loss:0.9444931432046703\n",
      "train loss:0.8947859503773066\n",
      "train loss:0.8980295120513074\n",
      "train loss:0.9235306037600484\n",
      "train loss:0.8037599894857037\n",
      "train loss:0.7414500505589088\n",
      "train loss:1.1705454638492088\n",
      "train loss:0.8108611987068213\n",
      "train loss:0.9580235277257886\n",
      "train loss:1.0481726760131382\n",
      "train loss:0.8558079824122822\n",
      "train loss:0.8911856845291808\n",
      "train loss:0.9867686562193846\n",
      "train loss:0.7687399552650166\n",
      "train loss:0.8238401321387587\n",
      "train loss:1.16463779323306\n",
      "train loss:0.8675967847294855\n",
      "train loss:0.9718198731189855\n",
      "train loss:0.9851833343470833\n",
      "train loss:0.8710761692560055\n",
      "train loss:0.8331829795995759\n",
      "train loss:0.9618021065801018\n",
      "train loss:1.0017846544457705\n",
      "train loss:0.9191057440677446\n",
      "train loss:0.9195454276151402\n",
      "train loss:1.0592962029371988\n",
      "train loss:0.8395362547554471\n",
      "train loss:0.8050513270019622\n",
      "train loss:0.816834295015199\n",
      "train loss:1.0449667864806884\n",
      "train loss:0.8932515120585406\n",
      "train loss:0.9376120167494271\n",
      "train loss:0.8883027895697532\n",
      "train loss:0.941100126833313\n",
      "train loss:0.8994359368970889\n",
      "train loss:1.0844681295984244\n",
      "train loss:0.9801905260107198\n",
      "train loss:0.9623580304299437\n",
      "train loss:0.9113505764064602\n",
      "train loss:0.8600095371962577\n",
      "train loss:0.8505355225850754\n",
      "train loss:0.7452338469452816\n",
      "train loss:0.9766014586003148\n",
      "train loss:1.0963824209263495\n",
      "train loss:0.8337959798659352\n",
      "train loss:0.9081935142356332\n",
      "train loss:0.832226643211871\n",
      "train loss:0.920083643686041\n",
      "train loss:1.0589064780826616\n",
      "train loss:0.9410149987308378\n",
      "train loss:0.7401014421079962\n",
      "train loss:0.8969450705522506\n",
      "train loss:0.7784090350076954\n",
      "train loss:0.8410285210779962\n",
      "train loss:1.0326670476437783\n",
      "train loss:0.9442286964453188\n",
      "train loss:0.9159561248792505\n",
      "train loss:0.9480001807406353\n",
      "train loss:1.1054427326573046\n",
      "train loss:1.0634977730310955\n",
      "train loss:0.8889553810376563\n",
      "train loss:0.9552430896060636\n",
      "train loss:0.8931619263407587\n",
      "train loss:0.8556258380917217\n",
      "train loss:0.9138031348221118\n",
      "train loss:1.0436940648000914\n",
      "train loss:0.8881269309545362\n",
      "train loss:1.0585697469708963\n",
      "train loss:0.9435970697701971\n",
      "train loss:0.84821947335599\n",
      "train loss:0.853586432342622\n",
      "train loss:0.8346378336890615\n",
      "train loss:0.7745800743063742\n",
      "train loss:1.0227532469666882\n",
      "train loss:1.0400519271324764\n",
      "train loss:1.0432544472599325\n",
      "train loss:0.9326615298817974\n",
      "train loss:0.917044269352754\n",
      "train loss:0.913065100758697\n",
      "train loss:0.8965604800845113\n",
      "train loss:1.0332660578235\n",
      "train loss:0.8223128174160047\n",
      "train loss:0.9381764633875213\n",
      "train loss:1.0037068547067174\n",
      "train loss:0.9238765737564215\n",
      "train loss:0.9181447214967828\n",
      "train loss:0.8166348347641672\n",
      "train loss:0.9753158442282452\n",
      "train loss:0.9534035912839558\n",
      "train loss:0.8560347966431343\n",
      "train loss:0.9783127760362029\n",
      "train loss:1.043002388191299\n",
      "train loss:1.1052046556774986\n",
      "train loss:0.9388761044912459\n",
      "train loss:0.7787220507096488\n",
      "train loss:1.0931217268146485\n",
      "train loss:0.8363769701045614\n",
      "train loss:0.8688919196161531\n",
      "train loss:1.1507385072785288\n",
      "train loss:0.899000568910755\n",
      "train loss:0.992014041753439\n",
      "train loss:1.157898556914828\n",
      "train loss:0.873891618426169\n",
      "train loss:1.016867004521382\n",
      "train loss:0.8986515641527074\n",
      "train loss:0.9536957739182538\n",
      "train loss:1.0076349150510915\n",
      "train loss:1.0217150476432852\n",
      "train loss:0.8359224528927498\n",
      "train loss:1.007340856360505\n",
      "train loss:0.8996945776144685\n",
      "train loss:1.1247812681860792\n",
      "train loss:0.9389802542515859\n",
      "train loss:0.8703357361468873\n",
      "train loss:1.0079287662007024\n",
      "train loss:0.9304364834804573\n",
      "train loss:0.851283261499617\n",
      "train loss:0.923181134425906\n",
      "train loss:0.8150758555631186\n",
      "train loss:0.8715287020135989\n",
      "train loss:0.97524628535985\n",
      "train loss:0.898781834328385\n",
      "train loss:0.9285027267138033\n",
      "train loss:0.8451134553865026\n",
      "train loss:0.9200645420004807\n",
      "train loss:0.8768957563303785\n",
      "train loss:0.952826207779136\n",
      "train loss:0.9856194578626227\n",
      "train loss:0.9882332685977926\n",
      "train loss:0.7613607979341098\n",
      "train loss:1.1040231834249503\n",
      "train loss:1.036703646713475\n",
      "train loss:0.8842216900913462\n",
      "train loss:0.9513635106151918\n",
      "train loss:0.9106656657302014\n",
      "train loss:1.2068828529771445\n",
      "train loss:0.8715303226190565\n",
      "train loss:0.9141928727922695\n",
      "train loss:0.7857872537285929\n",
      "train loss:0.8938896134951261\n",
      "train loss:0.8397025974300516\n",
      "train loss:0.9694165203793729\n",
      "train loss:0.9626710563173964\n",
      "train loss:1.0599173739547338\n",
      "train loss:0.9056696290799472\n",
      "train loss:0.813699194183043\n",
      "train loss:0.9651720066756632\n",
      "train loss:0.8997511380356962\n",
      "train loss:0.9560527440327767\n",
      "train loss:0.8016048278238423\n",
      "train loss:0.7307291460106907\n",
      "train loss:0.9663026501883717\n",
      "train loss:0.9675714991001511\n",
      "train loss:0.9520522030589283\n",
      "train loss:0.7517623175077071\n",
      "train loss:0.8373144709102083\n",
      "train loss:0.7654290169245496\n",
      "train loss:0.9558286314412725\n",
      "train loss:0.9874392599063927\n",
      "train loss:0.7690349386465993\n",
      "train loss:1.0230258317608005\n",
      "train loss:0.9609572072778201\n",
      "train loss:0.8754983122890397\n",
      "train loss:1.051617382988806\n",
      "train loss:0.8850807052580519\n",
      "train loss:0.9112188581084362\n",
      "train loss:0.8384661657316594\n",
      "train loss:0.8527671818317603\n",
      "train loss:0.9445797874932044\n",
      "train loss:0.9533540000178248\n",
      "train loss:0.8631546243558285\n",
      "train loss:1.0773100108016942\n",
      "train loss:0.9261175924159835\n",
      "train loss:1.0098233202981515\n",
      "train loss:1.0373007600547033\n",
      "train loss:0.9023872582889463\n",
      "train loss:0.8751488426451027\n",
      "train loss:0.9476304686887418\n",
      "train loss:0.853829292999031\n",
      "train loss:0.9290831611703267\n",
      "train loss:0.8545634797053003\n",
      "train loss:0.7893694678229288\n",
      "train loss:1.0976087051636059\n",
      "train loss:0.9050937106583206\n",
      "train loss:0.8988763993144275\n",
      "train loss:0.8994608855056896\n",
      "train loss:0.7726427733457661\n",
      "train loss:1.1000721201651538\n",
      "train loss:0.8220554011309764\n",
      "train loss:0.8399929138958377\n",
      "train loss:1.2432491712799134\n",
      "train loss:1.223342961178236\n",
      "train loss:0.9624531464149295\n",
      "train loss:1.0005057700297313\n",
      "train loss:0.9392768320502008\n",
      "train loss:1.0403698657680616\n",
      "train loss:1.000312745227268\n",
      "train loss:0.8030239229861814\n",
      "train loss:0.9225244896892479\n",
      "train loss:1.0274693418702163\n",
      "train loss:0.9553234093169263\n",
      "train loss:0.9100461066074109\n",
      "train loss:0.8248097826105999\n",
      "train loss:1.0652264627775438\n",
      "train loss:1.0029121340566516\n",
      "train loss:1.0219156348769727\n",
      "train loss:0.7666715588357899\n",
      "train loss:0.9491613935154762\n",
      "train loss:0.8189489783416194\n",
      "train loss:0.949548837656764\n",
      "train loss:0.9633615239367611\n",
      "train loss:0.9216336535260987\n",
      "train loss:1.050691458873435\n",
      "train loss:1.0587867882227295\n",
      "train loss:0.9777425240660123\n",
      "train loss:1.056729880369888\n",
      "train loss:0.9036801928054807\n",
      "train loss:1.0303544649368135\n",
      "train loss:0.7063730266680848\n",
      "train loss:1.0001428340215819\n",
      "train loss:0.9055182878605693\n",
      "train loss:0.9771568702566956\n",
      "train loss:0.972086243664933\n",
      "train loss:0.7522651397206157\n",
      "train loss:0.8380746720869758\n",
      "train loss:1.066481268918986\n",
      "train loss:0.932429392542229\n",
      "train loss:0.8857422078266174\n",
      "train loss:1.0308063633476\n",
      "train loss:1.0793245566064549\n",
      "train loss:1.0034303378725276\n",
      "train loss:0.9495104647040361\n",
      "train loss:0.9410904026495135\n",
      "train loss:0.8066255408342657\n",
      "train loss:1.0016006715895514\n",
      "train loss:0.905052894636512\n",
      "train loss:0.9981275806227498\n",
      "train loss:0.8627471688036563\n",
      "train loss:0.9029090731138425\n",
      "train loss:0.9037027752901307\n",
      "train loss:0.9310573253296988\n",
      "train loss:0.8722150355736413\n",
      "train loss:0.8565630420658314\n",
      "train loss:0.9590217826842511\n",
      "train loss:0.8920785342907159\n",
      "train loss:0.7942473022708897\n",
      "train loss:0.7266399526999701\n",
      "train loss:0.8661412286683711\n",
      "train loss:0.8749030621020439\n",
      "train loss:0.9970657423912899\n",
      "train loss:0.8222597697667786\n",
      "train loss:1.0000694801445933\n",
      "train loss:0.9283637377954115\n",
      "train loss:0.9199753306170995\n",
      "train loss:0.9263035493181374\n",
      "train loss:0.8620885757691552\n",
      "train loss:0.9389632800572759\n",
      "train loss:0.8128322742864883\n",
      "train loss:0.9572382745177223\n",
      "train loss:1.0296292517716197\n",
      "train loss:0.8398822165934896\n",
      "train loss:0.9229443252833809\n",
      "train loss:1.0325498774842676\n",
      "train loss:0.7371743029622209\n",
      "train loss:0.9048014889934521\n",
      "train loss:0.8419284500876598\n",
      "train loss:0.7836005147081099\n",
      "train loss:0.9053835634740388\n",
      "train loss:0.8858621005132896\n",
      "train loss:0.9835842962366398\n",
      "train loss:0.9565615625068352\n",
      "train loss:0.8472272197323157\n",
      "train loss:0.9552711005605421\n",
      "train loss:0.8252011406512412\n",
      "train loss:0.8971402556368356\n",
      "train loss:0.9487710273633566\n",
      "train loss:0.7786565447715269\n",
      "=== epoch:8, train acc:0.991, test acc:0.986 ===\n",
      "train loss:0.9351857072830613\n",
      "train loss:0.8478365747823403\n",
      "train loss:0.892808272850571\n",
      "train loss:0.780104481020137\n",
      "train loss:0.8128144321880691\n",
      "train loss:0.9917775221592191\n",
      "train loss:0.9548560050515666\n",
      "train loss:1.0741895642134482\n",
      "train loss:0.930154404885645\n",
      "train loss:0.9403531881833748\n",
      "train loss:0.8053052937953349\n",
      "train loss:0.8550063206044999\n",
      "train loss:0.9011902530086098\n",
      "train loss:0.6653560646745832\n",
      "train loss:0.7975723527121376\n",
      "train loss:0.7975492709342018\n",
      "train loss:0.9315055816739212\n",
      "train loss:0.9832770557760249\n",
      "train loss:0.9806697264207653\n",
      "train loss:0.8220205684509884\n",
      "train loss:0.8536677962982405\n",
      "train loss:0.9588702201217294\n",
      "train loss:0.8720360336214452\n",
      "train loss:0.768222596638807\n",
      "train loss:1.1083311806857574\n",
      "train loss:0.8478543685821736\n",
      "train loss:0.8356706631633197\n",
      "train loss:0.9184811408422543\n",
      "train loss:0.8785878591248429\n",
      "train loss:0.8312209098937692\n",
      "train loss:0.8960497587691586\n",
      "train loss:0.8761710723636679\n",
      "train loss:1.0275457086743522\n",
      "train loss:0.8720078727255135\n",
      "train loss:0.9397334458997331\n",
      "train loss:0.8484113977530767\n",
      "train loss:0.7905961939836463\n",
      "train loss:1.0199995253839425\n",
      "train loss:0.7690213077928547\n",
      "train loss:0.813784442270776\n",
      "train loss:1.0004367626281856\n",
      "train loss:0.7767459299693494\n",
      "train loss:1.0001229584875515\n",
      "train loss:1.150171324332083\n",
      "train loss:0.9070352009237581\n",
      "train loss:1.0089510116947684\n",
      "train loss:0.9444571987338812\n",
      "train loss:0.9347653298800944\n",
      "train loss:1.0602309900635478\n",
      "train loss:0.9522154109294384\n",
      "train loss:0.9396119311972542\n",
      "train loss:1.0433334099574458\n",
      "train loss:0.8061980030514014\n",
      "train loss:0.8443009173137814\n",
      "train loss:0.8995548182347107\n",
      "train loss:0.9016523032815539\n",
      "train loss:0.9524545481376113\n",
      "train loss:0.7573366874770667\n",
      "train loss:1.0286651196590644\n",
      "train loss:0.8542222595274249\n",
      "train loss:0.9837750038281561\n",
      "train loss:0.9317534176722149\n",
      "train loss:0.7760088676362312\n",
      "train loss:0.99569930435756\n",
      "train loss:0.7863121990626405\n",
      "train loss:0.8942892695750844\n",
      "train loss:0.9778747447318062\n",
      "train loss:1.0270684973430235\n",
      "train loss:0.8994807196708411\n",
      "train loss:0.8610233690632694\n",
      "train loss:0.9672129277764167\n",
      "train loss:0.8235211719190844\n",
      "train loss:0.8188915602004033\n",
      "train loss:0.9580838166870904\n",
      "train loss:0.9505583195665416\n",
      "train loss:1.1142572626294278\n",
      "train loss:0.7810020776070441\n",
      "train loss:0.8554371971721122\n",
      "train loss:0.9404153295761961\n",
      "train loss:0.8403298739945584\n",
      "train loss:1.0431233862649218\n",
      "train loss:0.8305199149579523\n",
      "train loss:0.8388263126754151\n",
      "train loss:0.9906139645821522\n",
      "train loss:0.8038579168433329\n",
      "train loss:0.7747175210621947\n",
      "train loss:0.825579285964891\n",
      "train loss:0.8739477530931992\n",
      "train loss:0.9597526005979361\n",
      "train loss:1.1094674282386148\n",
      "train loss:0.9090057573066715\n",
      "train loss:0.9108518469896829\n",
      "train loss:0.9221437383219084\n",
      "train loss:0.870548175164341\n",
      "train loss:0.7722674404133215\n",
      "train loss:0.8900497718547064\n",
      "train loss:0.8453442327137259\n",
      "train loss:0.90213048914775\n",
      "train loss:0.8559386446611391\n",
      "train loss:0.8528631456209915\n",
      "train loss:0.8811428884940146\n",
      "train loss:0.9420595252187743\n",
      "train loss:0.9413773546675501\n",
      "train loss:0.9123945273031819\n",
      "train loss:0.904634359557924\n",
      "train loss:0.9674740857576072\n",
      "train loss:0.7868636293630062\n",
      "train loss:0.9478864337040211\n",
      "train loss:1.0848696183308282\n",
      "train loss:0.7609612357875961\n",
      "train loss:0.7966842507854486\n",
      "train loss:0.8807012683698496\n",
      "train loss:0.9796468116379827\n",
      "train loss:0.9700277210822723\n",
      "train loss:1.0823487243308172\n",
      "train loss:0.9597179677728548\n",
      "train loss:0.8201489489471363\n",
      "train loss:0.8852371974370544\n",
      "train loss:0.9628966284329072\n",
      "train loss:0.9444149778273627\n",
      "train loss:0.9903500346307433\n",
      "train loss:1.0446629417889661\n",
      "train loss:0.95390312188264\n",
      "train loss:0.9337837060330162\n",
      "train loss:1.0688785427836818\n",
      "train loss:0.9610255900638568\n",
      "train loss:0.850830919337956\n",
      "train loss:0.9095136204597328\n",
      "train loss:0.9782167011597798\n",
      "train loss:1.0151693173999397\n",
      "train loss:0.9192470100789326\n",
      "train loss:0.8960873525132098\n",
      "train loss:1.0565062988044875\n",
      "train loss:0.7337042285099694\n",
      "train loss:0.8898171485851343\n",
      "train loss:1.2153500181448469\n",
      "train loss:0.9359648431935851\n",
      "train loss:0.8125231223581852\n",
      "train loss:0.8432774861116964\n",
      "train loss:0.6304431936028734\n",
      "train loss:0.8320470976011738\n",
      "train loss:0.7766743337241705\n",
      "train loss:0.7654909522555472\n",
      "train loss:0.8860207082153981\n",
      "train loss:0.9495637584391626\n",
      "train loss:0.6835188551944236\n",
      "train loss:0.797818012257704\n",
      "train loss:0.9339945183621583\n",
      "train loss:0.9353266251152416\n",
      "train loss:0.9400660852493613\n",
      "train loss:0.9777409746330492\n",
      "train loss:0.9424496427762178\n",
      "train loss:0.8473531835931272\n",
      "train loss:0.9740764780693689\n",
      "train loss:0.9160831620037098\n",
      "train loss:0.9949439761059673\n",
      "train loss:1.0918109162651333\n",
      "train loss:0.9409617799566236\n",
      "train loss:1.0803249710901028\n",
      "train loss:0.9097755346873178\n",
      "train loss:0.9386296900658837\n",
      "train loss:0.9491344432833153\n",
      "train loss:0.8246614773477922\n",
      "train loss:0.7738157288184802\n",
      "train loss:0.7990538379334842\n",
      "train loss:0.8383286225878007\n",
      "train loss:0.9280060074605533\n",
      "train loss:0.7667227365326396\n",
      "train loss:1.050913815467239\n",
      "train loss:1.0461751516735673\n",
      "train loss:0.9689383574422169\n",
      "train loss:0.9774411014844859\n",
      "train loss:0.8707479321474405\n",
      "train loss:0.7580479369419075\n",
      "train loss:0.8685943135955838\n",
      "train loss:1.0259133996366758\n",
      "train loss:0.9748572882462735\n",
      "train loss:0.7994808941066266\n",
      "train loss:0.8756241595120733\n",
      "train loss:0.8977915182250215\n",
      "train loss:1.0383400638388758\n",
      "train loss:0.9149078267939386\n",
      "train loss:1.0478498583640194\n",
      "train loss:0.8985695339494342\n",
      "train loss:0.9955542138215057\n",
      "train loss:0.8587937376404267\n",
      "train loss:0.9539462830485077\n",
      "train loss:0.7426528879453297\n",
      "train loss:0.924562116069939\n",
      "train loss:0.8798122132131583\n",
      "train loss:0.9495092056354616\n",
      "train loss:0.9988064274887176\n",
      "train loss:0.8643967773054716\n",
      "train loss:0.9733226342757756\n",
      "train loss:0.7954989986978088\n",
      "train loss:0.7877687982148254\n",
      "train loss:0.7368846662046883\n",
      "train loss:0.8414560178327067\n",
      "train loss:0.9386586064532807\n",
      "train loss:1.0975463563692738\n",
      "train loss:0.8764976173851021\n",
      "train loss:0.8152599898779682\n",
      "train loss:0.8400150809283105\n",
      "train loss:0.9449524078056675\n",
      "train loss:0.8670704858341653\n",
      "train loss:0.8328384904943279\n",
      "train loss:1.075251094358996\n",
      "train loss:0.8333222430126423\n",
      "train loss:0.873178685076408\n",
      "train loss:0.9896214246414344\n",
      "train loss:0.8133234146108665\n",
      "train loss:0.8703844559404749\n",
      "train loss:0.9098735168415244\n",
      "train loss:0.9397851142302571\n",
      "train loss:0.9093861074021659\n",
      "train loss:0.9014510416583136\n",
      "train loss:0.8022478884424925\n",
      "train loss:0.8566921538603425\n",
      "train loss:0.9874859769919507\n",
      "train loss:0.7540991044014759\n",
      "train loss:0.8906521652351179\n",
      "train loss:0.9843623227054669\n",
      "train loss:0.8395274709630739\n",
      "train loss:0.8802837645162402\n",
      "train loss:1.1242907394858788\n",
      "train loss:0.8125744250465992\n",
      "train loss:0.870825513961814\n",
      "train loss:0.8846570688844038\n",
      "train loss:0.8938697932183791\n",
      "train loss:0.960911661726884\n",
      "train loss:0.7949920185882824\n",
      "train loss:0.6811122489241881\n",
      "train loss:0.976454650924994\n",
      "train loss:0.8647335540275624\n",
      "train loss:0.8574036228778172\n",
      "train loss:0.8282249846882729\n",
      "train loss:0.763161927448916\n",
      "train loss:0.8257204631227261\n",
      "train loss:0.9613654619109657\n",
      "train loss:0.8505230089475702\n",
      "train loss:0.9961274566131004\n",
      "train loss:1.1268978282254387\n",
      "train loss:0.9744474329345602\n",
      "train loss:0.8599515546592411\n",
      "train loss:0.9471712757413531\n",
      "train loss:0.8693501662088546\n",
      "train loss:0.9022797711877163\n",
      "train loss:0.9171575435810528\n",
      "train loss:1.0326917276190801\n",
      "train loss:0.9493010110037706\n",
      "train loss:0.9914797165151761\n",
      "train loss:0.8687732055798463\n",
      "train loss:1.0536049758519326\n",
      "train loss:0.8387943219536039\n",
      "train loss:0.7890960308225421\n",
      "train loss:0.7800921452028723\n",
      "train loss:0.9904820654712267\n",
      "train loss:1.032611474353291\n",
      "train loss:1.075144043363173\n",
      "train loss:0.8192211840374379\n",
      "train loss:1.0182480460675094\n",
      "train loss:0.9390186777370927\n",
      "train loss:0.8621189711184191\n",
      "train loss:0.9019198415566082\n",
      "train loss:0.7648242615354812\n",
      "train loss:0.8277242479757798\n",
      "train loss:0.9897856573975585\n",
      "train loss:0.6611882335494221\n",
      "train loss:0.8851691959988293\n",
      "train loss:0.8819909337019005\n",
      "train loss:0.8442676022363631\n",
      "train loss:1.0054388774357568\n",
      "train loss:0.916671517701157\n",
      "train loss:0.8589950868640948\n",
      "train loss:1.029223769882298\n",
      "train loss:1.0787746748838483\n",
      "train loss:0.9481512699564993\n",
      "train loss:0.7643300681483219\n",
      "train loss:0.8359129757876893\n",
      "train loss:0.9294127148489396\n",
      "train loss:0.962490828413786\n",
      "train loss:0.9655549474235358\n",
      "train loss:0.8867211491815759\n",
      "train loss:0.7402625879960856\n",
      "train loss:1.1182433775923815\n",
      "train loss:0.8079409263140199\n",
      "train loss:0.9443676209292705\n",
      "train loss:0.9423953561754062\n",
      "train loss:0.99886836449693\n",
      "train loss:1.0085914197538035\n",
      "train loss:0.8497655068242341\n",
      "train loss:0.800702224824635\n",
      "train loss:0.9758668930776324\n",
      "train loss:0.9002154436288191\n",
      "train loss:0.9237989600204106\n",
      "train loss:0.9208036171386418\n",
      "train loss:0.9086423618812576\n",
      "train loss:0.9338050036981498\n",
      "train loss:0.9757750299838901\n",
      "train loss:0.925127266889023\n",
      "train loss:0.7405413235285274\n",
      "train loss:0.9328215293326174\n",
      "train loss:0.7926217719991291\n",
      "train loss:0.8829815784889006\n",
      "train loss:0.8315615696735066\n",
      "train loss:0.8047713937066164\n",
      "train loss:0.8690255925231003\n",
      "train loss:0.8554690465816356\n",
      "train loss:0.7468149418114034\n",
      "train loss:0.9228824544959828\n",
      "train loss:1.1194457413635697\n",
      "train loss:0.928713443662685\n",
      "train loss:0.830780525578998\n",
      "train loss:0.9580164464899192\n",
      "train loss:0.9729100248238366\n",
      "train loss:0.9694690136754813\n",
      "train loss:0.7655866280771982\n",
      "train loss:0.9363607821711648\n",
      "train loss:0.9046259508556738\n",
      "train loss:0.8077719948643649\n",
      "train loss:0.8495068521309824\n",
      "train loss:0.8763267217151784\n",
      "train loss:0.9966619444296347\n",
      "train loss:0.8146757253670946\n",
      "train loss:0.7751027125012695\n",
      "train loss:0.8936651015607514\n",
      "train loss:0.76437262289109\n",
      "train loss:1.0529225788755208\n",
      "train loss:0.9116228852019279\n",
      "train loss:0.9327366623231222\n",
      "train loss:0.827883067814466\n",
      "train loss:1.0930625829852378\n",
      "train loss:0.7231061226409095\n",
      "train loss:1.1056222541011913\n",
      "train loss:0.8604584765906655\n",
      "train loss:0.915720998730587\n",
      "train loss:1.1342887929752823\n",
      "train loss:0.9133838763936258\n",
      "train loss:1.001150659085207\n",
      "train loss:0.834841378401851\n",
      "train loss:0.7929165804673377\n",
      "train loss:0.8552675552774851\n",
      "train loss:0.8944453249244994\n",
      "train loss:0.9057810843295332\n",
      "train loss:0.7883620626368759\n",
      "train loss:0.8179350386084616\n",
      "train loss:1.089344500140934\n",
      "train loss:0.9817486203309147\n",
      "train loss:0.7743062481939407\n",
      "train loss:0.8664003914629835\n",
      "train loss:0.9893722369128539\n",
      "train loss:0.906034314443994\n",
      "train loss:1.0244705052718133\n",
      "train loss:0.8775032957054644\n",
      "train loss:0.8325243560209672\n",
      "train loss:0.8865457023440233\n",
      "train loss:0.7629420033723973\n",
      "train loss:0.9463044184170252\n",
      "train loss:0.8716229186314746\n",
      "train loss:0.8657438080445047\n",
      "train loss:1.0533559303921889\n",
      "train loss:1.0013720223278637\n",
      "train loss:1.013971764860042\n",
      "train loss:0.9165085568316421\n",
      "train loss:1.1486531499119117\n",
      "train loss:0.8321666701074563\n",
      "train loss:0.8854477963656288\n",
      "train loss:0.8788787519731486\n",
      "train loss:0.9320438936997278\n",
      "train loss:0.9331485499728341\n",
      "train loss:0.8550646901736125\n",
      "train loss:0.9553045761297816\n",
      "train loss:0.8348983885516263\n",
      "train loss:0.8566716797429283\n",
      "train loss:0.9796157380149295\n",
      "train loss:0.874520918349146\n",
      "train loss:0.8011271892631429\n",
      "train loss:0.962485359953041\n",
      "train loss:0.8001273726519678\n",
      "train loss:0.8564103362289694\n",
      "train loss:0.8191651110209078\n",
      "train loss:0.8732647535452673\n",
      "train loss:0.8257740282737344\n",
      "train loss:0.9363507360442229\n",
      "train loss:1.1040979417915517\n",
      "train loss:0.8949948707250586\n",
      "train loss:1.135804256868345\n",
      "train loss:0.9821222092938935\n",
      "train loss:1.0777690199376941\n",
      "train loss:0.9675476469509239\n",
      "train loss:0.8720691444938824\n",
      "train loss:0.9840131050148533\n",
      "train loss:0.9691509607123798\n",
      "train loss:0.9191795538122363\n",
      "train loss:0.8426015118463108\n",
      "train loss:1.1274918001097505\n",
      "train loss:0.840201655785213\n",
      "train loss:0.9207035348250525\n",
      "train loss:0.8803517424738945\n",
      "train loss:0.8793146194394426\n",
      "train loss:0.8490685977491184\n",
      "train loss:0.9847010072910055\n",
      "train loss:0.8271865094796553\n",
      "train loss:0.9726711455651881\n",
      "train loss:0.77217780268191\n",
      "train loss:1.061948890992537\n",
      "train loss:0.7718115134235474\n",
      "train loss:0.861344834077792\n",
      "train loss:0.8377577637548747\n",
      "train loss:0.9986283689956029\n",
      "train loss:0.9637108312840931\n",
      "train loss:1.1337886407227884\n",
      "train loss:0.8049593477858804\n",
      "train loss:0.7368010568103877\n",
      "train loss:0.918553446824009\n",
      "train loss:1.0020621530834537\n",
      "train loss:0.7450712532770473\n",
      "train loss:0.8314086533441845\n",
      "train loss:0.8313703555111479\n",
      "train loss:1.0404053754538873\n",
      "train loss:0.8508714167429716\n",
      "train loss:0.9498973478061383\n",
      "train loss:0.8361589829660343\n",
      "train loss:0.7686162565461367\n",
      "train loss:0.8304540061998957\n",
      "train loss:0.884274853165715\n",
      "train loss:1.1540766250946648\n",
      "train loss:0.8268205773665734\n",
      "train loss:0.8118160865264072\n",
      "train loss:0.7769162081257369\n",
      "train loss:0.9218508076219323\n",
      "train loss:0.8419251603566344\n",
      "train loss:0.7507273331947311\n",
      "train loss:0.8512966531252784\n",
      "train loss:1.0235326212907858\n",
      "train loss:1.0014663448831371\n",
      "train loss:0.838606471678451\n",
      "train loss:0.8433172505800353\n",
      "train loss:0.7915633488437018\n",
      "train loss:1.0524401405861483\n",
      "train loss:0.8905484857051508\n",
      "train loss:0.9657257195165133\n",
      "train loss:0.9320922126029357\n",
      "train loss:0.9244306114668835\n",
      "train loss:0.7862058811787713\n",
      "train loss:0.9308132961188907\n",
      "train loss:0.7298660249789302\n",
      "train loss:0.9785297577808478\n",
      "train loss:0.9402582868591183\n",
      "train loss:0.9033436972148882\n",
      "train loss:1.008918949130649\n",
      "train loss:0.9854185108102993\n",
      "train loss:0.8085891706439884\n",
      "train loss:0.6820107388002811\n",
      "train loss:0.8830700500913724\n",
      "train loss:0.9763762167332533\n",
      "train loss:0.7971791964531634\n",
      "train loss:0.8546507979045834\n",
      "train loss:0.979787960103345\n",
      "train loss:0.9863029499807797\n",
      "train loss:0.8376165968031547\n",
      "train loss:1.0543765402256657\n",
      "train loss:1.1263879690427943\n",
      "train loss:0.8916542080513349\n",
      "train loss:0.8874783327344552\n",
      "train loss:1.0599647446040361\n",
      "train loss:0.9669842847442677\n",
      "train loss:0.8402228646089287\n",
      "train loss:0.9795545169237818\n",
      "train loss:0.6854439906246306\n",
      "train loss:0.8844843873167686\n",
      "train loss:0.8367498635413193\n",
      "train loss:1.0145384758865967\n",
      "train loss:0.7346803393003628\n",
      "train loss:0.7477338042496317\n",
      "train loss:0.8646371519782764\n",
      "train loss:1.035474286146797\n",
      "train loss:0.9699473166955975\n",
      "train loss:1.188610451670026\n",
      "train loss:0.8496121209765412\n",
      "train loss:0.8411282744402364\n",
      "train loss:0.7917724495402011\n",
      "train loss:0.9188933025313643\n",
      "train loss:0.8841135278238218\n",
      "train loss:0.931805010822903\n",
      "train loss:0.8868969625697958\n",
      "train loss:0.8865943927414399\n",
      "train loss:1.0213027208469745\n",
      "train loss:0.9298168090523555\n",
      "train loss:0.9651228553684374\n",
      "train loss:0.8547445382320809\n",
      "train loss:0.9083370480863331\n",
      "train loss:0.8996070021971603\n",
      "train loss:0.8162011190703143\n",
      "train loss:0.8733432867241607\n",
      "train loss:0.8860368383350147\n",
      "train loss:0.9130960721867435\n",
      "train loss:0.929664591388329\n",
      "train loss:0.8643871958156776\n",
      "train loss:0.9909556255094824\n",
      "train loss:0.8488743558184326\n",
      "train loss:0.7874475389830016\n",
      "train loss:0.8835938502107216\n",
      "train loss:0.8591838615526428\n",
      "train loss:0.8471495216621591\n",
      "train loss:0.886111419231142\n",
      "train loss:0.8105329387043819\n",
      "train loss:0.8144704663796116\n",
      "train loss:0.8195772256645961\n",
      "train loss:0.8996208520335184\n",
      "train loss:0.7755424087541588\n",
      "train loss:0.9989328903206289\n",
      "train loss:0.9564201340758189\n",
      "train loss:0.9210405415519547\n",
      "train loss:0.9912270521596472\n",
      "train loss:0.794309418195494\n",
      "train loss:0.8965970381644162\n",
      "train loss:0.8639412200551004\n",
      "train loss:0.9769711807747568\n",
      "train loss:1.2085735303203535\n",
      "train loss:0.8920388847104554\n",
      "train loss:1.158875829367404\n",
      "train loss:0.9652476871537253\n",
      "train loss:1.013166187627142\n",
      "train loss:0.8022809709075731\n",
      "train loss:0.8368779064863804\n",
      "train loss:0.9496657861300345\n",
      "train loss:0.8694883005617784\n",
      "train loss:0.8277583314501952\n",
      "train loss:0.9106025493476355\n",
      "train loss:0.8973266734738228\n",
      "train loss:1.0479578179653017\n",
      "train loss:0.8916494405519056\n",
      "train loss:0.8989380064745884\n",
      "train loss:0.6134805430376025\n",
      "train loss:1.0020333848860254\n",
      "train loss:0.8534677455330681\n",
      "train loss:0.935850403480167\n",
      "train loss:0.8318406170194541\n",
      "train loss:0.9426889072505912\n",
      "train loss:0.8136398440279906\n",
      "train loss:0.9500980131070107\n",
      "train loss:0.8999705856039363\n",
      "train loss:0.8160087043806413\n",
      "train loss:0.9330770446427656\n",
      "train loss:0.8480570257718674\n",
      "train loss:0.7732137455654953\n",
      "train loss:0.8897002692353084\n",
      "train loss:1.0592394580155955\n",
      "train loss:0.9755811107003026\n",
      "train loss:0.9010343720513352\n",
      "train loss:0.8012988412949476\n",
      "train loss:0.7011667826544218\n",
      "train loss:0.7729277138284993\n",
      "train loss:1.0585783634262405\n",
      "train loss:0.9514782592010173\n",
      "train loss:0.8283449749339638\n",
      "train loss:0.9823943453126741\n",
      "train loss:1.0731424018320812\n",
      "train loss:0.952532721811986\n",
      "train loss:0.9174967178526119\n",
      "train loss:1.1067562208385093\n",
      "train loss:0.7868730833624897\n",
      "train loss:1.049469573172569\n",
      "train loss:0.9926381192844856\n",
      "train loss:1.0794413692626683\n",
      "train loss:0.8952888517948526\n",
      "train loss:0.8456332788175871\n",
      "train loss:0.9086202350497673\n",
      "train loss:0.9114523687192161\n",
      "train loss:0.9766104926392889\n",
      "train loss:0.8528596163913469\n",
      "train loss:0.9454420195748402\n",
      "train loss:0.8168496885945953\n",
      "train loss:0.9439986410479112\n",
      "train loss:0.7003043123228639\n",
      "train loss:0.9542238985782329\n",
      "train loss:0.9635327515101909\n",
      "train loss:0.8448947436016127\n",
      "train loss:0.8901895785061104\n",
      "train loss:0.9620409543329016\n",
      "train loss:0.8877926407247145\n",
      "train loss:0.765642413415987\n",
      "train loss:0.739946211297614\n",
      "train loss:0.8922132175621984\n",
      "train loss:0.8943805633120817\n",
      "train loss:1.0198842994395476\n",
      "train loss:0.926616300609244\n",
      "train loss:0.8224127602189226\n",
      "train loss:0.8221639934378383\n",
      "train loss:0.8974187996981872\n",
      "train loss:0.9942741598307014\n",
      "train loss:0.8639270576497773\n",
      "train loss:0.9614345642229327\n",
      "train loss:1.0659559549663884\n",
      "train loss:1.1694299301213504\n",
      "train loss:0.8123926301631641\n",
      "train loss:1.1793042696013214\n",
      "train loss:0.9428329636455469\n",
      "train loss:0.9360818568313128\n",
      "=== epoch:9, train acc:0.994, test acc:0.984 ===\n",
      "train loss:0.9765419780100415\n",
      "train loss:1.0417952166199913\n",
      "train loss:0.905764905149376\n",
      "train loss:0.9095646335777231\n",
      "train loss:0.9440918953149448\n",
      "train loss:0.8921844101161038\n",
      "train loss:0.7836466135310967\n",
      "train loss:0.873898133783185\n",
      "train loss:0.8779111872424344\n",
      "train loss:0.8745940780286205\n",
      "train loss:0.8311117169108067\n",
      "train loss:0.8969773088240871\n",
      "train loss:0.8423202232723722\n",
      "train loss:0.9626199426889113\n",
      "train loss:0.9156810261342653\n",
      "train loss:0.9392401367031856\n",
      "train loss:0.9650051333399984\n",
      "train loss:0.897195194233446\n",
      "train loss:0.8974442044569918\n",
      "train loss:0.9053409179423749\n",
      "train loss:0.7482652536084767\n",
      "train loss:0.9749707642164458\n",
      "train loss:0.8465063946608841\n",
      "train loss:1.020776290291177\n",
      "train loss:0.8512736686369737\n",
      "train loss:0.928762853875538\n",
      "train loss:0.8838037743586763\n",
      "train loss:0.8120502911649224\n",
      "train loss:0.9138200546489919\n",
      "train loss:0.788217185148278\n",
      "train loss:0.7939093932587262\n",
      "train loss:0.8722844688799214\n",
      "train loss:0.9667205289398038\n",
      "train loss:0.895741197836916\n",
      "train loss:1.0976438816565832\n",
      "train loss:0.933722364759458\n",
      "train loss:0.8326257616982923\n",
      "train loss:0.9988529891583866\n",
      "train loss:0.8506526032629717\n",
      "train loss:0.7718372659979457\n",
      "train loss:0.7293062898995539\n",
      "train loss:0.83318673858378\n",
      "train loss:0.8655485342261948\n",
      "train loss:0.9614167706187341\n",
      "train loss:0.8160025302277198\n",
      "train loss:0.9336112173296346\n",
      "train loss:0.9371382942643597\n",
      "train loss:0.9860287523499296\n",
      "train loss:0.7036477440297542\n",
      "train loss:0.9356434149777054\n",
      "train loss:1.1504354330910842\n",
      "train loss:0.7946298287657947\n",
      "train loss:0.8851108175818936\n",
      "train loss:0.9891537398974942\n",
      "train loss:0.9595442592813584\n",
      "train loss:0.8281390190888664\n",
      "train loss:0.8386292510764892\n",
      "train loss:0.8481104437088939\n",
      "train loss:0.9622641824064947\n",
      "train loss:0.7964477932806274\n",
      "train loss:0.9363451148868848\n",
      "train loss:0.9115039468405449\n",
      "train loss:0.9695499717395818\n",
      "train loss:0.9706644228187525\n",
      "train loss:0.8320508060099\n",
      "train loss:0.8988103178279124\n",
      "train loss:1.00949011871309\n",
      "train loss:0.8036842463730579\n",
      "train loss:1.0389554909687198\n",
      "train loss:0.7654706058587287\n",
      "train loss:0.7630458102143471\n",
      "train loss:0.7758718617878851\n",
      "train loss:0.8301789462249931\n",
      "train loss:0.9662851568321965\n",
      "train loss:0.9560738861243445\n",
      "train loss:1.0099207535552586\n",
      "train loss:0.9687152569390601\n",
      "train loss:0.9065405211017081\n",
      "train loss:1.0048466713276571\n",
      "train loss:0.774023478544148\n",
      "train loss:1.0711818486672962\n",
      "train loss:0.9726012449167982\n",
      "train loss:0.7759932713762784\n",
      "train loss:0.8426405105430864\n",
      "train loss:0.9323214987605211\n",
      "train loss:0.7399576821774037\n",
      "train loss:0.9298812955869438\n",
      "train loss:0.9279649965796873\n",
      "train loss:0.7339367855939648\n",
      "train loss:0.884911709895875\n",
      "train loss:0.9197855189032689\n",
      "train loss:1.0086042564844515\n",
      "train loss:0.770479812979105\n",
      "train loss:0.8378677913667985\n",
      "train loss:0.8637877928567106\n",
      "train loss:0.9219611183942388\n",
      "train loss:0.9090193847061552\n",
      "train loss:0.8593913499064272\n",
      "train loss:0.9471193101990238\n",
      "train loss:0.8854069531067402\n",
      "train loss:0.9565148806812305\n",
      "train loss:1.1519999324239758\n",
      "train loss:1.0132470554265485\n",
      "train loss:0.7724162845560398\n",
      "train loss:0.8207312380341273\n",
      "train loss:0.889858930740016\n",
      "train loss:0.941652559585891\n",
      "train loss:0.9125701092066053\n",
      "train loss:0.9435236579117859\n",
      "train loss:0.7964730068414057\n",
      "train loss:1.062944245400328\n",
      "train loss:0.7460814663325971\n",
      "train loss:0.9062168378177121\n",
      "train loss:0.9316164138241647\n",
      "train loss:0.7862497281432408\n",
      "train loss:0.9909700669546957\n",
      "train loss:0.887030659492796\n",
      "train loss:1.0238319193088907\n",
      "train loss:0.9285338414150133\n",
      "train loss:1.0797171261187886\n",
      "train loss:1.0699986711153737\n",
      "train loss:0.8960604489071442\n",
      "train loss:0.8102194177570123\n",
      "train loss:0.8617881553660246\n",
      "train loss:0.9561875904254978\n",
      "train loss:1.0526202395064748\n",
      "train loss:0.7710192100001805\n",
      "train loss:0.9457480407761968\n",
      "train loss:0.7767153296175242\n",
      "train loss:0.8737142643408689\n",
      "train loss:0.9326615829883831\n",
      "train loss:0.988672161971232\n",
      "train loss:0.8733235037381957\n",
      "train loss:0.8991931512693135\n",
      "train loss:1.044464152219564\n",
      "train loss:1.0546582818899195\n",
      "train loss:0.9035189416128661\n",
      "train loss:0.8594037677897108\n",
      "train loss:0.936501006097902\n",
      "train loss:0.8668321440860606\n",
      "train loss:0.7997263153064595\n",
      "train loss:0.9619211503693034\n",
      "train loss:0.9903959043191992\n",
      "train loss:0.8028614340031016\n",
      "train loss:1.0516700759436974\n",
      "train loss:0.8004723906382553\n",
      "train loss:0.9520786075342877\n",
      "train loss:0.9624624667324098\n",
      "train loss:0.9265614422496625\n",
      "train loss:0.8152360876972874\n",
      "train loss:0.9086692746252432\n",
      "train loss:0.7925914437095822\n",
      "train loss:0.8176061794871383\n",
      "train loss:0.8953293277703801\n",
      "train loss:0.7387468657982393\n",
      "train loss:0.7988090873348257\n",
      "train loss:0.901746007453021\n",
      "train loss:0.8731695124788657\n",
      "train loss:0.9536608819697012\n",
      "train loss:0.8599200980556623\n",
      "train loss:1.039447110085038\n",
      "train loss:1.024545959403684\n",
      "train loss:0.9132359878268779\n",
      "train loss:0.8741214314723921\n",
      "train loss:0.845373597577003\n",
      "train loss:0.7840468353196064\n",
      "train loss:0.8015271086198632\n",
      "train loss:0.7985532184618297\n",
      "train loss:0.9423509407578221\n",
      "train loss:0.9486016211909419\n",
      "train loss:0.8684637646065299\n",
      "train loss:0.9315927046404622\n",
      "train loss:0.9821641914306776\n",
      "train loss:0.9327624407952766\n",
      "train loss:0.8372037155239288\n",
      "train loss:0.9743657162310572\n",
      "train loss:1.0298507278791493\n",
      "train loss:0.8148830160261046\n",
      "train loss:0.9384603431522629\n",
      "train loss:0.8885697422627679\n",
      "train loss:0.8071867706025151\n",
      "train loss:0.92227688753137\n",
      "train loss:0.6783812211251348\n",
      "train loss:1.026419601539587\n",
      "train loss:0.8577062617817631\n",
      "train loss:0.945440096183607\n",
      "train loss:0.9832277847756664\n",
      "train loss:0.7791069703213318\n",
      "train loss:0.980768771826517\n",
      "train loss:0.7996800023292429\n",
      "train loss:0.7674918059122109\n",
      "train loss:0.8558848385120521\n",
      "train loss:1.1742730111979751\n",
      "train loss:1.0111425964566751\n",
      "train loss:0.8703400016460618\n",
      "train loss:0.8923395918755931\n",
      "train loss:0.9734443908623142\n",
      "train loss:0.9460787992368832\n",
      "train loss:0.911622558504066\n",
      "train loss:0.9773477543599857\n",
      "train loss:1.14816631129099\n",
      "train loss:0.877644441372371\n",
      "train loss:0.9756326479710553\n",
      "train loss:0.845449690922678\n",
      "train loss:0.8995959522612893\n",
      "train loss:0.9205591451241353\n",
      "train loss:0.7538118106103573\n",
      "train loss:0.9999064590715137\n",
      "train loss:0.8155842526009013\n",
      "train loss:0.8017247025523639\n",
      "train loss:0.9689408712743645\n",
      "train loss:0.8258811468917243\n",
      "train loss:0.9252146570459644\n",
      "train loss:1.0637380497117794\n",
      "train loss:0.9284890129220955\n",
      "train loss:0.8746948584888534\n",
      "train loss:0.9312473273954648\n",
      "train loss:0.9589350482731456\n",
      "train loss:0.9541704365878426\n",
      "train loss:1.021188666606841\n",
      "train loss:0.7678050221720596\n",
      "train loss:0.9750502326287286\n",
      "train loss:0.9308179159401826\n",
      "train loss:1.012428192369846\n",
      "train loss:0.9389392773012443\n",
      "train loss:0.9439453433852296\n",
      "train loss:0.7953639809612513\n",
      "train loss:0.9100561493648713\n",
      "train loss:0.8781730427622769\n",
      "train loss:0.728017451620555\n",
      "train loss:1.0068724160842768\n",
      "train loss:0.747968548462323\n",
      "train loss:0.7394761444086132\n",
      "train loss:0.8841645862226308\n",
      "train loss:0.8110260343117345\n",
      "train loss:0.861303716936657\n",
      "train loss:0.9201500991341098\n",
      "train loss:0.8637157136658997\n",
      "train loss:0.9441494288941367\n",
      "train loss:0.9329682371265116\n",
      "train loss:0.8038963954264509\n",
      "train loss:0.8556773792782044\n",
      "train loss:0.947693442974816\n",
      "train loss:0.8748762179802564\n",
      "train loss:0.768537771128655\n",
      "train loss:0.9787141242055587\n",
      "train loss:0.720215071813336\n",
      "train loss:0.8854621459012627\n",
      "train loss:0.8387384677605916\n",
      "train loss:0.7111053401242099\n",
      "train loss:0.9833485836522855\n",
      "train loss:0.7083418860367477\n",
      "train loss:0.9798253488655407\n",
      "train loss:0.9581604755752463\n",
      "train loss:0.8050121644941777\n",
      "train loss:0.8638448799992418\n",
      "train loss:0.871034700845804\n",
      "train loss:0.9321996209483373\n",
      "train loss:0.8851138482773139\n",
      "train loss:0.9175508567348039\n",
      "train loss:1.053313309725837\n",
      "train loss:0.9758351114143786\n",
      "train loss:0.915375864200856\n",
      "train loss:0.9710503157044049\n",
      "train loss:0.9052285711784144\n",
      "train loss:1.0288198854102537\n",
      "train loss:0.8491276875159055\n",
      "train loss:1.1405230099296972\n",
      "train loss:0.7848747523628732\n",
      "train loss:1.0317183619093993\n",
      "train loss:0.856714143472595\n",
      "train loss:0.849948459916519\n",
      "train loss:0.9788140113088518\n",
      "train loss:0.9668214792513925\n",
      "train loss:0.9116602426720313\n",
      "train loss:0.8576967681477836\n",
      "train loss:0.7382767809521984\n",
      "train loss:0.898208884153704\n",
      "train loss:0.8319269943404902\n",
      "train loss:1.0105308824259973\n",
      "train loss:0.8648546278928992\n",
      "train loss:0.9591826927598855\n",
      "train loss:0.9270282317418578\n",
      "train loss:0.9264861115965247\n",
      "train loss:0.7837188192753222\n",
      "train loss:0.7938035356310372\n",
      "train loss:0.8329580084994503\n",
      "train loss:0.9986623596981079\n",
      "train loss:0.799848371376097\n",
      "train loss:1.0198912904162265\n",
      "train loss:0.9510626381688131\n",
      "train loss:0.9096455265869396\n",
      "train loss:0.7987565478583134\n",
      "train loss:0.9578797422763349\n",
      "train loss:0.8423888546494898\n",
      "train loss:0.9437170522755072\n",
      "train loss:0.9364187927007519\n",
      "train loss:0.8236243139233711\n",
      "train loss:0.8103067384965376\n",
      "train loss:0.8892812705600289\n",
      "train loss:0.8346729157158275\n",
      "train loss:0.997435869252723\n",
      "train loss:0.8814361002844714\n",
      "train loss:0.7727069165774623\n",
      "train loss:1.0302884782991146\n",
      "train loss:0.8982603619940384\n",
      "train loss:1.0724629308424127\n",
      "train loss:0.9316398914011412\n",
      "train loss:0.9486542487621739\n",
      "train loss:1.0142026291173694\n",
      "train loss:0.9185404721741689\n",
      "train loss:0.9590416513992993\n",
      "train loss:1.1386444949837935\n",
      "train loss:0.9288701048106757\n",
      "train loss:0.9479406966749896\n",
      "train loss:0.7550410664298579\n",
      "train loss:1.0091228874369813\n",
      "train loss:0.7370534151938269\n",
      "train loss:0.7489160800794589\n",
      "train loss:0.9758761734091342\n",
      "train loss:1.092836101969556\n",
      "train loss:0.9110915512318983\n",
      "train loss:0.7701315925649921\n",
      "train loss:0.8859674899050741\n",
      "train loss:0.7882154320523572\n",
      "train loss:0.8731039091004633\n",
      "train loss:0.8521722686072846\n",
      "train loss:0.8264052596793171\n",
      "train loss:0.9742264428527249\n",
      "train loss:1.002240147512763\n",
      "train loss:0.8727623760399141\n",
      "train loss:0.9509473923690775\n",
      "train loss:0.8859394251244601\n",
      "train loss:0.9808732099782351\n",
      "train loss:0.881009442251975\n",
      "train loss:0.7948716305346802\n",
      "train loss:0.851689776088997\n",
      "train loss:0.7846955535398047\n",
      "train loss:0.9795147858159963\n",
      "train loss:1.0304943093368382\n",
      "train loss:1.0821731663793837\n",
      "train loss:1.131702317351764\n",
      "train loss:0.861602003077304\n",
      "train loss:0.8210815173242575\n",
      "train loss:0.959690626258393\n",
      "train loss:0.9506245772014994\n",
      "train loss:0.9165984149429802\n",
      "train loss:0.7902537746476862\n",
      "train loss:0.9313901421020365\n",
      "train loss:0.9114200772592789\n",
      "train loss:0.7579528037800523\n",
      "train loss:0.8196490237985787\n",
      "train loss:0.9855725904655257\n",
      "train loss:0.9959686416658441\n",
      "train loss:0.855089756969553\n",
      "train loss:0.8396634218374069\n",
      "train loss:0.7694112239395365\n",
      "train loss:0.803199707440063\n",
      "train loss:0.8127980962928479\n",
      "train loss:0.9430995190908465\n",
      "train loss:0.7885393453034788\n",
      "train loss:0.9714977325492185\n",
      "train loss:0.8665667547957101\n",
      "train loss:0.6889781290556201\n",
      "train loss:0.7084221859550651\n",
      "train loss:0.9142179420532858\n",
      "train loss:0.8403061885948999\n",
      "train loss:0.8484764241696015\n",
      "train loss:0.8526593553042183\n",
      "train loss:0.9228496775942745\n",
      "train loss:0.8261694310512947\n",
      "train loss:0.8421204830367138\n",
      "train loss:0.9049445324287756\n",
      "train loss:0.9665991597214127\n",
      "train loss:0.8924310350823983\n",
      "train loss:1.1380663720622393\n",
      "train loss:0.8280290413899545\n",
      "train loss:0.9775835732194388\n",
      "train loss:0.9381646271097663\n",
      "train loss:0.765543227738287\n",
      "train loss:0.9636341496867289\n",
      "train loss:0.8760066972655584\n",
      "train loss:0.8497513921102147\n",
      "train loss:0.9207328262005348\n",
      "train loss:0.8219105991407696\n",
      "train loss:0.8240600446631656\n",
      "train loss:0.9110212585948054\n",
      "train loss:0.894470260851407\n",
      "train loss:0.6864297021283636\n",
      "train loss:0.9202248122209293\n",
      "train loss:0.9603305961558033\n",
      "train loss:0.9073666813995493\n",
      "train loss:0.9862943401757027\n",
      "train loss:0.8132881903133715\n",
      "train loss:0.9104212969369645\n",
      "train loss:0.7864664230455722\n",
      "train loss:0.8503344049352282\n",
      "train loss:0.9792892402072106\n",
      "train loss:1.0527714723431385\n",
      "train loss:0.97772782046746\n",
      "train loss:0.8562658804155638\n",
      "train loss:0.8790994762953744\n",
      "train loss:0.9582947552242096\n",
      "train loss:1.041806807638464\n",
      "train loss:1.0970551208768358\n",
      "train loss:0.9267087670526\n",
      "train loss:0.8970366296291042\n",
      "train loss:0.9507239145173212\n",
      "train loss:0.916683435134595\n",
      "train loss:0.871076886937087\n",
      "train loss:0.7892208034920423\n",
      "train loss:0.9409729665285791\n",
      "train loss:0.9059787228661811\n",
      "train loss:1.0226224309278704\n",
      "train loss:0.9747476367927187\n",
      "train loss:0.9683286814195905\n",
      "train loss:0.9149321638771096\n",
      "train loss:0.8441836943295913\n",
      "train loss:0.9445025001972961\n",
      "train loss:0.8287972743137777\n",
      "train loss:0.7759518413517099\n",
      "train loss:0.8511913872722776\n",
      "train loss:0.9707425548942231\n",
      "train loss:0.9211018459923601\n",
      "train loss:0.8542274962231096\n",
      "train loss:1.0467436892393869\n",
      "train loss:0.9466775245687995\n",
      "train loss:0.9244807093444504\n",
      "train loss:0.913333750679123\n",
      "train loss:0.9409647648248369\n",
      "train loss:0.7151104890056138\n",
      "train loss:0.9191493134767806\n",
      "train loss:0.9762211192437498\n",
      "train loss:0.7733419492030591\n",
      "train loss:1.0013243454086143\n",
      "train loss:0.8791457591661763\n",
      "train loss:0.8800088848321893\n",
      "train loss:0.8821622928144227\n",
      "train loss:0.8972620680985972\n",
      "train loss:0.9430000913485549\n",
      "train loss:0.8388614825722907\n",
      "train loss:0.9794359726920981\n",
      "train loss:0.9415322216831404\n",
      "train loss:0.9507165201115068\n",
      "train loss:0.8420648121227567\n",
      "train loss:0.7859782671172714\n",
      "train loss:1.010699036136534\n",
      "train loss:0.8499813973629564\n",
      "train loss:0.9059907551443448\n",
      "train loss:0.9694827934914126\n",
      "train loss:0.983106306453926\n",
      "train loss:0.8067263654583782\n",
      "train loss:1.0104103468761423\n",
      "train loss:1.0971283210535718\n",
      "train loss:0.9883614126032683\n",
      "train loss:1.0920235711026904\n",
      "train loss:0.8940998366231925\n",
      "train loss:0.8390700075720916\n",
      "train loss:0.8545018022310157\n",
      "train loss:0.8816461692222475\n",
      "train loss:1.0389555417335687\n",
      "train loss:0.8778680697202143\n",
      "train loss:0.9343495897038951\n",
      "train loss:1.0391715943648172\n",
      "train loss:0.8152424035036777\n",
      "train loss:0.8143784558822135\n",
      "train loss:0.8294257271597425\n",
      "train loss:0.8253319715797511\n",
      "train loss:0.7050851943129784\n",
      "train loss:0.8941857501178976\n",
      "train loss:0.9105592776032425\n",
      "train loss:1.1308552454513672\n",
      "train loss:0.9462944431975181\n",
      "train loss:1.1665459916153245\n",
      "train loss:0.8309768628158091\n",
      "train loss:0.841085850196738\n",
      "train loss:1.0531677956952163\n",
      "train loss:0.6960446782852745\n",
      "train loss:0.8349523571512916\n",
      "train loss:0.9092423007923174\n",
      "train loss:0.8850019285141412\n",
      "train loss:0.922380632582379\n",
      "train loss:0.9884342063878833\n",
      "train loss:1.001752803588402\n",
      "train loss:0.9704528466403971\n",
      "train loss:0.9904109932698435\n",
      "train loss:0.8088463260574045\n",
      "train loss:0.7943458177945907\n",
      "train loss:0.8198036080760059\n",
      "train loss:0.9041356380581651\n",
      "train loss:0.7909523976277066\n",
      "train loss:0.832091284176618\n",
      "train loss:0.8675703607813461\n",
      "train loss:0.9335634278199358\n",
      "train loss:0.7105769021545183\n",
      "train loss:0.9845068307013727\n",
      "train loss:0.6846059758869947\n",
      "train loss:0.8686911443244473\n",
      "train loss:0.9425480595404104\n",
      "train loss:0.8611856211078144\n",
      "train loss:0.8642732147768625\n",
      "train loss:0.9604728645681062\n",
      "train loss:0.9652863118069825\n",
      "train loss:0.9922115556573303\n",
      "train loss:0.7587993562977785\n",
      "train loss:0.8914299333433948\n",
      "train loss:0.9403159985328253\n",
      "train loss:0.915204944189912\n",
      "train loss:0.9906907083683559\n",
      "train loss:0.7436864679161291\n",
      "train loss:0.7949769027041779\n",
      "train loss:1.1418466908705593\n",
      "train loss:1.0505290627979678\n",
      "train loss:0.9034731933322577\n",
      "train loss:0.9028782406332693\n",
      "train loss:0.9782383643036064\n",
      "train loss:0.9730670218280731\n",
      "train loss:0.8837747347174062\n",
      "train loss:1.0412484348359279\n",
      "train loss:0.8935374015761584\n",
      "train loss:0.8380160409387993\n",
      "train loss:0.7575088306607156\n",
      "train loss:0.8360475495420122\n",
      "train loss:0.875550870099424\n",
      "train loss:0.9628894032925062\n",
      "train loss:0.9466181031298785\n",
      "train loss:0.8740445011292234\n",
      "train loss:0.9044932020100557\n",
      "train loss:1.0755376879666008\n",
      "train loss:0.847798648551635\n",
      "train loss:0.745852780537303\n",
      "train loss:1.0600479684563568\n",
      "train loss:0.8722995573981875\n",
      "train loss:0.7797500531614229\n",
      "train loss:0.9851394303171397\n",
      "train loss:0.9961713307578822\n",
      "train loss:0.9895368549289145\n",
      "train loss:0.8985380880411141\n",
      "train loss:0.9356335289329775\n",
      "train loss:1.0324730431281384\n",
      "train loss:0.8496700838716397\n",
      "train loss:0.8986875049809636\n",
      "train loss:0.8781900282791689\n",
      "train loss:0.862839989381509\n",
      "train loss:1.0661799777523913\n",
      "train loss:0.8725330082439037\n",
      "train loss:0.9240872726847743\n",
      "train loss:0.8417319714725032\n",
      "train loss:0.9215641875459174\n",
      "train loss:0.8359898731073495\n",
      "train loss:0.9146456802979275\n",
      "train loss:0.9568108667416847\n",
      "train loss:0.9147652196279091\n",
      "train loss:1.0191045240149972\n",
      "train loss:0.9577233776389652\n",
      "train loss:0.997740901185658\n",
      "train loss:0.7053797143510245\n",
      "train loss:0.8724908443577474\n",
      "train loss:0.8704431544578535\n",
      "train loss:0.939021734910877\n",
      "train loss:1.1139104504842796\n",
      "train loss:0.8685795323494105\n",
      "train loss:0.7660294706453965\n",
      "train loss:0.8802217890444376\n",
      "train loss:0.7984452223544394\n",
      "train loss:0.9905327015023532\n",
      "train loss:0.8754359934348082\n",
      "train loss:0.8320326913721864\n",
      "train loss:0.8260782953419021\n",
      "train loss:0.988275442197759\n",
      "train loss:0.910170981200126\n",
      "train loss:0.900131727857517\n",
      "train loss:0.965479203596615\n",
      "train loss:0.908838335629325\n",
      "train loss:1.012312879608768\n",
      "train loss:1.045096231093102\n",
      "train loss:0.912917656977986\n",
      "train loss:0.9619272740323251\n",
      "train loss:0.8531913483762559\n",
      "train loss:1.0231509225657676\n",
      "train loss:0.9062038411106141\n",
      "train loss:0.9456165666693611\n",
      "train loss:1.00838579252164\n",
      "train loss:1.0189697203967192\n",
      "train loss:0.8642140226248077\n",
      "train loss:0.9087342576307893\n",
      "train loss:0.8807883984753855\n",
      "train loss:1.0024046651892073\n",
      "train loss:0.8413215347869312\n",
      "train loss:0.8624814807693839\n",
      "train loss:0.8732620112453107\n",
      "train loss:0.8449217646671788\n",
      "train loss:0.8296619954996394\n",
      "train loss:1.143789095137102\n",
      "train loss:1.0441695398162258\n",
      "train loss:1.0328371571442883\n",
      "train loss:1.1103379172372447\n",
      "train loss:0.8174131530911458\n",
      "train loss:1.000097929966306\n",
      "train loss:0.9566976102104402\n",
      "=== epoch:10, train acc:0.993, test acc:0.985 ===\n",
      "train loss:0.8497671717182755\n",
      "train loss:1.0465047071086078\n",
      "train loss:0.9876787278962318\n",
      "train loss:0.9887327318563008\n",
      "train loss:0.9369801489968941\n",
      "train loss:0.8219299532626724\n",
      "train loss:1.1898035975586618\n",
      "train loss:0.9199528468411216\n",
      "train loss:0.9703728796067953\n",
      "train loss:0.9365312685216175\n",
      "train loss:0.9810859221033738\n",
      "train loss:0.8098645864619756\n",
      "train loss:0.8177249541503574\n",
      "train loss:0.9487340069110445\n",
      "train loss:0.7419843339981814\n",
      "train loss:0.9427695825735527\n",
      "train loss:0.8843127321790607\n",
      "train loss:0.7847255319324848\n",
      "train loss:0.9112134071441433\n",
      "train loss:0.8489312797203086\n",
      "train loss:0.8004051822508216\n",
      "train loss:0.9924408173156141\n",
      "train loss:0.8167196925330158\n",
      "train loss:0.8787159350442747\n",
      "train loss:0.9327159332182542\n",
      "train loss:1.0215804026046533\n",
      "train loss:0.858686237903483\n",
      "train loss:0.8603921798047981\n",
      "train loss:0.7198548386543274\n",
      "train loss:1.011574614043434\n",
      "train loss:0.853164643286508\n",
      "train loss:0.9273810874955645\n",
      "train loss:0.8263283762426974\n",
      "train loss:0.8952715060700959\n",
      "train loss:0.7625338553517059\n",
      "train loss:0.786788023990599\n",
      "train loss:0.9798317216304389\n",
      "train loss:0.8534903657593376\n",
      "train loss:0.7617944869824161\n",
      "train loss:0.817551073298582\n",
      "train loss:1.0309006038728161\n",
      "train loss:0.9258297187857452\n",
      "train loss:0.8512845382310025\n",
      "train loss:0.8448930988234322\n",
      "train loss:0.9584946240828109\n",
      "train loss:0.8025508702369156\n",
      "train loss:1.0259707427074358\n",
      "train loss:0.8499081881632959\n",
      "train loss:0.955947747002186\n",
      "train loss:0.940258884735544\n",
      "train loss:0.7001343472876046\n",
      "train loss:0.9467028364433996\n",
      "train loss:0.993045222857836\n",
      "train loss:0.9546170669304977\n",
      "train loss:0.6864044080004764\n",
      "train loss:0.8416055085532896\n",
      "train loss:0.985924692468896\n",
      "train loss:0.923680701691907\n",
      "train loss:0.6940972935310277\n",
      "train loss:0.8739341807276847\n",
      "train loss:0.8478252438775268\n",
      "train loss:0.813711603476063\n",
      "train loss:0.8874264500733726\n",
      "train loss:0.9081756749098961\n",
      "train loss:0.9256550323546112\n",
      "train loss:0.902571590656339\n",
      "train loss:0.8147461925835148\n",
      "train loss:0.8017364984407679\n",
      "train loss:0.7707860649426752\n",
      "train loss:0.9276743059380549\n",
      "train loss:1.067993538331735\n",
      "train loss:1.0191313868004193\n",
      "train loss:1.0241820133478645\n",
      "train loss:0.7936857535448931\n",
      "train loss:0.8867538221949454\n",
      "train loss:0.965103363614543\n",
      "train loss:1.0329057730424374\n",
      "train loss:1.012091163992431\n",
      "train loss:0.8698573659449994\n",
      "train loss:0.7682147957567358\n",
      "train loss:0.8102909247839857\n",
      "train loss:0.9685988911045514\n",
      "train loss:0.8307206598972756\n",
      "train loss:0.8350477802550127\n",
      "train loss:0.9249405669939523\n",
      "train loss:0.8387583540628338\n",
      "train loss:0.8281434111920027\n",
      "train loss:0.9378773594435592\n",
      "train loss:0.9296456899787293\n",
      "train loss:0.8763674522261964\n",
      "train loss:0.877253447572957\n",
      "train loss:0.8923557102321985\n",
      "train loss:0.8437132443374294\n",
      "train loss:0.7188385124849994\n",
      "train loss:0.7829856684435881\n",
      "train loss:0.8974219266518793\n",
      "train loss:0.9482840275756543\n",
      "train loss:1.0948155934340078\n",
      "train loss:0.9573621459701749\n",
      "train loss:0.8289711184606419\n",
      "train loss:0.9242188594687011\n",
      "train loss:1.0098465700135772\n",
      "train loss:0.9387678644311154\n",
      "train loss:1.04609171640205\n",
      "train loss:0.647728906700622\n",
      "train loss:0.9794144624593946\n",
      "train loss:0.970771814742699\n",
      "train loss:0.906797107134888\n",
      "train loss:0.9557099809383294\n",
      "train loss:0.9653046660483472\n",
      "train loss:0.8640523140162071\n",
      "train loss:0.9598102734109584\n",
      "train loss:0.6969011910419601\n",
      "train loss:0.9123780168197504\n",
      "train loss:0.8809084717806276\n",
      "train loss:0.8833717966677209\n",
      "train loss:0.7354582275681996\n",
      "train loss:0.8035640514387685\n",
      "train loss:0.9279837724941395\n",
      "train loss:0.6927123928281413\n",
      "train loss:0.8502241670387884\n",
      "train loss:1.0303463733547396\n",
      "train loss:0.8646213650265185\n",
      "train loss:0.8220543248269688\n",
      "train loss:0.9367749370223933\n",
      "train loss:0.9463870820998962\n",
      "train loss:0.8363463218002317\n",
      "train loss:0.6921251128793788\n",
      "train loss:0.8780461931262755\n",
      "train loss:0.7885660984436125\n",
      "train loss:0.7693629996360144\n",
      "train loss:0.7960364344738013\n",
      "train loss:0.8120510831172738\n",
      "train loss:0.9233345700843522\n",
      "train loss:0.9308977393836002\n",
      "train loss:0.8966290174064078\n",
      "train loss:1.0036132969944467\n",
      "train loss:0.7268465257136107\n",
      "train loss:0.9209665038626447\n",
      "train loss:0.8404116144025621\n",
      "train loss:0.9814401195872978\n",
      "train loss:0.9908810078417664\n",
      "train loss:0.8787608149836873\n",
      "train loss:0.7692359300576337\n",
      "train loss:0.8223877131962655\n",
      "train loss:0.9190224547610972\n",
      "train loss:0.7818191602539709\n",
      "train loss:0.9866339887763169\n",
      "train loss:0.9724859952389364\n",
      "train loss:0.8330254883985799\n",
      "train loss:0.8923909885414577\n",
      "train loss:0.9201706066625203\n",
      "train loss:0.8532254050440278\n",
      "train loss:0.9263232917241779\n",
      "train loss:0.8667242282048392\n",
      "train loss:0.8138539358631772\n",
      "train loss:1.0095230313031434\n",
      "train loss:0.8816623641675722\n",
      "train loss:0.8125590714835695\n",
      "train loss:0.9661620991157538\n",
      "train loss:0.9308795743985182\n",
      "train loss:0.6707122450373856\n",
      "train loss:0.8316181548256653\n",
      "train loss:0.8164151685511587\n",
      "train loss:0.9018359597742651\n",
      "train loss:1.0233761796287073\n",
      "train loss:0.9334652329580603\n",
      "train loss:0.8517663286025248\n",
      "train loss:1.0113814606986893\n",
      "train loss:0.7635062147619653\n",
      "train loss:0.8189276807485102\n",
      "train loss:0.7987839919471271\n",
      "train loss:0.9901080743327421\n",
      "train loss:0.7843979652009895\n",
      "train loss:0.8886677629680471\n",
      "train loss:0.8391117476367085\n",
      "train loss:0.8227204153784559\n",
      "train loss:0.8732041571226371\n",
      "train loss:0.7901040465396199\n",
      "train loss:0.898994688267298\n",
      "train loss:1.0860601472471716\n",
      "train loss:0.8973228523332578\n",
      "train loss:0.8695007060390653\n",
      "train loss:0.7724618753712236\n",
      "train loss:1.1142528114457635\n",
      "train loss:0.930673010587568\n",
      "train loss:1.0303354306924684\n",
      "train loss:1.1316866406628272\n",
      "train loss:0.8808149804971189\n",
      "train loss:0.9104894940087075\n",
      "train loss:1.1876204463211233\n",
      "train loss:0.9359849546759389\n",
      "train loss:1.0253765541898006\n",
      "train loss:0.7907042971593299\n",
      "train loss:0.6269058490357546\n",
      "train loss:0.8189381170287919\n",
      "train loss:0.8255284934383025\n",
      "train loss:0.8883822514047778\n",
      "train loss:0.8353517505588681\n",
      "train loss:0.9076209095519961\n",
      "train loss:0.8609278647932455\n",
      "train loss:0.7928311393525841\n",
      "train loss:0.784172320531735\n",
      "train loss:0.9088810990292524\n",
      "train loss:0.8783853377008402\n",
      "train loss:0.779972486348475\n",
      "train loss:1.0440141376178687\n",
      "train loss:0.8988525630648883\n",
      "train loss:0.938142000333492\n",
      "train loss:1.03935409282801\n",
      "train loss:0.7205023243513903\n",
      "train loss:0.9332486264358363\n",
      "train loss:0.8873687093533347\n",
      "train loss:0.8724336910388035\n",
      "train loss:0.7412708070602585\n",
      "train loss:0.7364664429131649\n",
      "train loss:0.9156214035683007\n",
      "train loss:0.7886430974951638\n",
      "train loss:0.8464122033389304\n",
      "train loss:0.7479137512124985\n",
      "train loss:0.91373285058354\n",
      "train loss:0.8415367405168861\n",
      "train loss:0.9358168705992429\n",
      "train loss:1.1150645045010117\n",
      "train loss:0.8334112415729623\n",
      "train loss:0.8390832199500755\n",
      "train loss:0.6003370791790773\n",
      "train loss:0.8575588193199449\n",
      "train loss:0.7305655745376629\n",
      "train loss:0.8302126092276382\n",
      "train loss:0.8812099363774692\n",
      "train loss:0.732314005249395\n",
      "train loss:0.8041583928308671\n",
      "train loss:0.822947507136804\n",
      "train loss:0.8056626589721634\n",
      "train loss:0.7244394295555325\n",
      "train loss:0.9586896000196838\n",
      "train loss:1.0473499851730252\n",
      "train loss:0.8141432227423586\n",
      "train loss:0.9547471657146531\n",
      "train loss:0.9951749488868649\n",
      "train loss:0.9757409753680618\n",
      "train loss:0.8790923667481734\n",
      "train loss:0.7962626139806187\n",
      "train loss:0.8377320559057488\n",
      "train loss:0.9055459099429782\n",
      "train loss:0.8059886649338885\n",
      "train loss:0.8381191168067476\n",
      "train loss:0.8728734672822169\n",
      "train loss:1.0032597753192103\n",
      "train loss:0.821669359412546\n",
      "train loss:0.7962178265949015\n",
      "train loss:0.9131311044665951\n",
      "train loss:0.8587792391684897\n",
      "train loss:1.006157682282772\n",
      "train loss:0.8990633211941852\n",
      "train loss:1.014215424226734\n",
      "train loss:0.9884393502990197\n",
      "train loss:0.9444169180048023\n",
      "train loss:0.9455691976616077\n",
      "train loss:0.9016392221029453\n",
      "train loss:0.7822063491081866\n",
      "train loss:0.9456157930731465\n",
      "train loss:0.8146493774434425\n",
      "train loss:1.0505235847388046\n",
      "train loss:0.9139100283357466\n",
      "train loss:1.0364519107451478\n",
      "train loss:0.807692181346853\n",
      "train loss:0.9402775281742833\n",
      "train loss:0.9169796477344526\n",
      "train loss:0.8394584412711236\n",
      "train loss:0.9252540012947926\n",
      "train loss:0.8855356864866438\n",
      "train loss:0.729074021655602\n",
      "train loss:0.9519902478037403\n",
      "train loss:0.770579478348623\n",
      "train loss:0.8091851245260747\n",
      "train loss:0.9353902937523081\n",
      "train loss:0.8290676614650198\n",
      "train loss:1.095270769060804\n",
      "train loss:0.7227821518313167\n",
      "train loss:0.9046691343149087\n",
      "train loss:0.9188256176769142\n",
      "train loss:0.9321141305126585\n",
      "train loss:0.962885497954567\n",
      "train loss:0.8666693179885671\n",
      "train loss:0.8605901568645227\n",
      "train loss:0.7783828910045155\n",
      "train loss:1.0131383438849135\n",
      "train loss:0.832828486959052\n",
      "train loss:0.8608033594999341\n",
      "train loss:0.8533351285900892\n",
      "train loss:0.93211805541862\n",
      "train loss:0.7704872095498607\n",
      "train loss:0.8361452827070647\n",
      "train loss:0.8606538506407163\n",
      "train loss:1.0465482575819287\n",
      "train loss:0.9354045888131668\n",
      "train loss:0.8247473704189859\n",
      "train loss:0.9658403741229479\n",
      "train loss:1.0284394714562288\n",
      "train loss:0.9478095661530869\n",
      "train loss:0.8228169834081946\n",
      "train loss:0.9359589201424946\n",
      "train loss:0.9768133581476947\n",
      "train loss:0.9580475650761693\n",
      "train loss:0.981643512497396\n",
      "train loss:0.9194168179804646\n",
      "train loss:0.9438341264255072\n",
      "train loss:0.8307383348153817\n",
      "train loss:0.8412216105110418\n",
      "train loss:0.7743958860073076\n",
      "train loss:0.9395165672477184\n",
      "train loss:1.0742912524185988\n",
      "train loss:1.0155627088653199\n",
      "train loss:0.7450916516673967\n",
      "train loss:1.0030383189313958\n",
      "train loss:0.8971451204787338\n",
      "train loss:0.8766870918579055\n",
      "train loss:0.8995598186915835\n",
      "train loss:1.0296200091058612\n",
      "train loss:0.8387573787166624\n",
      "train loss:1.0002878251935674\n",
      "train loss:0.8247482948494563\n",
      "train loss:0.9451718289615434\n",
      "train loss:0.9444291559159879\n",
      "train loss:0.9111213942417784\n",
      "train loss:0.883684473593166\n",
      "train loss:0.8963600901426383\n",
      "train loss:0.8339252319627836\n",
      "train loss:1.0770474900814064\n",
      "train loss:0.9092813116593564\n",
      "train loss:0.8443654994678681\n",
      "train loss:0.8600823345770511\n",
      "train loss:1.0147385781442173\n",
      "train loss:0.77221711033784\n",
      "train loss:0.8929115394169332\n",
      "train loss:0.9585843620457765\n",
      "train loss:0.7696632003346986\n",
      "train loss:0.9011666019405483\n",
      "train loss:0.8053951084665417\n",
      "train loss:0.9769827296582413\n",
      "train loss:0.8151332942969995\n",
      "train loss:0.9146564676795579\n",
      "train loss:0.9645837199179994\n",
      "train loss:0.8032095499802332\n",
      "train loss:0.8791157329736627\n",
      "train loss:0.8713793464500751\n",
      "train loss:0.9796727269758679\n",
      "train loss:0.9658254136705385\n",
      "train loss:1.0062611627189644\n",
      "train loss:0.9001528974246555\n",
      "train loss:0.8093406736475521\n",
      "train loss:0.8860311075716464\n",
      "train loss:0.8821781595458528\n",
      "train loss:1.0558175389129703\n",
      "train loss:0.8045151590509113\n",
      "train loss:1.0433186128998344\n",
      "train loss:0.8346467749520465\n",
      "train loss:0.8996544510808105\n",
      "train loss:0.8160168134778725\n",
      "train loss:0.9058810977503601\n",
      "train loss:0.9066076403713066\n",
      "train loss:0.9318607846470219\n",
      "train loss:0.9409715446660363\n",
      "train loss:0.9533389096404477\n",
      "train loss:0.9779957730263031\n",
      "train loss:0.908698215969746\n",
      "train loss:0.7635622113718779\n",
      "train loss:0.7874390552338767\n",
      "train loss:1.0382158792505216\n",
      "train loss:1.0544138011863589\n",
      "train loss:0.8937546422101269\n",
      "train loss:0.7047064958264297\n",
      "train loss:0.8659739984961261\n",
      "train loss:0.8808855688748826\n",
      "train loss:0.9665896460258279\n",
      "train loss:0.9780529623408534\n",
      "train loss:0.9074388294322384\n",
      "train loss:1.0082335408883722\n",
      "train loss:0.7901101890258544\n",
      "train loss:0.8308319082182287\n",
      "train loss:1.018515616264593\n",
      "train loss:0.8255205281004885\n",
      "train loss:0.7120039924672268\n",
      "train loss:0.9601470351139638\n",
      "train loss:0.8158221985374119\n",
      "train loss:0.9382958650457605\n",
      "train loss:0.8665413402486084\n",
      "train loss:0.8530416522524747\n",
      "train loss:0.8629076666969998\n",
      "train loss:0.992272935440073\n",
      "train loss:0.8572716955334182\n",
      "train loss:0.8027452816784837\n",
      "train loss:0.7960426557127737\n",
      "train loss:1.0410163282531668\n",
      "train loss:0.7763100094524945\n",
      "train loss:0.8667667983591498\n",
      "train loss:0.9104020675916032\n",
      "train loss:1.1072389805899743\n",
      "train loss:0.825929271128352\n",
      "train loss:0.7280137992292822\n",
      "train loss:0.9798839511141094\n",
      "train loss:0.9014904484929134\n",
      "train loss:0.9050946500959944\n",
      "train loss:0.8144976503924067\n",
      "train loss:0.9120293268631718\n",
      "train loss:0.930905736512965\n",
      "train loss:0.918172312061514\n",
      "train loss:1.0190053031329136\n",
      "train loss:0.9416742684995226\n",
      "train loss:0.8410755731580305\n",
      "train loss:0.7297737724618447\n",
      "train loss:0.9372660647347283\n",
      "train loss:1.0549766372017115\n",
      "train loss:0.9085293457325528\n",
      "train loss:0.8225026167503277\n",
      "train loss:0.8618564806264751\n",
      "train loss:0.740564895917813\n",
      "train loss:0.8930169259781957\n",
      "train loss:0.8755476582423211\n",
      "train loss:0.7345923319871016\n",
      "train loss:1.0260840474683297\n",
      "train loss:0.7673535407178653\n",
      "train loss:1.0303990973814385\n",
      "train loss:1.095589776846336\n",
      "train loss:0.9265148252893092\n",
      "train loss:1.010659137416861\n",
      "train loss:0.9045564540217231\n",
      "train loss:0.8333223388926114\n",
      "train loss:0.8951412909001464\n",
      "train loss:0.8056500418038022\n",
      "train loss:0.833393301003899\n",
      "train loss:0.9010148033376016\n",
      "train loss:0.9210272071543945\n",
      "train loss:1.0772013801526379\n",
      "train loss:0.9695847099187697\n",
      "train loss:0.9083015156339707\n",
      "train loss:0.7175766166594981\n",
      "train loss:0.969913762056042\n",
      "train loss:0.8540393811830058\n",
      "train loss:1.024926451167416\n",
      "train loss:0.9993757700605451\n",
      "train loss:0.9172121929558097\n",
      "train loss:0.8700934785022676\n",
      "train loss:0.9541829194212412\n",
      "train loss:0.8827900477430093\n",
      "train loss:0.696488343010367\n",
      "train loss:1.0894653286485656\n",
      "train loss:0.9762442169634036\n",
      "train loss:0.8322741563807549\n",
      "train loss:0.6576463037740844\n",
      "train loss:0.804068728486562\n",
      "train loss:0.9714428860847241\n",
      "train loss:0.9055927177429335\n",
      "train loss:0.9288040509599063\n",
      "train loss:1.0186111115503034\n",
      "train loss:0.8062023803777874\n",
      "train loss:0.8747949178897624\n",
      "train loss:0.97590126521493\n",
      "train loss:0.9986531903346512\n",
      "train loss:0.8942701582525795\n",
      "train loss:0.8595846532696966\n",
      "train loss:0.9569171253663487\n",
      "train loss:0.7135346012452979\n",
      "train loss:0.9157873929560322\n",
      "train loss:1.0419237009107023\n",
      "train loss:0.78002786256049\n",
      "train loss:0.8541001850447172\n",
      "train loss:1.1149115590464338\n",
      "train loss:0.7735947106994154\n",
      "train loss:1.005808488086556\n",
      "train loss:0.7062431032552949\n",
      "train loss:0.9849255280179876\n",
      "train loss:0.8349142796456919\n",
      "train loss:0.8183572587611642\n",
      "train loss:0.8691325342933273\n",
      "train loss:1.135332461874277\n",
      "train loss:0.9355409249079747\n",
      "train loss:0.9626523387790116\n",
      "train loss:0.971001773977767\n",
      "train loss:0.8162994803208159\n",
      "train loss:0.7971443711906331\n",
      "train loss:0.9053793247848063\n",
      "train loss:0.8778229638917362\n",
      "train loss:0.7569189309732025\n",
      "train loss:0.9398030246090362\n",
      "train loss:0.846878261849909\n",
      "train loss:0.9377768504070392\n",
      "train loss:0.9751593583754324\n",
      "train loss:0.9587475338624094\n",
      "train loss:0.9861716711960224\n",
      "train loss:0.9962056886026849\n",
      "train loss:1.0006580476366687\n",
      "train loss:0.8454011461150982\n",
      "train loss:0.9467043643505078\n",
      "train loss:1.0721511086532098\n",
      "train loss:0.9433373906022777\n",
      "train loss:0.8829636131251383\n",
      "train loss:0.9893110558803216\n",
      "train loss:0.8094191476730839\n",
      "train loss:0.8779373108351284\n",
      "train loss:0.87267456732403\n",
      "train loss:0.7550513501686277\n",
      "train loss:0.9978210398698585\n",
      "train loss:0.776085366107052\n",
      "train loss:0.8937389682306557\n",
      "train loss:0.7871044754919708\n",
      "train loss:0.914908707101181\n",
      "train loss:0.8749975629027134\n",
      "train loss:0.8416611186561\n",
      "train loss:0.909665528917513\n",
      "train loss:1.0132217934513852\n",
      "train loss:0.842742069575396\n",
      "train loss:0.8968898099457516\n",
      "train loss:0.909678259883561\n",
      "train loss:0.9268350517090532\n",
      "train loss:0.8596215808035309\n",
      "train loss:0.8512421189982088\n",
      "train loss:0.9053494078500657\n",
      "train loss:0.8232313177854708\n",
      "train loss:0.7338448799304542\n",
      "train loss:0.8701059882538179\n",
      "train loss:0.9195649493654776\n",
      "train loss:0.9444360869467985\n",
      "train loss:0.9827396057789746\n",
      "train loss:0.8069238347827488\n",
      "train loss:0.7991357792646621\n",
      "train loss:0.7981634463663622\n",
      "train loss:0.859950867269727\n",
      "train loss:0.8443234240648093\n",
      "train loss:0.8948546990016445\n",
      "train loss:0.757302616740064\n",
      "train loss:0.9059506056753419\n",
      "train loss:0.9614670356135542\n",
      "train loss:0.8327162479826582\n",
      "train loss:1.0251474970666765\n",
      "train loss:0.9069584392066203\n",
      "train loss:0.915436198519174\n",
      "train loss:0.701849404538911\n",
      "train loss:0.9717881795185367\n",
      "train loss:0.9431370936446472\n",
      "train loss:0.8624271790593079\n",
      "train loss:0.8350891597422774\n",
      "train loss:0.7977716626883837\n",
      "train loss:0.8139842041161681\n",
      "train loss:0.9353234210696789\n",
      "train loss:0.8946608226037587\n",
      "train loss:0.8967769207935309\n",
      "train loss:0.9347623909937414\n",
      "train loss:0.9779763055989875\n",
      "train loss:0.8958869842698293\n",
      "train loss:1.0070072419043266\n",
      "train loss:1.0169950076266683\n",
      "train loss:0.8718213881780084\n",
      "train loss:0.8096097603265315\n",
      "train loss:0.8764428971495528\n",
      "train loss:0.9706566793843103\n",
      "train loss:0.973188378064418\n",
      "train loss:1.0729172912663745\n",
      "train loss:0.8103215682263938\n",
      "train loss:0.8710899686095678\n",
      "train loss:0.9235501659786276\n",
      "train loss:0.9055503009964564\n",
      "train loss:0.8803760850916822\n",
      "train loss:0.8729389767931655\n",
      "train loss:0.8162060295045254\n",
      "train loss:1.055485998079806\n",
      "train loss:0.8068237337802959\n",
      "train loss:0.8894232326632765\n",
      "train loss:0.919329252990377\n",
      "train loss:0.7901410835149487\n",
      "train loss:0.7526963181026712\n",
      "train loss:0.8606595644626411\n",
      "train loss:0.8293331256509527\n",
      "train loss:0.9530364682290613\n",
      "train loss:0.7405426559746101\n",
      "train loss:0.912030366410494\n",
      "train loss:0.9539944499026725\n",
      "train loss:0.7527485134304455\n",
      "train loss:0.9225449860696737\n",
      "train loss:0.8862639515924235\n",
      "train loss:0.8222586007596889\n",
      "train loss:0.9531361676760653\n",
      "train loss:0.8852732470243115\n",
      "train loss:0.8335321394117249\n",
      "train loss:0.9683437181681847\n",
      "train loss:0.7553425229094186\n",
      "train loss:0.8978193420326624\n",
      "train loss:0.7709660523859386\n",
      "train loss:1.115727714999134\n",
      "train loss:0.9180599511101043\n",
      "train loss:0.7482724874715171\n",
      "train loss:0.7471134575609709\n",
      "train loss:0.7833088187481175\n",
      "train loss:0.8728856987544815\n",
      "train loss:0.7632868336733363\n",
      "train loss:0.8740578748159069\n",
      "train loss:0.9376267065701027\n",
      "train loss:0.8667767887016837\n",
      "=== epoch:11, train acc:0.997, test acc:0.989 ===\n",
      "train loss:1.0328176200706638\n",
      "train loss:0.9626709920566389\n",
      "train loss:0.9283553581152456\n",
      "train loss:0.9214095471751652\n",
      "train loss:0.7965132242729648\n",
      "train loss:0.7997134386558432\n",
      "train loss:0.8381439179662837\n",
      "train loss:1.0447615808023862\n",
      "train loss:0.845722033374124\n",
      "train loss:0.8944519963348884\n",
      "train loss:0.8558997195610789\n",
      "train loss:1.0054824055022744\n",
      "train loss:0.814189031431164\n",
      "train loss:0.861807120150835\n",
      "train loss:0.856582974318098\n",
      "train loss:0.9384836302483478\n",
      "train loss:0.9348434360081714\n",
      "train loss:0.9368437182565931\n",
      "train loss:0.8797863407754728\n",
      "train loss:0.812097934899004\n",
      "train loss:0.8053394663009186\n",
      "train loss:1.1482663892899985\n",
      "train loss:0.8836760683165688\n",
      "train loss:0.9763521674452573\n",
      "train loss:0.8212231959841365\n",
      "train loss:0.8436922466873545\n",
      "train loss:0.9355462348366692\n",
      "train loss:0.7339878531739843\n",
      "train loss:0.7886323015480586\n",
      "train loss:0.8112058508031627\n",
      "train loss:0.8071540340360498\n",
      "train loss:0.9441844779600436\n",
      "train loss:0.6951990958670712\n",
      "train loss:0.9582020266470057\n",
      "train loss:0.9593804037780856\n",
      "train loss:0.8661986907811277\n",
      "train loss:1.0517649471349275\n",
      "train loss:1.0366828259486802\n",
      "train loss:0.9322923773148009\n",
      "train loss:0.9551909340172099\n",
      "train loss:0.7891770942946876\n",
      "train loss:0.9601764134594446\n",
      "train loss:0.8415573419459628\n",
      "train loss:0.926488161333366\n",
      "train loss:0.8653307737514198\n",
      "train loss:0.8835323265717635\n",
      "train loss:0.6949741335735137\n",
      "train loss:0.770468392167439\n",
      "train loss:0.8268273568139953\n",
      "train loss:0.7494109251297876\n",
      "train loss:0.9541149463118341\n",
      "train loss:0.9706155776163979\n",
      "train loss:0.9768698754177021\n",
      "train loss:0.8968467652424578\n",
      "train loss:0.9762380068085028\n",
      "train loss:0.9615917077086072\n",
      "train loss:0.8356677526915425\n",
      "train loss:0.8287420940142988\n",
      "train loss:0.8341433442678821\n",
      "train loss:0.923342587976338\n",
      "train loss:0.9352954064448568\n",
      "train loss:0.8332562249065266\n",
      "train loss:0.936905742680229\n",
      "train loss:1.0811800046316933\n",
      "train loss:0.872361560155039\n",
      "train loss:1.0731774495065325\n",
      "train loss:0.867751609674007\n",
      "train loss:0.8394168577913617\n",
      "train loss:0.8492397968016051\n",
      "train loss:0.9552037210756046\n",
      "train loss:0.834854199289913\n",
      "train loss:0.8619064586232406\n",
      "train loss:0.7057211927525121\n",
      "train loss:1.1375865509360183\n",
      "train loss:0.9598312921050243\n",
      "train loss:1.007324347341817\n",
      "train loss:0.8031637413967988\n",
      "train loss:0.9968693056470957\n",
      "train loss:0.8256849290911497\n",
      "train loss:0.808301363609952\n",
      "train loss:0.9381384034425827\n",
      "train loss:0.8764481759416505\n",
      "train loss:0.7607491048810734\n",
      "train loss:0.8595818947864643\n",
      "train loss:0.7395773368140703\n",
      "train loss:0.8379316875486065\n",
      "train loss:0.8396263854322976\n",
      "train loss:0.9858426966851473\n",
      "train loss:0.8892136272784209\n",
      "train loss:0.8738296083815288\n",
      "train loss:0.9032231379863126\n",
      "train loss:0.8891565758823387\n",
      "train loss:0.7941810309100538\n",
      "train loss:0.7731936865004936\n",
      "train loss:0.8204689491918112\n",
      "train loss:0.9807524023030646\n",
      "train loss:0.8295519003023171\n",
      "train loss:0.9837091254240938\n",
      "train loss:0.8978909458408532\n",
      "train loss:0.922233445300057\n",
      "train loss:1.0762660831065691\n",
      "train loss:1.1585622245262919\n",
      "train loss:0.8231494236624844\n",
      "train loss:1.032152208643916\n",
      "train loss:0.8940099999701736\n",
      "train loss:0.7195082112106224\n",
      "train loss:0.6672860530788891\n",
      "train loss:0.9140890875798365\n",
      "train loss:0.9042403921131692\n",
      "train loss:0.8039422532446854\n",
      "train loss:0.8552855530263327\n",
      "train loss:1.0510169635432631\n",
      "train loss:1.0302801627015994\n",
      "train loss:0.8844718856289938\n",
      "train loss:0.9519622739769482\n",
      "train loss:0.8465377277274613\n",
      "train loss:0.7810219979655738\n",
      "train loss:0.6878200444033287\n",
      "train loss:0.8988972985227849\n",
      "train loss:0.7841529236635894\n",
      "train loss:0.8718117596080682\n",
      "train loss:0.8351488783470566\n",
      "train loss:0.771568824310715\n",
      "train loss:0.8761479341534104\n",
      "train loss:0.9440990020181761\n",
      "train loss:1.0834097612806537\n",
      "train loss:1.0275867020197065\n",
      "train loss:0.9171862966141822\n",
      "train loss:0.9206047717851291\n",
      "train loss:1.102816931613633\n",
      "train loss:0.7845028736731149\n",
      "train loss:0.932148445309711\n",
      "train loss:0.8616648490631015\n",
      "train loss:0.7214454512947132\n",
      "train loss:0.6333273055539526\n",
      "train loss:1.0552456642816317\n",
      "train loss:1.003787019980032\n",
      "train loss:0.8921594533649766\n",
      "train loss:0.8127325410731092\n",
      "train loss:0.860478988257624\n",
      "train loss:0.9238752214875121\n",
      "train loss:0.799293476836521\n",
      "train loss:0.8123667325475091\n",
      "train loss:0.8307661926475515\n",
      "train loss:0.8654392090055041\n",
      "train loss:0.7944262921365671\n",
      "train loss:0.7770309996314311\n",
      "train loss:0.903135417729043\n",
      "train loss:0.818251368359616\n",
      "train loss:1.0029112570372936\n",
      "train loss:0.8708971348590651\n",
      "train loss:0.7811859763529708\n",
      "train loss:0.9347570547757933\n",
      "train loss:0.9849841782759708\n",
      "train loss:0.7704557379344494\n",
      "train loss:0.9767676947515642\n",
      "train loss:0.99097331500358\n",
      "train loss:0.9320935522968256\n",
      "train loss:0.9043271010595292\n",
      "train loss:0.8934343196112635\n",
      "train loss:0.7380340907935508\n",
      "train loss:0.8418368981951435\n",
      "train loss:0.6640679818971202\n",
      "train loss:0.9917128644115745\n",
      "train loss:0.934864565627976\n",
      "train loss:0.8319765323263774\n",
      "train loss:0.9721035883114125\n",
      "train loss:1.0376320088442297\n",
      "train loss:1.110788463295094\n",
      "train loss:0.8810535991667899\n",
      "train loss:0.7816992347359941\n",
      "train loss:0.9901091697081363\n",
      "train loss:0.8300316640208999\n",
      "train loss:1.005379568457804\n",
      "train loss:0.8485813444161959\n",
      "train loss:0.8234345593113994\n",
      "train loss:0.9357740660020702\n",
      "train loss:0.867627264425796\n",
      "train loss:0.9097351560291385\n",
      "train loss:0.9891223146282891\n",
      "train loss:0.941522631436482\n",
      "train loss:1.020280041329619\n",
      "train loss:0.829477917529061\n",
      "train loss:0.8927584908860353\n",
      "train loss:0.9308306327015242\n",
      "train loss:0.8912009182076317\n",
      "train loss:0.8877451143918178\n",
      "train loss:0.8571010760301732\n",
      "train loss:0.687187757625798\n",
      "train loss:0.7853960425371479\n",
      "train loss:1.0665063440699702\n",
      "train loss:0.9433933395989662\n",
      "train loss:0.6924079000509517\n",
      "train loss:0.961950342350731\n",
      "train loss:0.8640817706434539\n",
      "train loss:0.9417993273865105\n",
      "train loss:0.8353443870148665\n",
      "train loss:0.9463924816229663\n",
      "train loss:0.8382153198862866\n",
      "train loss:1.0471091884942514\n",
      "train loss:0.8533418160169545\n",
      "train loss:0.8966281352841368\n",
      "train loss:0.8485799117712878\n",
      "train loss:0.8209965773636864\n",
      "train loss:0.8477170001627771\n",
      "train loss:0.8822557157233907\n",
      "train loss:0.9311148722588993\n",
      "train loss:0.848789354992807\n",
      "train loss:0.8028855290561223\n",
      "train loss:0.9141529258882919\n",
      "train loss:0.8891880618210641\n",
      "train loss:0.8154169654130625\n",
      "train loss:0.7281995661391591\n",
      "train loss:0.933225201245157\n",
      "train loss:1.0333184961534387\n",
      "train loss:0.8246682486658388\n",
      "train loss:0.9215143578616468\n",
      "train loss:0.864033547903999\n",
      "train loss:0.791146949111464\n",
      "train loss:0.8557865743909713\n",
      "train loss:0.9606118555122272\n",
      "train loss:0.9272948618310336\n",
      "train loss:0.889778358472314\n",
      "train loss:0.9731726637039828\n",
      "train loss:0.7654741629815294\n",
      "train loss:0.9980207428349418\n",
      "train loss:0.8516351573373897\n",
      "train loss:0.8887000704829822\n",
      "train loss:0.7734319596851459\n",
      "train loss:0.9127719408493428\n",
      "train loss:0.8996619847542304\n",
      "train loss:0.9314487233211699\n",
      "train loss:0.9162196250671515\n",
      "train loss:0.9176495388184006\n",
      "train loss:0.8799963672463992\n",
      "train loss:1.0013091417006883\n",
      "train loss:1.0287333038694761\n",
      "train loss:0.9382000484670718\n",
      "train loss:0.7426960920999397\n",
      "train loss:0.8879192527756499\n",
      "train loss:0.8719139568460461\n",
      "train loss:0.9315575246702003\n",
      "train loss:0.8028795750190667\n",
      "train loss:0.8274845512208913\n",
      "train loss:0.8346958231241196\n",
      "train loss:0.840295742061564\n",
      "train loss:0.9287741363572839\n",
      "train loss:0.8170887290089616\n",
      "train loss:0.8772045283600304\n",
      "train loss:0.9232037167744782\n",
      "train loss:0.9553818868072953\n",
      "train loss:0.8870658307239624\n",
      "train loss:0.9768619172144577\n",
      "train loss:0.8464493941081543\n",
      "train loss:1.0124651297984182\n",
      "train loss:0.8366215876603974\n",
      "train loss:0.9327510378792723\n",
      "train loss:0.8663077330983582\n",
      "train loss:0.8263821729651158\n",
      "train loss:0.9211384013642097\n",
      "train loss:0.9933284415729622\n",
      "train loss:0.8697035609222854\n",
      "train loss:0.8966656138075777\n",
      "train loss:0.89226403003342\n",
      "train loss:0.7664748822901777\n",
      "train loss:0.93160488994324\n",
      "train loss:0.946160712920863\n",
      "train loss:0.9511781613847643\n",
      "train loss:0.9607239060765344\n",
      "train loss:1.016851984674599\n",
      "train loss:0.8986404087793968\n",
      "train loss:0.9116631920553958\n",
      "train loss:1.0509044007395838\n",
      "train loss:0.8404277650942157\n",
      "train loss:1.0048301235378814\n",
      "train loss:0.8833502397526419\n",
      "train loss:0.8146433066785252\n",
      "train loss:0.8958832124089996\n",
      "train loss:1.0032624480763952\n",
      "train loss:0.833855260685186\n",
      "train loss:0.8885901166014643\n",
      "train loss:0.7542987035035331\n",
      "train loss:0.7581968460644442\n",
      "train loss:1.0429114923668124\n",
      "train loss:0.8398294160804005\n",
      "train loss:0.8835489867519493\n",
      "train loss:0.8855483620445385\n",
      "train loss:0.8602443412466282\n",
      "train loss:0.7981965106384195\n",
      "train loss:0.984600803039614\n",
      "train loss:0.8922719533950141\n",
      "train loss:1.0134240903528007\n",
      "train loss:0.919080633867999\n",
      "train loss:0.8672717955516589\n",
      "train loss:0.849506888146069\n",
      "train loss:0.9238968422903439\n",
      "train loss:0.9666669978790022\n",
      "train loss:0.913044986302047\n",
      "train loss:0.8473644306454071\n",
      "train loss:0.8930809521367319\n",
      "train loss:0.8258678017787824\n",
      "train loss:1.0269340200043349\n",
      "train loss:1.0029410498783087\n",
      "train loss:0.8187817536957824\n",
      "train loss:0.8613849841572745\n",
      "train loss:0.8062281175648701\n",
      "train loss:0.8788119578074312\n",
      "train loss:0.9001166313787304\n",
      "train loss:0.792924694750497\n",
      "train loss:0.7639469697578949\n",
      "train loss:1.0506821111670568\n",
      "train loss:0.8540853847652308\n",
      "train loss:0.9132551317193759\n",
      "train loss:0.7202095885421231\n",
      "train loss:0.9935806074149727\n",
      "train loss:1.0304372274032207\n",
      "train loss:0.8410004044743771\n",
      "train loss:0.7291427507981113\n",
      "train loss:0.8914213552455051\n",
      "train loss:0.6636565929941648\n",
      "train loss:0.9513446625456994\n",
      "train loss:0.8521615628866919\n",
      "train loss:0.8511542663383196\n",
      "train loss:0.7085653307003653\n",
      "train loss:0.9723372985803277\n",
      "train loss:0.926299017779198\n",
      "train loss:0.84704862087563\n",
      "train loss:0.9638761666566638\n",
      "train loss:0.8775218853549283\n",
      "train loss:0.840564750941728\n",
      "train loss:0.8092109091645459\n",
      "train loss:0.8987457975990019\n",
      "train loss:0.8893645913904706\n",
      "train loss:0.9063177685101373\n",
      "train loss:0.7819105295333152\n",
      "train loss:0.9460939007324916\n",
      "train loss:0.9382168975155827\n",
      "train loss:0.8959996906057889\n",
      "train loss:0.8001363317794727\n",
      "train loss:0.8837372684847593\n",
      "train loss:0.944231395857313\n",
      "train loss:0.9792632390071901\n",
      "train loss:0.8079486913062672\n",
      "train loss:1.0738390732376717\n",
      "train loss:1.0213565628976446\n",
      "train loss:0.8403085119956145\n",
      "train loss:0.950672349379899\n",
      "train loss:0.8122944791649881\n",
      "train loss:0.9575867015101329\n",
      "train loss:0.9034989713667517\n",
      "train loss:0.9883384853369728\n",
      "train loss:0.9115135764264454\n",
      "train loss:1.0326567978096168\n",
      "train loss:0.9501648579685191\n",
      "train loss:0.9769743307014047\n",
      "train loss:0.8053161007547048\n",
      "train loss:0.8839246074732655\n",
      "train loss:0.8738372204008849\n",
      "train loss:0.8814042879738397\n",
      "train loss:0.9514623415952529\n",
      "train loss:0.9743112811097063\n",
      "train loss:1.0979170433251506\n",
      "train loss:0.9204249701701712\n",
      "train loss:0.8148376808818034\n",
      "train loss:0.9450268870942571\n",
      "train loss:0.8264109594691531\n",
      "train loss:0.8474127215968456\n",
      "train loss:0.9843447135107752\n",
      "train loss:0.8675582230163711\n",
      "train loss:0.7819667248371946\n",
      "train loss:0.8229198476995719\n",
      "train loss:0.7704611314983183\n",
      "train loss:0.995217857430019\n",
      "train loss:0.8296603551386006\n",
      "train loss:0.9681416008904431\n",
      "train loss:0.8530999820009881\n",
      "train loss:0.8870962956950796\n",
      "train loss:0.883001049264013\n",
      "train loss:0.7991371520037513\n",
      "train loss:0.7866763086763323\n",
      "train loss:0.8828872503964398\n",
      "train loss:1.0000158486994855\n",
      "train loss:0.6415979626366379\n",
      "train loss:0.9784615831003625\n",
      "train loss:0.956868562752699\n",
      "train loss:0.8582163232974641\n",
      "train loss:0.9152335285889648\n",
      "train loss:0.7995887870323621\n",
      "train loss:0.8993161541011254\n",
      "train loss:0.8146940110047599\n",
      "train loss:1.0320612880750843\n",
      "train loss:0.9269466557221672\n",
      "train loss:0.8286793102322474\n",
      "train loss:0.927543435403663\n",
      "train loss:0.9543914300833063\n",
      "train loss:0.9333288141017572\n",
      "train loss:0.8810351180573456\n",
      "train loss:0.9184950641293984\n",
      "train loss:0.8629372389269413\n",
      "train loss:0.8055666959226894\n",
      "train loss:0.8973481344115661\n",
      "train loss:0.8192460591409924\n",
      "train loss:0.8716024874020114\n",
      "train loss:0.9176670560608841\n",
      "train loss:0.818237941656941\n",
      "train loss:0.7648018810576827\n",
      "train loss:0.974319976436581\n",
      "train loss:0.982554411364298\n",
      "train loss:0.8131734444293762\n",
      "train loss:0.830291293215632\n",
      "train loss:0.9996502701677037\n",
      "train loss:0.9558035536725886\n",
      "train loss:0.8348628320218243\n",
      "train loss:0.9054165988753615\n",
      "train loss:0.9906355540177562\n",
      "train loss:0.7732516689669308\n",
      "train loss:0.8279671931874969\n",
      "train loss:0.9831802948059554\n",
      "train loss:0.9332382954733452\n",
      "train loss:1.1120878848681517\n",
      "train loss:0.7888536070561893\n",
      "train loss:0.7947926935010825\n",
      "train loss:0.8948159117909354\n",
      "train loss:0.8830206423629174\n",
      "train loss:0.8884618568323203\n",
      "train loss:0.8286623430262875\n",
      "train loss:0.9070664710550163\n",
      "train loss:0.8130867531032716\n",
      "train loss:0.9390716454270721\n",
      "train loss:0.7943380889234417\n",
      "train loss:0.7726744566570783\n",
      "train loss:0.9906518240282947\n",
      "train loss:0.6689178324435053\n",
      "train loss:0.756648222925406\n",
      "train loss:0.9331280174015106\n",
      "train loss:0.8700465683732703\n",
      "train loss:1.074742790601484\n",
      "train loss:0.8297308469563663\n",
      "train loss:0.7885563505228762\n",
      "train loss:0.8237286479547621\n",
      "train loss:0.9955251973865858\n",
      "train loss:0.9305546407594601\n",
      "train loss:0.9558928467862394\n",
      "train loss:0.8026221491190845\n",
      "train loss:0.7826398140684044\n",
      "train loss:0.9218310747180477\n",
      "train loss:0.9805448711249266\n",
      "train loss:0.9573637339110622\n",
      "train loss:0.8969458063507076\n",
      "train loss:0.8501701936977983\n",
      "train loss:0.8085551558677844\n",
      "train loss:0.9816637947683023\n",
      "train loss:1.0228252082925195\n",
      "train loss:0.9119687730903735\n",
      "train loss:0.9996354178602721\n",
      "train loss:0.8871065480858504\n",
      "train loss:1.0631731917037868\n",
      "train loss:0.975988724700469\n",
      "train loss:1.0614664898401807\n",
      "train loss:0.7354315034281853\n",
      "train loss:0.7191453646594184\n",
      "train loss:0.915412869434132\n",
      "train loss:0.8508079674693368\n",
      "train loss:0.8333469434192128\n",
      "train loss:0.8782346420919496\n",
      "train loss:0.8449859134670163\n",
      "train loss:0.7475915909110478\n",
      "train loss:0.9978858678166519\n",
      "train loss:0.8757782924547132\n",
      "train loss:0.8517904030987076\n",
      "train loss:0.9896124034842038\n",
      "train loss:0.9839115952601654\n",
      "train loss:0.752597896459813\n",
      "train loss:0.9416527383060397\n",
      "train loss:0.8076885684546609\n",
      "train loss:0.9782703864845405\n",
      "train loss:0.8432804169474182\n",
      "train loss:0.7959163099085981\n",
      "train loss:0.9918676974092735\n",
      "train loss:0.8218495090076244\n",
      "train loss:0.8700610599313362\n",
      "train loss:0.8134092878600527\n",
      "train loss:0.8755347717245412\n",
      "train loss:0.8280711745319469\n",
      "train loss:0.829140757454821\n",
      "train loss:0.8663044446031306\n",
      "train loss:0.8703064563119005\n",
      "train loss:0.9070949892105205\n",
      "train loss:0.9203844586795462\n",
      "train loss:1.0592597042831344\n",
      "train loss:0.8415382610656853\n",
      "train loss:0.7606818073819297\n",
      "train loss:0.9746463350676611\n",
      "train loss:0.769703711652389\n",
      "train loss:0.9329994988343031\n",
      "train loss:0.8122947638026399\n",
      "train loss:0.991238761648202\n",
      "train loss:0.8120440811367717\n",
      "train loss:0.9790274078355994\n",
      "train loss:0.8217598820298232\n",
      "train loss:0.934639017896512\n",
      "train loss:0.8544849475713449\n",
      "train loss:0.9328169738244041\n",
      "train loss:0.9959174050050418\n",
      "train loss:0.9281125572557386\n",
      "train loss:1.0390068705058935\n",
      "train loss:0.9606794602092122\n",
      "train loss:0.808733869830723\n",
      "train loss:0.8519710845811491\n",
      "train loss:0.8189248365713719\n",
      "train loss:0.8077803516163081\n",
      "train loss:0.8552653196987379\n",
      "train loss:0.7314761340735167\n",
      "train loss:0.7798218181396075\n",
      "train loss:1.038319436956953\n",
      "train loss:0.9029755893883717\n",
      "train loss:0.8038816420721294\n",
      "train loss:0.8973279769533602\n",
      "train loss:0.8014844557661363\n",
      "train loss:0.8932346876327366\n",
      "train loss:0.9844019868490256\n",
      "train loss:0.951066999360136\n",
      "train loss:0.7803276755643208\n",
      "train loss:0.8919150742912783\n",
      "train loss:0.8733625820882519\n",
      "train loss:0.7610788363703143\n",
      "train loss:0.7427369584784251\n",
      "train loss:0.9368553442696798\n",
      "train loss:0.7399147313846428\n",
      "train loss:0.95202697552234\n",
      "train loss:1.070359921027114\n",
      "train loss:0.7665120559509413\n",
      "train loss:0.8743243082040302\n",
      "train loss:0.8759304035772754\n",
      "train loss:0.9095783144350753\n",
      "train loss:0.8683629008397221\n",
      "train loss:0.8976406297870275\n",
      "train loss:0.7705209562219935\n",
      "train loss:0.879627312201406\n",
      "train loss:0.8807181282101793\n",
      "train loss:0.8441240157879242\n",
      "train loss:0.9877902864617449\n",
      "train loss:0.8990529470408218\n",
      "train loss:1.0234020100533638\n",
      "train loss:0.7273822347508309\n",
      "train loss:0.677625424699933\n",
      "train loss:0.8526095917179515\n",
      "train loss:0.9312904316434146\n",
      "train loss:0.8507739167680662\n",
      "train loss:0.8218827018208456\n",
      "train loss:0.7521511259401684\n",
      "train loss:0.8825133298126856\n",
      "train loss:0.8090794874780698\n",
      "train loss:0.9985447462371666\n",
      "train loss:0.9877969958336918\n",
      "train loss:0.7588230201452966\n",
      "train loss:1.072904995018771\n",
      "train loss:0.9396759196609229\n",
      "train loss:0.9325148335837171\n",
      "train loss:0.7154088407992469\n",
      "train loss:0.7678813109229785\n",
      "train loss:0.869898433667997\n",
      "train loss:0.8697791630755897\n",
      "train loss:0.9792053280180957\n",
      "train loss:0.8531158811051317\n",
      "train loss:0.9228413683323621\n",
      "train loss:0.9908223775677869\n",
      "train loss:0.8725151134621464\n",
      "train loss:0.8993561724253293\n",
      "train loss:0.9744326771941229\n",
      "train loss:0.9893265725143157\n",
      "train loss:0.8387179568603426\n",
      "train loss:0.8759171934959725\n",
      "train loss:0.934680552292627\n",
      "train loss:0.9704847332129493\n",
      "train loss:0.8504323793081773\n",
      "train loss:0.7810742716679464\n",
      "train loss:1.0320111440391695\n",
      "train loss:0.8183067399476265\n",
      "train loss:0.7988904880460916\n",
      "train loss:0.7685599403114424\n",
      "train loss:0.8220105127579774\n",
      "train loss:1.0259357532506643\n",
      "train loss:0.873786495094764\n",
      "train loss:0.7302625704348381\n",
      "train loss:0.8310123883120041\n",
      "train loss:0.9641734277533902\n",
      "train loss:0.8512840508497729\n",
      "train loss:0.9209585541299065\n",
      "train loss:0.9127694126206437\n",
      "train loss:0.8668366243412828\n",
      "train loss:0.8072217928627975\n",
      "train loss:0.8363247340353581\n",
      "train loss:0.8063261784130036\n",
      "train loss:0.880858079195559\n",
      "train loss:0.9602534385308121\n",
      "train loss:0.7241819491041993\n",
      "train loss:0.8784873541005773\n",
      "train loss:0.9103917873714186\n",
      "train loss:0.7731649327057282\n",
      "=== epoch:12, train acc:0.993, test acc:0.991 ===\n",
      "train loss:0.8972584354470524\n",
      "train loss:0.9757977362085846\n",
      "train loss:0.7959452210434246\n",
      "train loss:0.8145136473448996\n",
      "train loss:0.9240070087026737\n",
      "train loss:0.8819250107372922\n",
      "train loss:0.8834170684150956\n",
      "train loss:0.8464414686327814\n",
      "train loss:0.8937659627373594\n",
      "train loss:0.839469443742737\n",
      "train loss:0.9955617092915547\n",
      "train loss:0.9639659057949312\n",
      "train loss:0.9889230602784802\n",
      "train loss:0.8403436642358443\n",
      "train loss:0.863977228888902\n",
      "train loss:0.8287351634633328\n",
      "train loss:0.9009639472417796\n",
      "train loss:0.7814074348681763\n",
      "train loss:0.9470405666686358\n",
      "train loss:0.8449342853856588\n",
      "train loss:0.9477934026196617\n",
      "train loss:0.8802946492287346\n",
      "train loss:1.013014250401524\n",
      "train loss:0.994326663921528\n",
      "train loss:0.7727860611199135\n",
      "train loss:1.0113564982615741\n",
      "train loss:1.013531406147205\n",
      "train loss:0.971217445405657\n",
      "train loss:0.9185906414052474\n",
      "train loss:0.8090529459950605\n",
      "train loss:0.852046529088782\n",
      "train loss:0.9057145660544947\n",
      "train loss:0.8325410228641097\n",
      "train loss:0.7733791235956649\n",
      "train loss:0.7931046972737346\n",
      "train loss:0.8431849112855879\n",
      "train loss:0.7903950908027112\n",
      "train loss:1.000254465844555\n",
      "train loss:0.8009126877040916\n",
      "train loss:0.740638945688792\n",
      "train loss:0.9434418443787991\n",
      "train loss:0.9994120497161123\n",
      "train loss:0.8746129238115222\n",
      "train loss:0.9225657128170132\n",
      "train loss:0.9888330239083863\n",
      "train loss:0.8335528425215085\n",
      "train loss:0.7468596193276046\n",
      "train loss:0.9542759240798133\n",
      "train loss:0.9049904727505214\n",
      "train loss:0.8871782757488463\n",
      "train loss:0.9127895152006426\n",
      "train loss:0.9441522949951087\n",
      "train loss:0.8247824975204161\n",
      "train loss:0.8810449810759065\n",
      "train loss:0.995003413487359\n",
      "train loss:0.9327259754115489\n",
      "train loss:0.8276236235341891\n",
      "train loss:0.7182294099231811\n",
      "train loss:1.0263500435649624\n",
      "train loss:0.8912371721303542\n",
      "train loss:0.9428012245345664\n",
      "train loss:1.0458644097306278\n",
      "train loss:0.8349936863148991\n",
      "train loss:0.8439801648989212\n",
      "train loss:1.0183279589725012\n",
      "train loss:0.882384341485593\n",
      "train loss:0.8638935951068268\n",
      "train loss:0.7424080287061686\n",
      "train loss:0.9313793136361764\n",
      "train loss:0.959477908132493\n",
      "train loss:0.7692207384418879\n",
      "train loss:0.9395437942372286\n",
      "train loss:0.7386467985421159\n",
      "train loss:0.9668499917440684\n",
      "train loss:0.8774837933882962\n",
      "train loss:1.0793119001749565\n",
      "train loss:0.9699323299803947\n",
      "train loss:0.7994975966901129\n",
      "train loss:0.8650703258357717\n",
      "train loss:0.8580572476229937\n",
      "train loss:0.7381186437682602\n",
      "train loss:0.9849934176932119\n",
      "train loss:0.9487573604358048\n",
      "train loss:0.9187526334382774\n",
      "train loss:0.8879913506512476\n",
      "train loss:1.0423845964937846\n",
      "train loss:1.1041025372316797\n",
      "train loss:0.7925233640291692\n",
      "train loss:0.8062670177421767\n",
      "train loss:0.9916316166539683\n",
      "train loss:0.9057717813075092\n",
      "train loss:0.9258491075672093\n",
      "train loss:0.8044643887941261\n",
      "train loss:0.7772479912378426\n",
      "train loss:0.9419155340718075\n",
      "train loss:0.8700893178292054\n",
      "train loss:0.881695212720613\n",
      "train loss:0.8861234310009739\n",
      "train loss:0.9356541992203262\n",
      "train loss:0.9001994594387438\n",
      "train loss:0.8886616368558508\n",
      "train loss:1.104845781700427\n",
      "train loss:0.8486663024699928\n",
      "train loss:0.9315607363774485\n",
      "train loss:0.7873994020134448\n",
      "train loss:1.0160387738952212\n",
      "train loss:0.8104595777961727\n",
      "train loss:1.012613283529769\n",
      "train loss:0.7590265035190238\n",
      "train loss:0.8385650248837512\n",
      "train loss:1.0377841681505104\n",
      "train loss:0.7902474218233942\n",
      "train loss:1.0806772186704343\n",
      "train loss:0.9586715163959237\n",
      "train loss:0.9541319565865919\n",
      "train loss:0.8522789512356187\n",
      "train loss:0.8196335537080961\n",
      "train loss:0.9817537236930481\n",
      "train loss:0.768880920503329\n",
      "train loss:0.8591867203237443\n",
      "train loss:0.8150520876966955\n",
      "train loss:0.7630151057512635\n",
      "train loss:0.8843784250476517\n",
      "train loss:1.0348517149973366\n",
      "train loss:0.786874073846768\n",
      "train loss:0.8908266554083193\n",
      "train loss:0.9496065293085697\n",
      "train loss:0.871499343300341\n",
      "train loss:0.766525176765979\n",
      "train loss:0.7267992163299549\n",
      "train loss:0.7948334973467602\n",
      "train loss:0.7995384677383062\n",
      "train loss:0.967107761805828\n",
      "train loss:0.871433876139283\n",
      "train loss:0.8357851018390154\n",
      "train loss:0.7657718770363803\n",
      "train loss:0.9401592347706856\n",
      "train loss:0.780753806236187\n",
      "train loss:1.0148956968764444\n",
      "train loss:0.8695231719181131\n",
      "train loss:0.8840165251417793\n",
      "train loss:0.7399438618417895\n",
      "train loss:0.7718267866728594\n",
      "train loss:0.959126459190825\n",
      "train loss:0.9511920062605874\n",
      "train loss:0.7774365729885566\n",
      "train loss:0.9572119859227364\n",
      "train loss:1.127999103271615\n",
      "train loss:0.7990758714132702\n",
      "train loss:0.878537942582159\n",
      "train loss:0.8751465532655118\n",
      "train loss:1.0314536728183947\n",
      "train loss:0.9330291309791819\n",
      "train loss:0.8415294496924288\n",
      "train loss:0.9988743445969219\n",
      "train loss:0.7344589300517802\n",
      "train loss:0.9677264691414145\n",
      "train loss:0.9862221910081991\n",
      "train loss:1.0111903391070927\n",
      "train loss:0.7971997987423322\n",
      "train loss:0.820021007890322\n",
      "train loss:0.8569444445514783\n",
      "train loss:0.922110831118646\n",
      "train loss:0.8651016137615974\n",
      "train loss:0.8145930637480724\n",
      "train loss:0.9271177248016216\n",
      "train loss:0.7577512300592488\n",
      "train loss:0.9410787253139028\n",
      "train loss:0.8692144396193991\n",
      "train loss:0.9596772723760318\n",
      "train loss:0.8628318770369598\n",
      "train loss:0.768207479846571\n",
      "train loss:0.9002658053383494\n",
      "train loss:0.7911523152928281\n",
      "train loss:0.8200676205135145\n",
      "train loss:0.8673209218616738\n",
      "train loss:0.9254691113205052\n",
      "train loss:0.7542724970094163\n",
      "train loss:0.8396287537666818\n",
      "train loss:0.848207116194489\n",
      "train loss:0.8818296380327167\n",
      "train loss:1.0327635233119168\n",
      "train loss:0.9285959122570996\n",
      "train loss:0.7254695964806486\n",
      "train loss:0.886101429605218\n",
      "train loss:0.8612203278733306\n",
      "train loss:0.9608958562361845\n",
      "train loss:0.8520327333145322\n",
      "train loss:0.8699405134876153\n",
      "train loss:0.8914864588609369\n",
      "train loss:0.9675180726624099\n",
      "train loss:0.8177524285778989\n",
      "train loss:1.0044575289392303\n",
      "train loss:0.9643907399654029\n",
      "train loss:0.8358676157571261\n",
      "train loss:0.818310532226584\n",
      "train loss:0.8835087772189948\n",
      "train loss:0.7741929136481026\n",
      "train loss:0.8804667640938056\n",
      "train loss:0.7849796792148785\n",
      "train loss:0.7962508870802292\n",
      "train loss:0.8334442032190771\n",
      "train loss:0.919445723816729\n",
      "train loss:0.9646672557184707\n",
      "train loss:0.8766295682048856\n",
      "train loss:0.9915900562041622\n",
      "train loss:0.915929915905313\n",
      "train loss:0.8670252288021775\n",
      "train loss:0.7342068304951641\n",
      "train loss:0.828099385310304\n",
      "train loss:0.7958152376749191\n",
      "train loss:0.7835175454779345\n",
      "train loss:0.904421937434826\n",
      "train loss:0.934490544284075\n",
      "train loss:0.9562188705720203\n",
      "train loss:0.9063270287895303\n",
      "train loss:0.9490170974213394\n",
      "train loss:0.9060507300346936\n",
      "train loss:0.928189227744746\n",
      "train loss:1.032467500769152\n",
      "train loss:0.9839712015256914\n",
      "train loss:0.8230998792918066\n",
      "train loss:1.1094332089729062\n",
      "train loss:1.0681221979511115\n",
      "train loss:1.0036344746509525\n",
      "train loss:0.8331825431007812\n",
      "train loss:1.0438871338237372\n",
      "train loss:0.8934648086415297\n",
      "train loss:0.6977525545165303\n",
      "train loss:0.8312139029667819\n",
      "train loss:0.9861726892759077\n",
      "train loss:0.976436340762363\n",
      "train loss:0.9220112817745642\n",
      "train loss:0.9359224008423288\n",
      "train loss:0.7891889772362225\n",
      "train loss:0.897897253710798\n",
      "train loss:0.9540300441905956\n",
      "train loss:0.9000109271919783\n",
      "train loss:0.7557925212744988\n",
      "train loss:0.7364433164417126\n",
      "train loss:0.8912171834638011\n",
      "train loss:1.039080649822131\n",
      "train loss:1.0726408974988488\n",
      "train loss:0.8820520760393356\n",
      "train loss:0.7763626428843317\n",
      "train loss:0.9784359444968084\n",
      "train loss:1.048108896216731\n",
      "train loss:0.95247354064287\n",
      "train loss:0.9022315190492495\n",
      "train loss:1.1124869448307557\n",
      "train loss:0.7915592464205226\n",
      "train loss:0.957208398548063\n",
      "train loss:0.9454350085106401\n",
      "train loss:0.8280955979659704\n",
      "train loss:0.7558520474083429\n",
      "train loss:0.9056031468207447\n",
      "train loss:0.9575753120734153\n",
      "train loss:0.9878360798977376\n",
      "train loss:0.8110671854979232\n",
      "train loss:0.9590189582764106\n",
      "train loss:0.9211056135426032\n",
      "train loss:0.6524071532827821\n",
      "train loss:0.7756284562072367\n",
      "train loss:0.8748960855282794\n",
      "train loss:0.8256630015034004\n",
      "train loss:0.7902003848963761\n",
      "train loss:0.8155081415924521\n",
      "train loss:0.8937951151098683\n",
      "train loss:0.8471302995476185\n",
      "train loss:1.0539659613697099\n",
      "train loss:0.8603555294889929\n",
      "train loss:0.7951395172271134\n",
      "train loss:0.8439886611108175\n",
      "train loss:0.8364947631453277\n",
      "train loss:0.766202289935119\n",
      "train loss:0.9225458011986425\n",
      "train loss:0.8181432498067015\n",
      "train loss:0.7741671053913507\n",
      "train loss:0.9421465406298586\n",
      "train loss:1.0725610508705692\n",
      "train loss:0.9495597414221995\n",
      "train loss:1.0095871514153578\n",
      "train loss:0.8014375590680826\n",
      "train loss:0.9425451667524127\n",
      "train loss:0.9219044092580512\n",
      "train loss:0.7282216130464582\n",
      "train loss:0.9532855741920205\n",
      "train loss:0.7832918805803764\n",
      "train loss:0.799357620182569\n",
      "train loss:0.852073588990066\n",
      "train loss:0.8938177257945241\n",
      "train loss:0.8388903514140021\n",
      "train loss:0.944775645995778\n",
      "train loss:0.8838373878952182\n",
      "train loss:0.7558749087675334\n",
      "train loss:0.7479291050765806\n",
      "train loss:0.8615088230623948\n",
      "train loss:0.8647696081085792\n",
      "train loss:0.8156391531225082\n",
      "train loss:1.0092604347183969\n",
      "train loss:0.7654826341702571\n",
      "train loss:0.7085683437623174\n",
      "train loss:0.935622415491493\n",
      "train loss:0.8986965467590373\n",
      "train loss:0.779926048528703\n",
      "train loss:0.9897798547629618\n",
      "train loss:0.8232110353073163\n",
      "train loss:0.7959227820181003\n",
      "train loss:0.7906995493625033\n",
      "train loss:0.8988077800260684\n",
      "train loss:0.9397214998088476\n",
      "train loss:0.8564135439662138\n",
      "train loss:1.005510629120173\n",
      "train loss:0.7968487666119857\n",
      "train loss:0.9092752427842412\n",
      "train loss:0.9778354434595832\n",
      "train loss:0.9438562521508247\n",
      "train loss:0.8799279156959892\n",
      "train loss:0.8432588354426998\n",
      "train loss:0.8662591952970962\n",
      "train loss:0.9392409106990578\n",
      "train loss:0.920665387836501\n",
      "train loss:0.9054336846396464\n",
      "train loss:0.9337535219615053\n",
      "train loss:0.8157167209831218\n",
      "train loss:0.9538369913007928\n",
      "train loss:0.9673365968192563\n",
      "train loss:0.8466003512657597\n",
      "train loss:0.8597719634463163\n",
      "train loss:0.9600591538041209\n",
      "train loss:0.977994898946402\n",
      "train loss:1.024785008439098\n",
      "train loss:0.7465003037246332\n",
      "train loss:0.9328797841789995\n",
      "train loss:0.9376796387307392\n",
      "train loss:0.8067190122537269\n",
      "train loss:1.0045266853193657\n",
      "train loss:0.9447008973346077\n",
      "train loss:0.8775853525481009\n",
      "train loss:0.9231694925094689\n",
      "train loss:1.0164602742918811\n",
      "train loss:0.9850229050533738\n",
      "train loss:0.8548680251891081\n",
      "train loss:0.8163807146199334\n",
      "train loss:0.686814501152655\n",
      "train loss:0.9409686785428218\n",
      "train loss:0.8731533709694337\n",
      "train loss:0.9014777378721455\n",
      "train loss:0.8806273610656952\n",
      "train loss:0.9435692139705104\n",
      "train loss:0.8094750278176348\n",
      "train loss:0.8174054172192784\n",
      "train loss:0.7898951715547278\n",
      "train loss:0.702988732710872\n",
      "train loss:0.7264654738160587\n",
      "train loss:0.7618422484835006\n",
      "train loss:1.125349402372234\n",
      "train loss:0.6391681931678561\n",
      "train loss:0.9769346622401492\n",
      "train loss:1.0177356154821966\n",
      "train loss:1.1303405221543033\n",
      "train loss:0.8040268422012014\n",
      "train loss:0.8632393391942652\n",
      "train loss:0.8810453148941975\n",
      "train loss:1.0232641159388833\n",
      "train loss:0.8483259822285281\n",
      "train loss:0.9603217746211079\n",
      "train loss:0.8881530603494795\n",
      "train loss:0.9659057892625104\n",
      "train loss:0.8861528029912761\n",
      "train loss:0.818927262351368\n",
      "train loss:0.7074495981179965\n",
      "train loss:0.9590603946669936\n",
      "train loss:0.855292571900745\n",
      "train loss:0.8873690200088363\n",
      "train loss:0.8238130722606307\n",
      "train loss:0.9065425188745809\n",
      "train loss:0.9057971273945489\n",
      "train loss:0.9234505571069875\n",
      "train loss:0.8199485027824452\n",
      "train loss:0.8427378859271435\n",
      "train loss:0.7553214392617464\n",
      "train loss:0.9655366678478822\n",
      "train loss:0.873260805882059\n",
      "train loss:0.8119215034875426\n",
      "train loss:0.9001756532158447\n",
      "train loss:0.7158409878738675\n",
      "train loss:0.8329927079296061\n",
      "train loss:0.9924284569157509\n",
      "train loss:0.9399273869029847\n",
      "train loss:0.9481230251517963\n",
      "train loss:0.753747194740336\n",
      "train loss:0.9497493032466003\n",
      "train loss:0.7276839196114409\n",
      "train loss:0.7551612913384118\n",
      "train loss:0.7727402901349177\n",
      "train loss:0.7744210195743679\n",
      "train loss:0.8998769840283306\n",
      "train loss:0.8341088343844892\n",
      "train loss:0.6877216134414664\n",
      "train loss:0.8579382683524702\n",
      "train loss:0.8294192783911634\n",
      "train loss:0.9614225350427574\n",
      "train loss:0.9731563759038084\n",
      "train loss:0.9876027951255508\n",
      "train loss:0.7498706477273962\n",
      "train loss:0.9416579182298119\n",
      "train loss:0.8080856552079997\n",
      "train loss:0.8548968984524936\n",
      "train loss:0.8685219026851395\n",
      "train loss:0.7628423305895364\n",
      "train loss:0.9754875651409606\n",
      "train loss:0.7475969626857183\n",
      "train loss:0.8195790461067329\n",
      "train loss:0.8989591450615331\n",
      "train loss:0.9644717070024933\n",
      "train loss:0.7207926887517369\n",
      "train loss:0.9845331844726849\n",
      "train loss:0.875193171462159\n",
      "train loss:0.8691206281101047\n",
      "train loss:0.9021514088767567\n",
      "train loss:0.8190571363456225\n",
      "train loss:0.9836711617049793\n",
      "train loss:0.9622497318142494\n",
      "train loss:0.9810597302742013\n",
      "train loss:0.964550071513631\n",
      "train loss:0.8171230043361642\n",
      "train loss:0.854579649413726\n",
      "train loss:0.868018695459304\n",
      "train loss:0.802151114763674\n",
      "train loss:1.125818355671391\n",
      "train loss:0.8481910121128615\n",
      "train loss:0.9943256662761197\n",
      "train loss:0.8589466843990928\n",
      "train loss:1.1373773362190165\n",
      "train loss:0.981075891239612\n",
      "train loss:0.8077890542066435\n",
      "train loss:0.8553750250381874\n",
      "train loss:0.9699480441320136\n",
      "train loss:0.771302589468032\n",
      "train loss:1.0046520791804057\n",
      "train loss:0.8849541437483387\n",
      "train loss:0.8145287543383257\n",
      "train loss:0.7839339944439051\n",
      "train loss:0.797906856386521\n",
      "train loss:1.00499982165615\n",
      "train loss:0.8133473374169623\n",
      "train loss:0.8268830791761838\n",
      "train loss:0.8070187126540482\n",
      "train loss:0.8737384595675389\n",
      "train loss:0.969046037431515\n",
      "train loss:0.9853178236124691\n",
      "train loss:0.9110041871535346\n",
      "train loss:0.7824574202733804\n",
      "train loss:0.9167598495335533\n",
      "train loss:1.0843634123559887\n",
      "train loss:0.8554087200536202\n",
      "train loss:0.9143571757714448\n",
      "train loss:0.8739667693599645\n",
      "train loss:0.8020280522699745\n",
      "train loss:0.986133234817351\n",
      "train loss:0.8588229530956595\n",
      "train loss:0.7666445862145704\n",
      "train loss:0.8766843907856152\n",
      "train loss:0.758031377589174\n",
      "train loss:0.7590504242181157\n",
      "train loss:0.8288948731691562\n",
      "train loss:0.7353941942446924\n",
      "train loss:1.016556710433394\n",
      "train loss:0.867667916097086\n",
      "train loss:0.8725945959364054\n",
      "train loss:0.8279044886797398\n",
      "train loss:0.8808862743026006\n",
      "train loss:0.9465275147465912\n",
      "train loss:0.8098602980280694\n",
      "train loss:0.9911077264082369\n",
      "train loss:0.8323123582458551\n",
      "train loss:0.987631266124232\n",
      "train loss:1.028200579292202\n",
      "train loss:0.9923223765520846\n",
      "train loss:0.8722656028481183\n",
      "train loss:0.7973932847153408\n",
      "train loss:0.8891549644707609\n",
      "train loss:0.8967633307125653\n",
      "train loss:0.8208508884140303\n",
      "train loss:0.9136487376913206\n",
      "train loss:0.9502240007661448\n",
      "train loss:0.9309527144329944\n",
      "train loss:0.8442274102371661\n",
      "train loss:0.8708128438197258\n",
      "train loss:0.9543349650757333\n",
      "train loss:0.8653867923149703\n",
      "train loss:0.8684215429317661\n",
      "train loss:0.7849756478942587\n",
      "train loss:0.9888496595096126\n",
      "train loss:0.7736687875345742\n",
      "train loss:1.0534006081440739\n",
      "train loss:0.6957910463574701\n",
      "train loss:0.995223216582438\n",
      "train loss:0.9259488417822758\n",
      "train loss:0.9686251034069885\n",
      "train loss:0.8910128890400781\n",
      "train loss:0.9422515966564619\n",
      "train loss:0.8891882332239683\n",
      "train loss:0.9603641611697473\n",
      "train loss:0.9455390564840505\n",
      "train loss:0.9042223257015071\n",
      "train loss:0.8852878594460394\n",
      "train loss:1.066572034389993\n",
      "train loss:0.6832407357284862\n",
      "train loss:0.818219337529367\n",
      "train loss:1.000616240063117\n",
      "train loss:0.8572109440921248\n",
      "train loss:0.8316640689115087\n",
      "train loss:0.8443733606758341\n",
      "train loss:0.7950394953190338\n",
      "train loss:0.8819650381152304\n",
      "train loss:0.7280109793311216\n",
      "train loss:0.7495769377596803\n",
      "train loss:0.6984586844162735\n",
      "train loss:0.8777578286793516\n",
      "train loss:0.9537681285923287\n",
      "train loss:0.9344717318047812\n",
      "train loss:0.9827306839507863\n",
      "train loss:0.8413575723608363\n",
      "train loss:1.142928428595597\n",
      "train loss:0.8817950111916879\n",
      "train loss:0.760528884266336\n",
      "train loss:0.9617683157253826\n",
      "train loss:0.9427184930556914\n",
      "train loss:0.9124171482342721\n",
      "train loss:0.820269736989314\n",
      "train loss:0.7240717407770724\n",
      "train loss:0.941152987285807\n",
      "train loss:0.8201954058831216\n",
      "train loss:0.8564425017653029\n",
      "train loss:0.7804317572185252\n",
      "train loss:0.7845917186346968\n",
      "train loss:0.92634734547207\n",
      "train loss:1.0021327712352495\n",
      "train loss:0.9054090304500303\n",
      "train loss:0.8314558631155811\n",
      "train loss:0.806769455314546\n",
      "train loss:1.013280614024656\n",
      "train loss:1.0437139222064353\n",
      "train loss:0.9742626999645891\n",
      "train loss:0.8294929589752776\n",
      "train loss:0.7513449431678768\n",
      "train loss:0.9507810795994306\n",
      "train loss:0.8257755107691684\n",
      "train loss:0.8000320622439969\n",
      "train loss:0.8468172203261375\n",
      "train loss:0.8219339527818792\n",
      "train loss:0.9978488238747402\n",
      "train loss:0.9949255358717325\n",
      "train loss:0.9725059960097288\n",
      "train loss:0.9195408968829291\n",
      "train loss:0.9763670150270459\n",
      "train loss:1.036550691333849\n",
      "train loss:0.9689740047289837\n",
      "train loss:0.886311358590367\n",
      "train loss:0.9165249960060704\n",
      "train loss:0.8443315348524922\n",
      "train loss:0.8764624786855009\n",
      "train loss:0.7873039484358901\n",
      "train loss:0.9047287464784953\n",
      "train loss:0.9709990484971139\n",
      "train loss:0.9144129028567725\n",
      "train loss:1.0311330951208841\n",
      "train loss:0.7393012843978006\n",
      "train loss:0.6752831121439367\n",
      "train loss:0.9870341540440976\n",
      "train loss:0.8236771355140413\n",
      "train loss:0.8329642284684301\n",
      "train loss:0.7859388799312279\n",
      "train loss:1.0058859507190818\n",
      "train loss:0.8125954042728631\n",
      "train loss:0.8109421671193057\n",
      "train loss:0.7776404523710929\n",
      "train loss:0.8529795545340033\n",
      "train loss:0.8357051409859966\n",
      "train loss:0.9088543247594428\n",
      "train loss:0.8983090286424849\n",
      "train loss:0.9783300903770186\n",
      "train loss:0.7555803106102514\n",
      "train loss:0.967547253507307\n",
      "train loss:0.842996222883473\n",
      "train loss:0.8826908513108097\n",
      "train loss:0.9493096853441343\n",
      "train loss:0.906525964277124\n",
      "train loss:0.9183733569991517\n",
      "train loss:0.8053832033281861\n",
      "train loss:1.0040097492980224\n",
      "train loss:0.9185021046393632\n",
      "train loss:0.9579294992977782\n",
      "train loss:0.9688611117889248\n",
      "train loss:0.9075797388920175\n",
      "train loss:0.9270346255603685\n",
      "train loss:0.9089140633734136\n",
      "train loss:0.9245424336058803\n",
      "=== epoch:13, train acc:0.996, test acc:0.987 ===\n",
      "train loss:0.8261822966860817\n",
      "train loss:0.8028398137932399\n",
      "train loss:0.8619370883086271\n",
      "train loss:0.8885945705891956\n",
      "train loss:0.9104789994670565\n",
      "train loss:0.8616233037635426\n",
      "train loss:0.7878437873927624\n",
      "train loss:0.9349765409600417\n",
      "train loss:0.7434163619978139\n",
      "train loss:0.8460082539416036\n",
      "train loss:0.8404294420474371\n",
      "train loss:0.9060294663168749\n",
      "train loss:0.8545722442608978\n",
      "train loss:0.8274835087513537\n",
      "train loss:0.9696146657338677\n",
      "train loss:1.096682584908735\n",
      "train loss:0.832211913219207\n",
      "train loss:0.8048427191400187\n",
      "train loss:0.8537779229609996\n",
      "train loss:0.808180832801518\n",
      "train loss:1.011507325954733\n",
      "train loss:0.8115949305442517\n",
      "train loss:0.9853909869595884\n",
      "train loss:0.8488349777591242\n",
      "train loss:1.0112911813454368\n",
      "train loss:0.9586089715681674\n",
      "train loss:0.970675495649079\n",
      "train loss:0.8599691200294035\n",
      "train loss:0.9644065327815561\n",
      "train loss:0.9625904098240546\n",
      "train loss:0.9652243743163055\n",
      "train loss:0.9231260066494116\n",
      "train loss:0.8806525393053272\n",
      "train loss:0.9473733186081615\n",
      "train loss:0.8084909944700935\n",
      "train loss:0.925597406747301\n",
      "train loss:0.7301869277812177\n",
      "train loss:0.7990642306940805\n",
      "train loss:0.853165382636455\n",
      "train loss:0.8894697474499901\n",
      "train loss:0.7861632818896739\n",
      "train loss:0.9404770299203983\n",
      "train loss:0.9559307037366651\n",
      "train loss:0.8940379293513311\n",
      "train loss:0.9352289193749251\n",
      "train loss:0.9054286906670298\n",
      "train loss:0.9583067710668369\n",
      "train loss:0.9647780603019589\n",
      "train loss:0.9339846013381853\n",
      "train loss:0.9980704443155924\n",
      "train loss:0.8698747339233445\n",
      "train loss:0.9467226823836947\n",
      "train loss:0.8442543132620692\n",
      "train loss:0.6911216479295835\n",
      "train loss:0.8641230825416344\n",
      "train loss:0.887786371566923\n",
      "train loss:0.95393335450483\n",
      "train loss:0.8289323762145551\n",
      "train loss:0.8604357808425982\n",
      "train loss:0.8674243824452597\n",
      "train loss:0.9319120890697202\n",
      "train loss:0.883475358962544\n",
      "train loss:0.9177961482445864\n",
      "train loss:0.7797703105547907\n",
      "train loss:0.8986585673290237\n",
      "train loss:0.8630346656768644\n",
      "train loss:0.686737492404558\n",
      "train loss:0.8693391371816094\n",
      "train loss:0.85669359127312\n",
      "train loss:0.9845892005847131\n",
      "train loss:0.8802747483957856\n",
      "train loss:0.982002506320745\n",
      "train loss:0.8321370606848442\n",
      "train loss:0.9285141153407482\n",
      "train loss:0.7788002930489479\n",
      "train loss:0.9638629604823012\n",
      "train loss:0.9893506069386013\n",
      "train loss:0.7376877391387502\n",
      "train loss:0.9853196880106304\n",
      "train loss:0.8490692986220878\n",
      "train loss:0.9346325239677317\n",
      "train loss:1.053584447489665\n",
      "train loss:0.8774873863078847\n",
      "train loss:0.8860398898732127\n",
      "train loss:0.8148616872063245\n",
      "train loss:0.7720576060660056\n",
      "train loss:0.83104357921065\n",
      "train loss:0.8862153219047884\n",
      "train loss:0.9444320667641048\n",
      "train loss:1.002120055592394\n",
      "train loss:1.0377742331213289\n",
      "train loss:0.9589783354740072\n",
      "train loss:0.949353382902506\n",
      "train loss:0.8865987729574791\n",
      "train loss:0.9557163657672315\n",
      "train loss:0.8193901432968059\n",
      "train loss:0.9311149607958445\n",
      "train loss:0.9324102232276026\n",
      "train loss:0.8552450016421271\n",
      "train loss:0.7568049252440197\n",
      "train loss:1.1340714639061535\n",
      "train loss:0.9639672273966059\n",
      "train loss:0.9441335707847468\n",
      "train loss:0.727042884076087\n",
      "train loss:0.9210616359165716\n",
      "train loss:0.8520679379541858\n",
      "train loss:0.7267847909014646\n",
      "train loss:0.9557126574328317\n",
      "train loss:1.0708345068720417\n",
      "train loss:0.8740751768312626\n",
      "train loss:0.9744503573384925\n",
      "train loss:0.772454825565631\n",
      "train loss:0.8456942455199921\n",
      "train loss:0.6963228460070606\n",
      "train loss:0.8654411689736172\n",
      "train loss:0.9148699113581605\n",
      "train loss:0.8593132083032438\n",
      "train loss:1.082366346704181\n",
      "train loss:0.7119607266550975\n",
      "train loss:0.8946953040338983\n",
      "train loss:0.7800940615209662\n",
      "train loss:0.9865038748321012\n",
      "train loss:1.0100381524445097\n",
      "train loss:0.7491620391176258\n",
      "train loss:0.9883386478439574\n",
      "train loss:0.8376543960707445\n",
      "train loss:1.0089450299791642\n",
      "train loss:0.8384753200328434\n",
      "train loss:0.9508175696087183\n",
      "train loss:0.8017651954215852\n",
      "train loss:0.9909113926084757\n",
      "train loss:0.9107830577277748\n",
      "train loss:0.8793723386353705\n",
      "train loss:0.7454225805277345\n",
      "train loss:0.9001014736088174\n",
      "train loss:0.8048772118461109\n",
      "train loss:0.9287071353538516\n",
      "train loss:0.9746401800356382\n",
      "train loss:0.9360479224285393\n",
      "train loss:0.9762126149407515\n",
      "train loss:0.9793874923152858\n",
      "train loss:0.8678517226161246\n",
      "train loss:1.0119675880583312\n",
      "train loss:0.7230315415731419\n",
      "train loss:1.0401214264276026\n",
      "train loss:0.988146750715653\n",
      "train loss:0.9493570691080011\n",
      "train loss:0.7283339302675842\n",
      "train loss:1.028305587596755\n",
      "train loss:0.6888599312379483\n",
      "train loss:0.958785241044219\n",
      "train loss:0.8883180779744251\n",
      "train loss:0.7865713151110966\n",
      "train loss:0.8488948418919975\n",
      "train loss:0.9915039767908713\n",
      "train loss:0.7802245267362876\n",
      "train loss:0.987384334853852\n",
      "train loss:0.8482853773511388\n",
      "train loss:0.871448342381042\n",
      "train loss:0.8019050567768424\n",
      "train loss:0.8656179066884944\n",
      "train loss:0.9005592677930672\n",
      "train loss:0.7582952095209453\n",
      "train loss:0.8303204921755366\n",
      "train loss:0.6634009674825545\n",
      "train loss:0.7426150370677376\n",
      "train loss:0.8606225627751222\n",
      "train loss:0.9111492238485127\n",
      "train loss:0.8116821675453133\n",
      "train loss:0.7048613771711864\n",
      "train loss:0.8561305985496546\n",
      "train loss:0.9036296824345879\n",
      "train loss:0.9536047902868975\n",
      "train loss:1.226526443194584\n",
      "train loss:0.8654498910039089\n",
      "train loss:1.013775219670536\n",
      "train loss:0.9053366062145343\n",
      "train loss:0.8353947997376536\n",
      "train loss:0.9398884881198313\n",
      "train loss:0.9567433728450923\n",
      "train loss:0.6859369651081499\n",
      "train loss:0.7644453261142716\n",
      "train loss:0.8848108204581954\n",
      "train loss:1.0530817176248204\n",
      "train loss:0.9788507869228061\n",
      "train loss:1.029478214672272\n",
      "train loss:0.8448196073170183\n",
      "train loss:0.8209936255318078\n",
      "train loss:0.9317017054533353\n",
      "train loss:0.8224372205356087\n",
      "train loss:0.779811383716335\n",
      "train loss:0.9994104582980596\n",
      "train loss:0.8977351977731174\n",
      "train loss:0.8899860015186752\n",
      "train loss:0.8017545254672704\n",
      "train loss:0.8811128892771345\n",
      "train loss:0.9590734703275804\n",
      "train loss:0.8786555325276656\n",
      "train loss:0.7697947524588556\n",
      "train loss:0.9115198678426323\n",
      "train loss:0.8834231651679648\n",
      "train loss:0.9081360544531887\n",
      "train loss:0.8405816112492868\n",
      "train loss:0.8170326823172429\n",
      "train loss:0.9300497801050922\n",
      "train loss:0.8839912877396057\n",
      "train loss:0.8924988068485817\n",
      "train loss:1.0244814313542354\n",
      "train loss:0.8994222573549959\n",
      "train loss:0.8593621376621602\n",
      "train loss:0.983362797186773\n",
      "train loss:0.8271623763137991\n",
      "train loss:0.8517812574640834\n",
      "train loss:0.8413848669799586\n",
      "train loss:0.7672284228880986\n",
      "train loss:0.9601395143946162\n",
      "train loss:1.0676486723851368\n",
      "train loss:0.9232303727759937\n",
      "train loss:0.9369660501329534\n",
      "train loss:0.9606448051985673\n",
      "train loss:1.197229920672164\n",
      "train loss:0.7834227428606078\n",
      "train loss:0.9591158908741516\n",
      "train loss:0.922659705052956\n",
      "train loss:0.737784479076541\n",
      "train loss:0.7599973025523344\n",
      "train loss:0.9121775975210595\n",
      "train loss:0.9137529243562313\n",
      "train loss:0.8393367174704395\n",
      "train loss:0.981025338113338\n",
      "train loss:1.0338152760702666\n",
      "train loss:0.8638165384694975\n",
      "train loss:0.9053022671316652\n",
      "train loss:0.959798022626031\n",
      "train loss:0.8294636428868158\n",
      "train loss:0.8039965550957925\n",
      "train loss:0.9088667752401686\n",
      "train loss:0.944028414591695\n",
      "train loss:0.770444090179397\n",
      "train loss:0.861851434826329\n",
      "train loss:0.7559224948879233\n",
      "train loss:0.8688462004077497\n",
      "train loss:0.8747408989567487\n",
      "train loss:0.942720533498422\n",
      "train loss:0.8330782069686039\n",
      "train loss:0.8452519574938974\n",
      "train loss:0.9453305018575552\n",
      "train loss:1.00008758857461\n",
      "train loss:0.9401749783782515\n",
      "train loss:0.9279180245106525\n",
      "train loss:1.033915503160844\n",
      "train loss:0.9398670029393831\n",
      "train loss:1.051645309893162\n",
      "train loss:0.7608650142948791\n",
      "train loss:0.9654292540957786\n",
      "train loss:1.0613780527957237\n",
      "train loss:0.8290281347966969\n",
      "train loss:0.9745952953758374\n",
      "train loss:0.9668860922142273\n",
      "train loss:0.9297722268038793\n",
      "train loss:0.7097531528027489\n",
      "train loss:0.8821070126521446\n",
      "train loss:0.8694704067277041\n",
      "train loss:0.7591908008321836\n",
      "train loss:0.9629942046049423\n",
      "train loss:0.7733022091069688\n",
      "train loss:0.9907150549346768\n",
      "train loss:0.8196032691936134\n",
      "train loss:0.9150663210874116\n",
      "train loss:0.8551353223835495\n",
      "train loss:0.8862011095078356\n",
      "train loss:0.8123224034365361\n",
      "train loss:0.9352517446862292\n",
      "train loss:0.9328692978366973\n",
      "train loss:1.001540449784743\n",
      "train loss:0.978321961320716\n",
      "train loss:0.8601652156933303\n",
      "train loss:0.8607494913033709\n",
      "train loss:0.8237875950753568\n",
      "train loss:0.7957425461171068\n",
      "train loss:0.8658551727046122\n",
      "train loss:0.7145132051246094\n",
      "train loss:1.0428596040794615\n",
      "train loss:0.8640779297627793\n",
      "train loss:1.015279678907073\n",
      "train loss:0.8787697618387234\n",
      "train loss:0.9198080085311754\n",
      "train loss:0.744916937174663\n",
      "train loss:0.892941433086933\n",
      "train loss:0.6805960570162984\n",
      "train loss:1.0607333714296374\n",
      "train loss:0.8058595298140656\n",
      "train loss:0.9697202698970152\n",
      "train loss:0.8383809904592422\n",
      "train loss:0.9291533678409146\n",
      "train loss:0.8768314521788486\n",
      "train loss:0.9372884515510627\n",
      "train loss:0.7820376339634086\n",
      "train loss:0.8591791624767375\n",
      "train loss:0.9035492604022898\n",
      "train loss:0.971421679075304\n",
      "train loss:0.9141316498301952\n",
      "train loss:0.9299483318566482\n",
      "train loss:0.7585969094003544\n",
      "train loss:0.8344638029166656\n",
      "train loss:0.787538163544879\n",
      "train loss:0.993937580245003\n",
      "train loss:0.8692788766151378\n",
      "train loss:0.9343248630572076\n",
      "train loss:0.7958374959995538\n",
      "train loss:0.9628552567242465\n",
      "train loss:0.9119512729295747\n",
      "train loss:0.8176201050783473\n",
      "train loss:0.8591635722375335\n",
      "train loss:0.9708352212549096\n",
      "train loss:0.9315462624031475\n",
      "train loss:1.0175218067476979\n",
      "train loss:0.8335439352837553\n",
      "train loss:0.8649123212654751\n",
      "train loss:0.8400768044835697\n",
      "train loss:0.9024324230912804\n",
      "train loss:1.0120291069922163\n",
      "train loss:0.8693378669782027\n",
      "train loss:0.8934172584589355\n",
      "train loss:0.9109881288371956\n",
      "train loss:1.0351473720015496\n",
      "train loss:0.7803590747855575\n",
      "train loss:0.9178674659959598\n",
      "train loss:0.9444263912266966\n",
      "train loss:0.879591043914888\n",
      "train loss:0.8164608395559906\n",
      "train loss:0.933470968579096\n",
      "train loss:1.0005137359080447\n",
      "train loss:0.9009815812145926\n",
      "train loss:0.9375979255862457\n",
      "train loss:1.0048831018688258\n",
      "train loss:0.7683631645253927\n",
      "train loss:0.8689253237593251\n",
      "train loss:0.6463241538549864\n",
      "train loss:0.8184593559999765\n",
      "train loss:0.8268299189295663\n",
      "train loss:0.9244735659442452\n",
      "train loss:0.9098654141944497\n",
      "train loss:0.9999595451131204\n",
      "train loss:0.9895757551232047\n",
      "train loss:1.0134991988349875\n",
      "train loss:0.7861900475281878\n",
      "train loss:0.839677048217446\n",
      "train loss:0.8555284102085156\n",
      "train loss:0.8845846419576623\n",
      "train loss:0.7445817611823933\n",
      "train loss:0.9150641650322661\n",
      "train loss:0.9171791058698285\n",
      "train loss:0.9681820907490299\n",
      "train loss:1.0019258226617875\n",
      "train loss:0.7061709885246625\n",
      "train loss:0.8276532818725704\n",
      "train loss:0.9980941569289038\n",
      "train loss:0.8235899942758289\n",
      "train loss:0.919551867312299\n",
      "train loss:0.7269748663684497\n",
      "train loss:0.8296286133023492\n",
      "train loss:0.7261217232631576\n",
      "train loss:0.694355315070736\n",
      "train loss:0.977582956608748\n",
      "train loss:0.9042749297718052\n",
      "train loss:0.8491860102410566\n",
      "train loss:0.8343855915552814\n",
      "train loss:0.9966122873159193\n",
      "train loss:0.8822808133952685\n",
      "train loss:0.8643369984667683\n",
      "train loss:0.8822961260493954\n",
      "train loss:0.8442493324416553\n",
      "train loss:0.9212372597305741\n",
      "train loss:0.9403575054129178\n",
      "train loss:0.8686409622069672\n",
      "train loss:0.7681110195721813\n",
      "train loss:0.9271245596591\n",
      "train loss:0.803003185630806\n",
      "train loss:0.9097290365491574\n",
      "train loss:0.9959422776233182\n",
      "train loss:0.9662306012768659\n",
      "train loss:0.9410852796459832\n",
      "train loss:0.9129081133586884\n",
      "train loss:0.8709945281273904\n",
      "train loss:0.8927705116184137\n",
      "train loss:0.9097099639443385\n",
      "train loss:0.9305815292343442\n",
      "train loss:0.7631935140951563\n",
      "train loss:0.9033105169267972\n",
      "train loss:0.7673525507662425\n",
      "train loss:0.6953209882283075\n",
      "train loss:0.8891169754813673\n",
      "train loss:0.9013523985272122\n",
      "train loss:0.9210084487797839\n",
      "train loss:1.0603769757623733\n",
      "train loss:0.9314012702771783\n",
      "train loss:0.8332244731613071\n",
      "train loss:0.867850356717883\n",
      "train loss:0.8417852997985434\n",
      "train loss:0.8783908806803923\n",
      "train loss:0.8509337613290993\n",
      "train loss:0.9294034557661182\n",
      "train loss:0.8595583015154616\n",
      "train loss:0.870058129492002\n",
      "train loss:0.9392785501451231\n",
      "train loss:0.9500471797821186\n",
      "train loss:0.8831938888019927\n",
      "train loss:0.8022226619941775\n",
      "train loss:0.9125303273914689\n",
      "train loss:0.9661186438253204\n",
      "train loss:0.9352670384312473\n",
      "train loss:0.8914984815768554\n",
      "train loss:0.8228172981944768\n",
      "train loss:0.9490424334413966\n",
      "train loss:0.8101144556701405\n",
      "train loss:0.9157337638989971\n",
      "train loss:0.9167241576767837\n",
      "train loss:1.0603424402902528\n",
      "train loss:0.9859821545794459\n",
      "train loss:0.7133431084878391\n",
      "train loss:0.8511192844126677\n",
      "train loss:0.8583187586710014\n",
      "train loss:0.9652905976804783\n",
      "train loss:0.7530194288698473\n",
      "train loss:0.8734216150430895\n",
      "train loss:0.835588270637143\n",
      "train loss:0.8865507138771074\n",
      "train loss:0.9466729898077324\n",
      "train loss:0.9172777973646847\n",
      "train loss:0.779859860070299\n",
      "train loss:0.8873612626520919\n",
      "train loss:0.7851168135959904\n",
      "train loss:1.0403048574615121\n",
      "train loss:0.9120904500252314\n",
      "train loss:0.8978230513827887\n",
      "train loss:0.8972501772666752\n",
      "train loss:0.8849435590867146\n",
      "train loss:0.911826319832087\n",
      "train loss:1.0697313587178374\n",
      "train loss:0.9726122548684785\n",
      "train loss:0.7686241830487208\n",
      "train loss:0.8694995076162185\n",
      "train loss:0.9640760809215635\n",
      "train loss:0.9815506970767851\n",
      "train loss:0.8001983041179254\n",
      "train loss:1.1036670396219126\n",
      "train loss:0.9276342775708342\n",
      "train loss:0.950630427871134\n",
      "train loss:0.8124769669208662\n",
      "train loss:0.9973895066952804\n",
      "train loss:0.9440365631698038\n",
      "train loss:0.8822338310888114\n",
      "train loss:0.9076343895235841\n",
      "train loss:0.8155069236126781\n",
      "train loss:0.890730731067596\n",
      "train loss:0.8785110111591676\n",
      "train loss:1.02995331943188\n",
      "train loss:0.7205951650171705\n",
      "train loss:0.9303280080609503\n",
      "train loss:0.8710523463458041\n",
      "train loss:0.8691850809269555\n",
      "train loss:0.8807585272127065\n",
      "train loss:0.6882698887456139\n",
      "train loss:0.8389692274801555\n",
      "train loss:0.9830911385099778\n",
      "train loss:0.9524578997583021\n",
      "train loss:0.8968203589237135\n",
      "train loss:0.9379630271178284\n",
      "train loss:1.02727536305777\n",
      "train loss:0.9529733930400777\n",
      "train loss:0.798730787593137\n",
      "train loss:0.8904341975923019\n",
      "train loss:0.8103100092780403\n",
      "train loss:0.8615688674559081\n",
      "train loss:0.9597136800811559\n",
      "train loss:0.8498465528695753\n",
      "train loss:0.9706367166212477\n",
      "train loss:0.9543525545115389\n",
      "train loss:0.8706135370711249\n",
      "train loss:0.8768053259676566\n",
      "train loss:0.9496662528671953\n",
      "train loss:0.905959594839685\n",
      "train loss:0.687144712617427\n",
      "train loss:0.8443431875789603\n",
      "train loss:0.9408727323725793\n",
      "train loss:0.9720324355942825\n",
      "train loss:0.8430551817686418\n",
      "train loss:0.7770846662061232\n",
      "train loss:0.9761273656087396\n",
      "train loss:0.8284038879240275\n",
      "train loss:0.8593941875943871\n",
      "train loss:0.8889419597158983\n",
      "train loss:1.037824145223744\n",
      "train loss:0.8872312867315023\n",
      "train loss:0.776622892096693\n",
      "train loss:0.8171561861666615\n",
      "train loss:0.7008556371210739\n",
      "train loss:0.9801176722422066\n",
      "train loss:0.6651098381588758\n",
      "train loss:1.0474636974638498\n",
      "train loss:0.8623423841871066\n",
      "train loss:0.9409542454301305\n",
      "train loss:0.7907165838329824\n",
      "train loss:0.8019045335675206\n",
      "train loss:0.8426848270623504\n",
      "train loss:1.0843403534517286\n",
      "train loss:0.8399890451198838\n",
      "train loss:0.7951989753161162\n",
      "train loss:0.9488031868839866\n",
      "train loss:0.9473305916977243\n",
      "train loss:0.9136387829071592\n",
      "train loss:0.929565103100522\n",
      "train loss:0.7059779530618684\n",
      "train loss:0.8148490346315107\n",
      "train loss:0.8508992730507694\n",
      "train loss:1.0471291465981665\n",
      "train loss:0.8294379341200255\n",
      "train loss:0.7335195867625012\n",
      "train loss:0.8731108604873081\n",
      "train loss:0.9183417616584681\n",
      "train loss:1.0452119841583676\n",
      "train loss:0.8797580354840787\n",
      "train loss:0.9272706628123879\n",
      "train loss:0.9118359448171397\n",
      "train loss:0.6986964271911053\n",
      "train loss:0.7921530201361661\n",
      "train loss:0.9639382175067501\n",
      "train loss:0.9388019387356319\n",
      "train loss:0.7484129978547582\n",
      "train loss:0.930021451294885\n",
      "train loss:0.8174464109632639\n",
      "train loss:1.1211815543112928\n",
      "train loss:0.8991966753769236\n",
      "train loss:0.7738790424137059\n",
      "train loss:0.8645339125141501\n",
      "train loss:0.8300001051181275\n",
      "train loss:0.9067459767298053\n",
      "train loss:0.7692786472068187\n",
      "train loss:0.7718506162549513\n",
      "train loss:0.8407247465488759\n",
      "train loss:0.7585087128172084\n",
      "train loss:0.8182715725189114\n",
      "train loss:0.7992365798950783\n",
      "train loss:0.9368523534627005\n",
      "train loss:0.8953857846487829\n",
      "train loss:0.8067825440827066\n",
      "train loss:0.8682758181247152\n",
      "train loss:0.8119627764064948\n",
      "train loss:0.935972992181561\n",
      "train loss:0.7371102822940369\n",
      "train loss:0.944997085362152\n",
      "train loss:0.8791006912345205\n",
      "train loss:0.6451703534207379\n",
      "train loss:0.8759497299865135\n",
      "train loss:0.8865827762684071\n",
      "train loss:0.7958197289739612\n",
      "train loss:0.8499807207644244\n",
      "train loss:0.8756879361452005\n",
      "train loss:0.8756122275301729\n",
      "train loss:0.8831255919586615\n",
      "train loss:0.9362997717425317\n",
      "train loss:0.8065951362082885\n",
      "train loss:1.0313968730244443\n",
      "train loss:0.7737667100390297\n",
      "train loss:0.8352682192800924\n",
      "train loss:0.9180791138082098\n",
      "train loss:0.894789894367118\n",
      "train loss:0.8417616878328412\n",
      "train loss:1.0821991786211698\n",
      "train loss:0.7154547419645059\n",
      "train loss:1.0438620439680368\n",
      "train loss:0.796108985753345\n",
      "train loss:0.7095650690074131\n",
      "train loss:0.7282217495725237\n",
      "train loss:0.8572392948260172\n",
      "train loss:0.7802757612775304\n",
      "train loss:0.7846779638104343\n",
      "train loss:0.6429477350813306\n",
      "train loss:1.0136114848774138\n",
      "train loss:1.1657183200500374\n",
      "train loss:0.9630143065954028\n",
      "train loss:0.9459727065898591\n",
      "train loss:0.837470600062915\n",
      "train loss:0.9456864499902526\n",
      "train loss:1.0946736402953925\n",
      "train loss:1.0058151739749115\n",
      "train loss:0.7603011183697287\n",
      "train loss:0.749609414912739\n",
      "train loss:0.9575083342831802\n",
      "train loss:0.9987879541135876\n",
      "train loss:0.95597030640552\n",
      "train loss:0.9751135941409055\n",
      "train loss:0.9143885331299311\n",
      "train loss:0.8404202596848436\n",
      "train loss:0.9912457191093544\n",
      "train loss:0.9427891568568011\n",
      "train loss:0.8252791698987885\n",
      "train loss:0.8781236713413694\n",
      "train loss:0.9743246749499537\n",
      "=== epoch:14, train acc:0.995, test acc:0.988 ===\n",
      "train loss:0.8143697324887149\n",
      "train loss:0.8915185918498244\n",
      "train loss:0.8247805022108361\n",
      "train loss:0.8538395416886786\n",
      "train loss:0.8735735925367155\n",
      "train loss:0.9244711392678004\n",
      "train loss:0.9346633910784625\n",
      "train loss:0.7702553822029157\n",
      "train loss:0.7453962459896308\n",
      "train loss:0.7034709060883886\n",
      "train loss:1.0701038638914957\n",
      "train loss:0.7562947747649053\n",
      "train loss:0.9235237740530075\n",
      "train loss:0.8565954480466451\n",
      "train loss:0.8958707896062158\n",
      "train loss:0.7830441102288204\n",
      "train loss:0.8514478702362964\n",
      "train loss:0.8849487313073868\n",
      "train loss:0.9066970271649265\n",
      "train loss:0.8498124191133095\n",
      "train loss:0.919638247883244\n",
      "train loss:0.696737621484795\n",
      "train loss:0.9451137665942615\n",
      "train loss:0.724960482113795\n",
      "train loss:0.8241676112445233\n",
      "train loss:1.0100564365830065\n",
      "train loss:1.0235990687759473\n",
      "train loss:0.8052038210921016\n",
      "train loss:0.8163376779811001\n",
      "train loss:0.9922378184398245\n",
      "train loss:0.7256289909365752\n",
      "train loss:1.0458893709424302\n",
      "train loss:0.7945942996811344\n",
      "train loss:0.8511987818795106\n",
      "train loss:0.8181158349492071\n",
      "train loss:0.6335089655817956\n",
      "train loss:0.8219744585384067\n",
      "train loss:0.8104418136167348\n",
      "train loss:1.1063046473546985\n",
      "train loss:0.8680699937129325\n",
      "train loss:0.9233922392332947\n",
      "train loss:0.9850439840772819\n",
      "train loss:0.9150378247846099\n",
      "train loss:0.9758028569443542\n",
      "train loss:1.0436439033414644\n",
      "train loss:0.9008024445648924\n",
      "train loss:0.8243921213488313\n",
      "train loss:0.9838667627533836\n",
      "train loss:0.8745145268398494\n",
      "train loss:1.009846523625715\n",
      "train loss:0.8877532477181215\n",
      "train loss:0.8091815993963668\n",
      "train loss:0.7905573640923218\n",
      "train loss:0.8530836696086369\n",
      "train loss:0.9267611017828138\n",
      "train loss:0.8209065676226001\n",
      "train loss:0.9877125274581211\n",
      "train loss:0.8367517237192834\n",
      "train loss:0.8964756635830861\n",
      "train loss:0.9859048323476491\n",
      "train loss:0.9114301362583244\n",
      "train loss:0.8561853806339914\n",
      "train loss:0.7755792375024463\n",
      "train loss:0.8080245779950508\n",
      "train loss:0.8831342815352358\n",
      "train loss:0.8350239922917048\n",
      "train loss:1.0516561645249831\n",
      "train loss:0.8088921313658071\n",
      "train loss:0.8512373483511957\n",
      "train loss:0.8465863196519534\n",
      "train loss:0.8425886309449608\n",
      "train loss:0.7980096544221672\n",
      "train loss:0.9688501657874298\n",
      "train loss:0.8290219527914127\n",
      "train loss:0.797676824722564\n",
      "train loss:0.8625681165122344\n",
      "train loss:0.8182717891509745\n",
      "train loss:0.8424071192612714\n",
      "train loss:1.0643076239172118\n",
      "train loss:0.9480415219111265\n",
      "train loss:0.8543030862907672\n",
      "train loss:1.1342328809683229\n",
      "train loss:0.8550074381478417\n",
      "train loss:0.783681001333038\n",
      "train loss:0.9433994195233882\n",
      "train loss:0.9191793591495238\n",
      "train loss:0.8113650026706888\n",
      "train loss:0.9151847083536556\n",
      "train loss:0.8598080042751743\n",
      "train loss:1.0748102694876498\n",
      "train loss:0.7676610641136661\n",
      "train loss:0.9571326851294613\n",
      "train loss:0.8662761132976946\n",
      "train loss:0.9495671858471316\n",
      "train loss:0.9999837537269027\n",
      "train loss:0.9149243443032495\n",
      "train loss:0.8698665765264135\n",
      "train loss:0.856176549061216\n",
      "train loss:0.8613735854629287\n",
      "train loss:0.8324617696670796\n",
      "train loss:0.9630800443316015\n",
      "train loss:0.8526882217124665\n",
      "train loss:0.8113235029594157\n",
      "train loss:0.8094756384179834\n",
      "train loss:0.9836219489771616\n",
      "train loss:0.9484189886913501\n",
      "train loss:0.8922880239047681\n",
      "train loss:0.8203139315617477\n",
      "train loss:0.8844814294400376\n",
      "train loss:0.6668595795877224\n",
      "train loss:0.7920378603973808\n",
      "train loss:0.69685463181905\n",
      "train loss:1.0985564508608356\n",
      "train loss:0.8259701958516021\n",
      "train loss:0.854894829810437\n",
      "train loss:0.907053501236762\n",
      "train loss:0.8705127570194633\n",
      "train loss:0.7797304712067585\n",
      "train loss:0.8585710945410618\n",
      "train loss:0.8822814553565579\n",
      "train loss:0.7425026408124811\n",
      "train loss:0.8398560143626521\n",
      "train loss:0.8097482199752233\n",
      "train loss:0.9088561937462584\n",
      "train loss:0.9283052241056856\n",
      "train loss:0.8354816452983804\n",
      "train loss:0.8814632568707691\n",
      "train loss:0.9787631878343704\n",
      "train loss:0.8091714812498961\n",
      "train loss:0.8477957668328506\n",
      "train loss:0.7839135202157226\n",
      "train loss:0.8971200857940412\n",
      "train loss:0.8967713432528193\n",
      "train loss:0.8765938831427398\n",
      "train loss:0.8103903596502409\n",
      "train loss:0.796850326209611\n",
      "train loss:0.9190182437935351\n",
      "train loss:0.7358248408962099\n",
      "train loss:0.8052989278640109\n",
      "train loss:0.7915993609376616\n",
      "train loss:1.0284420352867152\n",
      "train loss:0.9900102027141946\n",
      "train loss:0.9727794984248177\n",
      "train loss:0.8179948537490094\n",
      "train loss:0.8827588907612021\n",
      "train loss:0.9088133675585237\n",
      "train loss:0.8730696113912514\n",
      "train loss:0.9422096265356036\n",
      "train loss:0.7789524823484159\n",
      "train loss:1.0257714520178367\n",
      "train loss:0.9223208977576683\n",
      "train loss:1.0774224350181074\n",
      "train loss:0.9573632338143035\n",
      "train loss:0.8262146696934495\n",
      "train loss:0.9231402445773821\n",
      "train loss:0.9097318986261993\n",
      "train loss:1.0094111949210847\n",
      "train loss:0.8660424380950295\n",
      "train loss:0.868709557577159\n",
      "train loss:0.8267892497271744\n",
      "train loss:0.7033729949558285\n",
      "train loss:1.0179485321799906\n",
      "train loss:0.8774210390320653\n",
      "train loss:0.9108717783298509\n",
      "train loss:0.9812922569699487\n",
      "train loss:0.8791726807705669\n",
      "train loss:0.9413937828956065\n",
      "train loss:0.9517253400654125\n",
      "train loss:0.8561370457563966\n",
      "train loss:0.8633222571634009\n",
      "train loss:0.787940135145541\n",
      "train loss:0.8599938312646441\n",
      "train loss:0.96849795885813\n",
      "train loss:1.0794081355875733\n",
      "train loss:0.8606417435256216\n",
      "train loss:0.6972468231183719\n",
      "train loss:0.959557238683261\n",
      "train loss:0.9109116214809378\n",
      "train loss:0.7880102397936315\n",
      "train loss:0.6579160954788688\n",
      "train loss:0.952863816727931\n",
      "train loss:0.8853505496328995\n",
      "train loss:0.8934262873492673\n",
      "train loss:0.6682787060582193\n",
      "train loss:0.8444686821441458\n",
      "train loss:0.9454338096311707\n",
      "train loss:0.9774978253995975\n",
      "train loss:0.8695723463793157\n",
      "train loss:0.8413894339843658\n",
      "train loss:0.774971123491912\n",
      "train loss:0.8674387072937428\n",
      "train loss:0.7661909217893799\n",
      "train loss:0.767537589325242\n",
      "train loss:0.7481667708065658\n",
      "train loss:0.916600709218972\n",
      "train loss:0.9978851052410724\n",
      "train loss:1.1064200664772073\n",
      "train loss:0.7742569662609768\n",
      "train loss:0.9144312557613391\n",
      "train loss:0.8958935481049173\n",
      "train loss:0.8357390605678933\n",
      "train loss:0.9830476134829621\n",
      "train loss:1.0259657475040884\n",
      "train loss:0.9234110181122258\n",
      "train loss:0.9545011848866636\n",
      "train loss:0.8686334201818418\n",
      "train loss:0.9381920146113284\n",
      "train loss:0.8970048736070793\n",
      "train loss:0.7370939128604213\n",
      "train loss:1.009118306011039\n",
      "train loss:0.8930429140208844\n",
      "train loss:0.7468712419312976\n",
      "train loss:0.9784291574828202\n",
      "train loss:1.0516661100143843\n",
      "train loss:0.8306664103020215\n",
      "train loss:0.954389485908305\n",
      "train loss:0.8469578430883345\n",
      "train loss:0.8620649284591295\n",
      "train loss:0.8208994563292131\n",
      "train loss:0.8163497581722869\n",
      "train loss:0.8929809939714108\n",
      "train loss:0.8826197318039953\n",
      "train loss:0.7986810805329335\n",
      "train loss:1.0124125266504886\n",
      "train loss:0.9331273055032909\n",
      "train loss:0.7479512879144664\n",
      "train loss:0.7614444760986848\n",
      "train loss:0.7556810657610801\n",
      "train loss:0.9852970628260497\n",
      "train loss:0.9420600856129139\n",
      "train loss:0.8098271734578788\n",
      "train loss:0.7591127944465882\n",
      "train loss:0.7860978980219987\n",
      "train loss:0.9202692841743702\n",
      "train loss:0.9302273264635028\n",
      "train loss:0.9624998161061149\n",
      "train loss:0.7612597641647\n",
      "train loss:0.8361507290085949\n",
      "train loss:0.879914655908483\n",
      "train loss:0.9738943837684902\n",
      "train loss:0.9716602196287034\n",
      "train loss:0.8492240989864293\n",
      "train loss:0.8637556686165556\n",
      "train loss:0.9745872812643307\n",
      "train loss:0.8567706444676658\n",
      "train loss:0.8482782735726289\n",
      "train loss:1.0146484436321963\n",
      "train loss:0.9197438748063091\n",
      "train loss:0.8936882056930862\n",
      "train loss:0.9433141066257984\n",
      "train loss:0.8927386099920283\n",
      "train loss:0.9786500581984505\n",
      "train loss:0.9583906541502407\n",
      "train loss:0.9218001159521684\n",
      "train loss:0.7840902660469848\n",
      "train loss:0.9944146919670012\n",
      "train loss:0.8658229729569965\n",
      "train loss:1.001183352094214\n",
      "train loss:0.8325305743995335\n",
      "train loss:1.0392515235252686\n",
      "train loss:1.0662555423781095\n",
      "train loss:1.03561120749067\n",
      "train loss:0.8322111187509701\n",
      "train loss:0.9079675407545806\n",
      "train loss:0.79358535899936\n",
      "train loss:0.7845207550552361\n",
      "train loss:0.9217734899407865\n",
      "train loss:0.9478653172545599\n",
      "train loss:1.0135128814969945\n",
      "train loss:0.7930618477784805\n",
      "train loss:0.864084433817535\n",
      "train loss:0.7996652874305991\n",
      "train loss:0.800759977222648\n",
      "train loss:0.8083924644692793\n",
      "train loss:1.0227158288261196\n",
      "train loss:0.8035834774859577\n",
      "train loss:0.7708405614048272\n",
      "train loss:0.8740094299643067\n",
      "train loss:0.9074168867066333\n",
      "train loss:1.0345543144168763\n",
      "train loss:0.8403889916527166\n",
      "train loss:0.9472238939092619\n",
      "train loss:0.9187020832209614\n",
      "train loss:0.9477486538897132\n",
      "train loss:1.062519079568027\n",
      "train loss:0.7950583802273333\n",
      "train loss:1.005379068477318\n",
      "train loss:0.9192719907270802\n",
      "train loss:0.7969832660436942\n",
      "train loss:0.8887098915836367\n",
      "train loss:0.8469153069970872\n",
      "train loss:0.9137705836027457\n",
      "train loss:1.0029956416350165\n",
      "train loss:0.919718849837856\n",
      "train loss:0.9027679059351782\n",
      "train loss:0.9178141139650284\n",
      "train loss:0.7999001460368705\n",
      "train loss:0.8891151125329185\n",
      "train loss:0.6960485380145109\n",
      "train loss:0.870358771454881\n",
      "train loss:0.8587555752166398\n",
      "train loss:0.9190173718389049\n",
      "train loss:0.7703759551263638\n",
      "train loss:0.7265172787210566\n",
      "train loss:0.9952588126137999\n",
      "train loss:0.7868641726988335\n",
      "train loss:0.8115460344937921\n",
      "train loss:0.9172129671470973\n",
      "train loss:0.7992432245826555\n",
      "train loss:0.9600276214322705\n",
      "train loss:0.9334060869564113\n",
      "train loss:1.0216847716524489\n",
      "train loss:0.8165016882269995\n",
      "train loss:0.899536814561905\n",
      "train loss:1.0801858213629518\n",
      "train loss:0.8739734904505384\n",
      "train loss:0.9155357782858478\n",
      "train loss:0.9191950558038979\n",
      "train loss:0.8933000379297568\n",
      "train loss:0.811520338394373\n",
      "train loss:0.8867590466623797\n",
      "train loss:0.777460420535652\n",
      "train loss:0.8961879545451045\n",
      "train loss:0.8649352703819284\n",
      "train loss:0.9345570621090928\n",
      "train loss:0.6790037469108104\n",
      "train loss:0.8301184190571564\n",
      "train loss:0.8092207660649793\n",
      "train loss:0.9125253380228573\n",
      "train loss:0.9407066866915392\n",
      "train loss:0.8317925593402887\n",
      "train loss:0.831430482142832\n",
      "train loss:0.8326191874210876\n",
      "train loss:0.8138083667921201\n",
      "train loss:1.0502037110256566\n",
      "train loss:1.0021400268304577\n",
      "train loss:0.9283495654404671\n",
      "train loss:0.8140120970960085\n",
      "train loss:0.9288807833368865\n",
      "train loss:0.91166601143433\n",
      "train loss:0.7896835894920848\n",
      "train loss:0.918113531572756\n",
      "train loss:1.0167319323335202\n",
      "train loss:0.9237773942304667\n",
      "train loss:0.9235711808437206\n",
      "train loss:0.871497641362738\n",
      "train loss:0.9528421527132095\n",
      "train loss:0.8318224045400561\n",
      "train loss:0.8096763192904549\n",
      "train loss:0.7240128398780383\n",
      "train loss:0.8110836233256188\n",
      "train loss:0.919374721359831\n",
      "train loss:0.7412029377814606\n",
      "train loss:0.8131149088053131\n",
      "train loss:0.8249488788782873\n",
      "train loss:0.8580265208222619\n",
      "train loss:0.7618671917450367\n",
      "train loss:0.8264033960384499\n",
      "train loss:0.8760044145827959\n",
      "train loss:1.0619867258309228\n",
      "train loss:1.0642313804011478\n",
      "train loss:0.867549997711422\n",
      "train loss:1.0063163148288314\n",
      "train loss:1.0565714815404232\n",
      "train loss:0.9061681889347727\n",
      "train loss:0.9138050364267204\n",
      "train loss:1.0287986012970827\n",
      "train loss:0.9416247608567258\n",
      "train loss:0.9458870368833111\n",
      "train loss:0.8271173532916067\n",
      "train loss:0.8039083302259646\n",
      "train loss:0.759236707913601\n",
      "train loss:0.7461375650637454\n",
      "train loss:0.8635661104907864\n",
      "train loss:0.9766255915535983\n",
      "train loss:1.063238905420584\n",
      "train loss:0.8036263329903037\n",
      "train loss:0.7452603463588602\n",
      "train loss:0.7600339683865475\n",
      "train loss:0.8903485783194598\n",
      "train loss:0.934635283037869\n",
      "train loss:0.8586749466008147\n",
      "train loss:0.7049531978646306\n",
      "train loss:0.9621281170552451\n",
      "train loss:0.935851594318508\n",
      "train loss:0.7999407774884106\n",
      "train loss:0.8406480644431877\n",
      "train loss:0.7974424000254885\n",
      "train loss:0.8500327416357379\n",
      "train loss:0.8274013289518376\n",
      "train loss:0.7891535171784102\n",
      "train loss:0.7587612831855995\n",
      "train loss:1.0309172717086783\n",
      "train loss:0.9668608008536732\n",
      "train loss:1.0069820033807877\n",
      "train loss:0.7420729973714978\n",
      "train loss:0.819050841298789\n",
      "train loss:0.9364421610286122\n",
      "train loss:0.8942351549759073\n",
      "train loss:0.9346617176500015\n",
      "train loss:0.853538318139211\n",
      "train loss:1.1377214045409698\n",
      "train loss:0.8234647491384695\n",
      "train loss:1.0280161037384947\n",
      "train loss:0.9035384529108835\n",
      "train loss:0.9558573086572809\n",
      "train loss:1.0685815402282277\n",
      "train loss:0.9418856645103658\n",
      "train loss:0.9261677957223078\n",
      "train loss:0.86561143921231\n",
      "train loss:1.0673092277747824\n",
      "train loss:0.7637008627701343\n",
      "train loss:0.9792914762306126\n",
      "train loss:0.980974221205465\n",
      "train loss:0.9596640747193215\n",
      "train loss:0.9355780695929817\n",
      "train loss:0.89506787488463\n",
      "train loss:0.9548002988492357\n",
      "train loss:0.9379814135737284\n",
      "train loss:0.8613223735079224\n",
      "train loss:0.9155426359373124\n",
      "train loss:0.8562548978613104\n",
      "train loss:0.9025475061440309\n",
      "train loss:0.8521702896047357\n",
      "train loss:0.8532212961623946\n",
      "train loss:1.0152315688141953\n",
      "train loss:1.0089818208584571\n",
      "train loss:0.8723683148209318\n",
      "train loss:0.8323309310433765\n",
      "train loss:0.9429620722227425\n",
      "train loss:0.96433243877848\n",
      "train loss:1.0169525232512722\n",
      "train loss:0.833972688704708\n",
      "train loss:0.8978826130239673\n",
      "train loss:0.8588438716792574\n",
      "train loss:0.8502423006533177\n",
      "train loss:0.8800109964578102\n",
      "train loss:1.0168456644909087\n",
      "train loss:0.9216809091872844\n",
      "train loss:0.9719994831630432\n",
      "train loss:0.9282320408469223\n",
      "train loss:0.8395260175833418\n",
      "train loss:0.7863882737721387\n",
      "train loss:0.855615664334862\n",
      "train loss:0.9149232631643747\n",
      "train loss:0.9630176014664561\n",
      "train loss:0.7911439372472259\n",
      "train loss:0.9527526143731739\n",
      "train loss:0.8719668728653376\n",
      "train loss:0.8274533437645943\n",
      "train loss:0.8159195599882467\n",
      "train loss:0.8465506306320023\n",
      "train loss:1.0673655617662892\n",
      "train loss:0.8430115067135155\n",
      "train loss:0.7087707015857377\n",
      "train loss:0.9500215568935896\n",
      "train loss:0.673500452777428\n",
      "train loss:0.7490368502906989\n",
      "train loss:0.8068760052888436\n",
      "train loss:0.9565592814452338\n",
      "train loss:1.0323318345920975\n",
      "train loss:0.8874917818522532\n",
      "train loss:0.8942403001217113\n",
      "train loss:0.975124748949995\n",
      "train loss:0.7261700941129474\n",
      "train loss:0.8152366739466322\n",
      "train loss:1.013065738855186\n",
      "train loss:0.7553651354808986\n",
      "train loss:0.9859899151476269\n",
      "train loss:0.8026372615843859\n",
      "train loss:0.7993504557165455\n",
      "train loss:0.8750662876477979\n",
      "train loss:0.8322302407441364\n",
      "train loss:1.0711469283481785\n",
      "train loss:0.9126943910113758\n",
      "train loss:0.9820756000082156\n",
      "train loss:0.7767172688509981\n",
      "train loss:0.8715981608772415\n",
      "train loss:0.9407071418465979\n",
      "train loss:0.7782035130217563\n",
      "train loss:1.0242377306720312\n",
      "train loss:0.7580160967164687\n",
      "train loss:0.758269004950259\n",
      "train loss:0.6728014101035129\n",
      "train loss:0.8137404328626622\n",
      "train loss:0.8753107958907385\n",
      "train loss:0.7566241021578706\n",
      "train loss:0.9059349559375436\n",
      "train loss:0.8271551128275191\n",
      "train loss:0.9987314309425567\n",
      "train loss:0.8147036526876305\n",
      "train loss:0.8757185141594374\n",
      "train loss:0.6883111076306591\n",
      "train loss:0.8442852055673145\n",
      "train loss:0.7465146334259961\n",
      "train loss:0.8539050285509091\n",
      "train loss:0.8007565692476214\n",
      "train loss:0.9433257701990192\n",
      "train loss:0.8543172453520748\n",
      "train loss:0.992712199784766\n",
      "train loss:0.8634493666157286\n",
      "train loss:0.916709223572135\n",
      "train loss:0.9017888767405445\n",
      "train loss:0.7631048329498621\n",
      "train loss:1.079483489790561\n",
      "train loss:0.8100496098297804\n",
      "train loss:0.799309260521127\n",
      "train loss:0.9529812746951198\n",
      "train loss:0.787158546501021\n",
      "train loss:0.7615442296531909\n",
      "train loss:0.8382933102294108\n",
      "train loss:0.8943527209785124\n",
      "train loss:0.7423026368513596\n",
      "train loss:0.8349003290270371\n",
      "train loss:1.0082262113869958\n",
      "train loss:1.0184955870587995\n",
      "train loss:0.9308927310918239\n",
      "train loss:0.8455387590433792\n",
      "train loss:0.7864410005242388\n",
      "train loss:0.8912333446300202\n",
      "train loss:0.9007619414998282\n",
      "train loss:1.0025251184172066\n",
      "train loss:0.9477724071552696\n",
      "train loss:0.9595133696883401\n",
      "train loss:0.9532101518465633\n",
      "train loss:0.6961122726156187\n",
      "train loss:0.8969601825913083\n",
      "train loss:0.8775639055083647\n",
      "train loss:0.9740868143890248\n",
      "train loss:0.9258666243011778\n",
      "train loss:0.7874853291033729\n",
      "train loss:0.8302567678575987\n",
      "train loss:1.0609348109751375\n",
      "train loss:0.8626537715040625\n",
      "train loss:0.9396997044116766\n",
      "train loss:0.7869137652738613\n",
      "train loss:0.8448342142173081\n",
      "train loss:0.96650876348018\n",
      "train loss:0.9248848928115002\n",
      "train loss:0.927843872835139\n",
      "train loss:0.9519424296032052\n",
      "train loss:0.9048853513854687\n",
      "train loss:0.724702361194133\n",
      "train loss:0.7340944869177506\n",
      "train loss:0.9167693067200517\n",
      "train loss:0.8766598604509622\n",
      "train loss:0.8887691697432171\n",
      "train loss:0.9608983604470893\n",
      "train loss:1.0708637889607935\n",
      "train loss:0.8846700066016436\n",
      "train loss:0.9000638927943259\n",
      "train loss:0.9613490459468435\n",
      "train loss:0.7645693079396374\n",
      "train loss:0.9150968283511586\n",
      "train loss:0.857682755142821\n",
      "train loss:0.880757663427964\n",
      "train loss:0.8546297852217951\n",
      "train loss:0.7933051203733847\n",
      "train loss:0.9502070951416427\n",
      "train loss:0.9864074415870624\n",
      "train loss:0.9930499299257578\n",
      "train loss:0.7039287842248556\n",
      "train loss:0.9861033707944441\n",
      "train loss:0.9216631514722855\n",
      "train loss:0.7678257628430688\n",
      "train loss:0.7771834863607675\n",
      "train loss:0.9174915381986882\n",
      "train loss:0.8919341168096482\n",
      "train loss:0.8408209922927561\n",
      "train loss:0.9864594446088111\n",
      "train loss:0.9811045681768803\n",
      "train loss:0.9445271456160076\n",
      "train loss:1.0318321258935825\n",
      "train loss:0.8010650745483872\n",
      "train loss:0.9709329891872202\n",
      "train loss:1.052509912095838\n",
      "train loss:0.9482056237345886\n",
      "train loss:0.9038870827390277\n",
      "train loss:0.9930406746434379\n",
      "train loss:0.9728529811909812\n",
      "train loss:0.7938187531650693\n",
      "train loss:0.9415205547682953\n",
      "train loss:0.8008899538794542\n",
      "train loss:0.939824225855501\n",
      "train loss:0.9953792947859219\n",
      "train loss:0.8777659384726332\n",
      "train loss:1.027866742670652\n",
      "train loss:0.9922967391944354\n",
      "train loss:0.9062152577609609\n",
      "train loss:0.8407194500896661\n",
      "train loss:0.8446347495927118\n",
      "train loss:1.0703393592969008\n",
      "train loss:0.9205845078806891\n",
      "train loss:0.8479964709324895\n",
      "train loss:0.8951259181534524\n",
      "train loss:0.7157676315013071\n",
      "train loss:1.032589467617655\n",
      "train loss:0.8622368504180016\n",
      "train loss:0.8920415457873994\n",
      "train loss:0.8479210301710814\n",
      "=== epoch:15, train acc:0.995, test acc:0.994 ===\n",
      "train loss:0.9789324520394467\n",
      "train loss:0.843570947495027\n",
      "train loss:0.8675691716127057\n",
      "train loss:0.929050628649215\n",
      "train loss:0.9249697553020954\n",
      "train loss:0.8733741525746401\n",
      "train loss:0.9992444142410326\n",
      "train loss:1.0062253376233792\n",
      "train loss:0.8842921298425946\n",
      "train loss:1.0086371233841354\n",
      "train loss:1.0327372330890945\n",
      "train loss:0.90058409773382\n",
      "train loss:0.9678840108694203\n",
      "train loss:0.8677229165392428\n",
      "train loss:0.8316532366137572\n",
      "train loss:0.6692900592265671\n",
      "train loss:0.9631933714298099\n",
      "train loss:0.9504513571361575\n",
      "train loss:0.8465052928720286\n",
      "train loss:0.7648519797142995\n",
      "train loss:0.9512699045751699\n",
      "train loss:0.83461001131014\n",
      "train loss:0.9220423649286983\n",
      "train loss:1.0279404102535659\n",
      "train loss:0.7962221688671584\n",
      "train loss:0.8450791725514395\n",
      "train loss:0.9632842942301849\n",
      "train loss:0.792045127716791\n",
      "train loss:0.8006185703364391\n",
      "train loss:0.9950655395927664\n",
      "train loss:0.8842025405650166\n",
      "train loss:0.9281624005453292\n",
      "train loss:0.9519476500385192\n",
      "train loss:0.785559667121818\n",
      "train loss:0.8663568540734196\n",
      "train loss:0.825584213274496\n",
      "train loss:0.8970770259783972\n",
      "train loss:0.786611761313247\n",
      "train loss:0.8376396202859213\n",
      "train loss:1.0456804324960949\n",
      "train loss:0.9905443223881936\n",
      "train loss:0.8482682832437405\n",
      "train loss:0.8906882767353828\n",
      "train loss:0.893207128786305\n",
      "train loss:0.9311603026336465\n",
      "train loss:0.8963063733230201\n",
      "train loss:0.772637252099297\n",
      "train loss:0.8975682154447352\n",
      "train loss:0.8766496649247211\n",
      "train loss:0.7024212884043838\n",
      "train loss:0.9308858260797733\n",
      "train loss:0.8305503570201535\n",
      "train loss:0.8666314881749851\n",
      "train loss:0.8803982319120862\n",
      "train loss:0.8748422049804283\n",
      "train loss:0.9568721938326453\n",
      "train loss:0.9786438287324414\n",
      "train loss:1.0176164501835125\n",
      "train loss:0.8950639566251587\n",
      "train loss:0.7625014434082427\n",
      "train loss:1.008647296038192\n",
      "train loss:1.117320323445702\n",
      "train loss:0.6974985084139164\n",
      "train loss:0.8942351294523461\n",
      "train loss:0.8529208027687812\n",
      "train loss:0.9266969523500134\n",
      "train loss:0.735558455932653\n",
      "train loss:0.7591156139588355\n",
      "train loss:0.7676487618858535\n",
      "train loss:0.9473116433122212\n",
      "train loss:0.881805464062231\n",
      "train loss:0.8478400629361699\n",
      "train loss:0.7386897812725358\n",
      "train loss:0.9907732584679658\n",
      "train loss:0.8948417709570018\n",
      "train loss:1.0385614855769914\n",
      "train loss:0.720679454819485\n",
      "train loss:0.7907857561059629\n",
      "train loss:0.7764667156891221\n",
      "train loss:1.0478693604911014\n",
      "train loss:0.8746878435466843\n",
      "train loss:0.8314542477883698\n",
      "train loss:0.8419529828408362\n",
      "train loss:0.8811340320077184\n",
      "train loss:0.7849681293175576\n",
      "train loss:0.6943869529479323\n",
      "train loss:0.8659169889782363\n",
      "train loss:0.7952364635609603\n",
      "train loss:0.8242596675846098\n",
      "train loss:0.8626235721242094\n",
      "train loss:0.7535142313177318\n",
      "train loss:1.0740195206497727\n",
      "train loss:0.7054179875298903\n",
      "train loss:0.8712191559503981\n",
      "train loss:0.956547650014585\n",
      "train loss:0.8718174487954278\n",
      "train loss:0.8812221331015858\n",
      "train loss:0.6328410820760539\n",
      "train loss:0.8170626162551713\n",
      "train loss:0.8904938648108914\n",
      "train loss:0.7216757281349483\n",
      "train loss:0.9310313658274222\n",
      "train loss:0.8765957916860632\n",
      "train loss:0.9985099535147307\n",
      "train loss:0.7113905254927093\n",
      "train loss:1.1564913333837943\n",
      "train loss:0.9556456633638705\n",
      "train loss:0.7909286061313607\n",
      "train loss:0.8345315744223334\n",
      "train loss:0.9421714295086077\n",
      "train loss:1.0724424117011773\n",
      "train loss:0.930526212619972\n",
      "train loss:1.0594296968703572\n",
      "train loss:0.7656913335123089\n",
      "train loss:0.7484271854213506\n",
      "train loss:0.8265301690071212\n",
      "train loss:0.929321408435928\n",
      "train loss:0.8497938764889456\n",
      "train loss:0.7913123625523335\n",
      "train loss:0.8980447791765479\n",
      "train loss:0.8274939901799159\n",
      "train loss:0.977886877529277\n",
      "train loss:0.9326293063661685\n",
      "train loss:0.9722002166795793\n",
      "train loss:0.9131357032837721\n",
      "train loss:0.8564120782587347\n",
      "train loss:1.0377976826557773\n",
      "train loss:0.8959060024878245\n",
      "train loss:0.8495482691866009\n",
      "train loss:0.9977232486778091\n",
      "train loss:0.9134519395791425\n",
      "train loss:0.8192171554701086\n",
      "train loss:0.7795893925793035\n",
      "train loss:0.9253122715412736\n",
      "train loss:0.9076599509778985\n",
      "train loss:0.9271535638021399\n",
      "train loss:0.9904532551752773\n",
      "train loss:0.7577366393086226\n",
      "train loss:0.764779193277509\n",
      "train loss:0.9253328025182422\n",
      "train loss:0.9269144594737274\n",
      "train loss:0.8576728111117907\n",
      "train loss:0.8583176707497248\n",
      "train loss:0.9060849962558845\n",
      "train loss:0.7854534394815574\n",
      "train loss:0.8664598088283049\n",
      "train loss:0.738621027790726\n",
      "train loss:0.7295975717093082\n",
      "train loss:0.9518634336729076\n",
      "train loss:1.0382671690715675\n",
      "train loss:0.9148604734879648\n",
      "train loss:0.7235224897975692\n",
      "train loss:0.9460173653233228\n",
      "train loss:0.8280350940889807\n",
      "train loss:0.8980151163714032\n",
      "train loss:0.854072696240243\n",
      "train loss:0.9505115871869306\n",
      "train loss:0.893617412152072\n",
      "train loss:0.8398989858892593\n",
      "train loss:0.883948665765571\n",
      "train loss:0.9124104629909788\n",
      "train loss:0.7706594192584012\n",
      "train loss:0.893056901408709\n",
      "train loss:0.76277079661076\n",
      "train loss:0.9632508471044271\n",
      "train loss:0.9829643141724124\n",
      "train loss:0.9116188545097792\n",
      "train loss:0.8258229198716889\n",
      "train loss:0.9127036735175079\n",
      "train loss:1.0423052684384362\n",
      "train loss:0.876195725668557\n",
      "train loss:0.8333413228363382\n",
      "train loss:0.904429496010792\n",
      "train loss:0.9204041015190668\n",
      "train loss:0.8133225191477093\n",
      "train loss:0.666940147274055\n",
      "train loss:1.0561437381219962\n",
      "train loss:0.9548323111640706\n",
      "train loss:0.9277926505000929\n",
      "train loss:0.9649400551865931\n",
      "train loss:0.8251167995046442\n",
      "train loss:0.817379929584918\n",
      "train loss:0.8420030176883961\n",
      "train loss:0.898061278485265\n",
      "train loss:0.8863069587625355\n",
      "train loss:0.8434309279413362\n",
      "train loss:1.021031552583879\n",
      "train loss:0.9562464745548521\n",
      "train loss:0.7627056858850786\n",
      "train loss:0.8849322030988499\n",
      "train loss:1.1346364924847911\n",
      "train loss:0.7362113975146743\n",
      "train loss:0.8550765064769201\n",
      "train loss:0.9915336325976642\n",
      "train loss:0.8175187381498411\n",
      "train loss:0.910247326320023\n",
      "train loss:0.8791020823763751\n",
      "train loss:1.0639219959476443\n",
      "train loss:0.8233336885010917\n",
      "train loss:0.794026195263436\n",
      "train loss:0.8036207898049512\n",
      "train loss:0.7644667538183191\n",
      "train loss:0.9012943751441024\n",
      "train loss:0.895082897135256\n",
      "train loss:0.8853837454675975\n",
      "train loss:0.9519067207084553\n",
      "train loss:0.8350470724464659\n",
      "train loss:0.7703585960726328\n",
      "train loss:0.9222896285539177\n",
      "train loss:0.6221593951161768\n",
      "train loss:0.708442714447164\n",
      "train loss:0.9148940712945891\n",
      "train loss:0.8615103072009619\n",
      "train loss:0.8330826432541187\n",
      "train loss:0.9131429529627428\n",
      "train loss:0.8663761378948852\n",
      "train loss:0.8712373001557525\n",
      "train loss:0.9619288673493471\n",
      "train loss:0.78058538954922\n",
      "train loss:0.8547543034768563\n",
      "train loss:0.8722821976436514\n",
      "train loss:1.0377578795800875\n",
      "train loss:0.6638783664649465\n",
      "train loss:0.799245893032448\n",
      "train loss:0.8944034124591126\n",
      "train loss:0.8776787925964201\n",
      "train loss:0.9921431416312032\n",
      "train loss:0.804275638493518\n",
      "train loss:0.8445358352324303\n",
      "train loss:0.8817620484411655\n",
      "train loss:0.7318065744653288\n",
      "train loss:0.7446317404612495\n",
      "train loss:0.6669999040222936\n",
      "train loss:0.9416918466371698\n",
      "train loss:0.7036502922938473\n",
      "train loss:0.8374544099171826\n",
      "train loss:0.9345929869871399\n",
      "train loss:0.7311353338610904\n",
      "train loss:0.8286190022258357\n",
      "train loss:0.8076238426578112\n",
      "train loss:0.7223126543415677\n",
      "train loss:0.8817666707796208\n",
      "train loss:0.9500757836694242\n",
      "train loss:0.9163597896256213\n",
      "train loss:0.812335290828232\n",
      "train loss:0.952665616171768\n",
      "train loss:0.8429284370531999\n",
      "train loss:0.8470945678068081\n",
      "train loss:0.9543425897311368\n",
      "train loss:0.8758607830156842\n",
      "train loss:0.8422597847256115\n",
      "train loss:0.9137177727799193\n",
      "train loss:0.7677791453619865\n",
      "train loss:1.0191739627591792\n",
      "train loss:0.9932451209367141\n",
      "train loss:0.9561565546609968\n",
      "train loss:0.8258359456759531\n",
      "train loss:0.857112093934695\n",
      "train loss:0.7891366628830326\n",
      "train loss:0.6783225094225434\n",
      "train loss:0.9053127420884906\n",
      "train loss:0.9570610373219375\n",
      "train loss:1.019360797495902\n",
      "train loss:0.7531586254437438\n",
      "train loss:0.7957864595608025\n",
      "train loss:0.7099017497525828\n",
      "train loss:0.8899039029896352\n",
      "train loss:0.8338457701707703\n",
      "train loss:0.8985743565658245\n",
      "train loss:0.8669175663237652\n",
      "train loss:0.8955284720354295\n",
      "train loss:0.7390288422289848\n",
      "train loss:0.8303705128865586\n",
      "train loss:0.7921893945588536\n",
      "train loss:0.8234138961474529\n",
      "train loss:0.7744351169174748\n",
      "train loss:0.9037506957828586\n",
      "train loss:0.7770866309464524\n",
      "train loss:0.6998777069316301\n",
      "train loss:0.9901028278771606\n",
      "train loss:0.8688264094911357\n",
      "train loss:0.9875420447095878\n",
      "train loss:0.9954755489182423\n",
      "train loss:0.9210342867008553\n",
      "train loss:0.900056468435858\n",
      "train loss:0.9202569313067248\n",
      "train loss:0.7551753752396566\n",
      "train loss:0.7184286326662058\n",
      "train loss:0.849317692225053\n",
      "train loss:0.999308648476821\n",
      "train loss:0.8649423051352975\n",
      "train loss:0.9231214291195274\n",
      "train loss:1.0131067834934744\n",
      "train loss:0.8773627329243218\n",
      "train loss:0.7628502508310936\n",
      "train loss:0.8547904445587291\n",
      "train loss:0.9056417631926159\n",
      "train loss:0.7646498885603848\n",
      "train loss:0.8414821991683943\n",
      "train loss:0.9400404373844964\n",
      "train loss:0.8454182004423717\n",
      "train loss:0.8149274942847906\n",
      "train loss:0.8938443076985167\n",
      "train loss:0.901541125225677\n",
      "train loss:0.7619962828802963\n",
      "train loss:0.9769919673392442\n",
      "train loss:0.8415897728707136\n",
      "train loss:0.9477296870555513\n",
      "train loss:0.8477897426701446\n",
      "train loss:0.8695877977777351\n",
      "train loss:0.9803269440399461\n",
      "train loss:0.9364856925170325\n",
      "train loss:0.8297895032716351\n",
      "train loss:1.0323161521291433\n",
      "train loss:0.9364735056213344\n",
      "train loss:0.7201982342669301\n",
      "train loss:0.6605689274801356\n",
      "train loss:0.9601057771832641\n",
      "train loss:0.9215214096409047\n",
      "train loss:0.9250337942099989\n",
      "train loss:0.8534483704829607\n",
      "train loss:0.7740731139419118\n",
      "train loss:0.8596862622393608\n",
      "train loss:0.8549176236919817\n",
      "train loss:0.9009559103363265\n",
      "train loss:0.8373775532398254\n",
      "train loss:0.8827052231290555\n",
      "train loss:0.8506649279933356\n",
      "train loss:0.7990834918977993\n",
      "train loss:0.8938418594385503\n",
      "train loss:0.8940185141645987\n",
      "train loss:1.0965747717140821\n",
      "train loss:0.9623639855605819\n",
      "train loss:0.8943575093707051\n",
      "train loss:0.9022850463555108\n",
      "train loss:0.9771448590820065\n",
      "train loss:0.9738348015827707\n",
      "train loss:0.8714143411741854\n",
      "train loss:0.7873312545671612\n",
      "train loss:1.0689545804915264\n",
      "train loss:0.8127414485451996\n",
      "train loss:0.875174098188825\n",
      "train loss:0.9549742455047202\n",
      "train loss:0.8522707224095539\n",
      "train loss:0.9664686142400015\n",
      "train loss:0.84122641910729\n",
      "train loss:0.791799794732143\n",
      "train loss:0.805411731656158\n",
      "train loss:1.0075780436139428\n",
      "train loss:0.8308841811619199\n",
      "train loss:0.8929427379762199\n",
      "train loss:0.9322292730020775\n",
      "train loss:0.849793351662389\n",
      "train loss:0.7747279573956968\n",
      "train loss:0.8136771341873574\n",
      "train loss:0.8328242908670842\n",
      "train loss:0.9331156220129957\n",
      "train loss:0.8128649168581057\n",
      "train loss:0.9854081887500696\n",
      "train loss:0.8462629688977001\n",
      "train loss:0.7667228463900662\n",
      "train loss:0.8195989395828265\n",
      "train loss:0.6797313416877353\n",
      "train loss:0.8965372863500671\n",
      "train loss:0.9875446343715751\n",
      "train loss:0.8493491239274329\n",
      "train loss:0.8788479586555455\n",
      "train loss:0.8567027065548589\n",
      "train loss:0.8967722577567068\n",
      "train loss:0.8305721089028292\n",
      "train loss:0.8910272040238363\n",
      "train loss:0.9136548838294365\n",
      "train loss:0.8261961097056278\n",
      "train loss:0.9541891986605449\n",
      "train loss:0.9534584530768404\n",
      "train loss:1.0202083333444614\n",
      "train loss:0.8867949556314112\n",
      "train loss:0.7793906479002272\n",
      "train loss:1.0063611740334417\n",
      "train loss:0.7939400910181095\n",
      "train loss:0.9128614964454788\n",
      "train loss:0.9513643244165015\n",
      "train loss:0.8427410647603029\n",
      "train loss:0.8430764452031541\n",
      "train loss:0.8379008542779057\n",
      "train loss:0.8433105464559881\n",
      "train loss:0.9827700780392652\n",
      "train loss:0.8416265266883096\n",
      "train loss:0.8839816926566684\n",
      "train loss:0.9065123287028355\n",
      "train loss:0.8724625896416955\n",
      "train loss:0.9366373843000154\n",
      "train loss:0.9337972976899903\n",
      "train loss:0.9031167826623842\n",
      "train loss:0.7883759048669385\n",
      "train loss:0.8676231360123451\n",
      "train loss:0.7974536853404857\n",
      "train loss:0.8943160724113924\n",
      "train loss:0.8630682212764107\n",
      "train loss:0.8780363134543728\n",
      "train loss:0.8625518318849913\n",
      "train loss:0.8415814172245571\n",
      "train loss:0.8626121790975465\n",
      "train loss:0.8332374622527182\n",
      "train loss:0.8599623365149417\n",
      "train loss:0.8597836294384997\n",
      "train loss:0.9183489565082746\n",
      "train loss:0.9570096598357308\n",
      "train loss:0.7681693922700117\n",
      "train loss:0.8670102833236151\n",
      "train loss:0.9116084703667673\n",
      "train loss:1.000581508185688\n",
      "train loss:0.8340544257217481\n",
      "train loss:0.931910911752004\n",
      "train loss:0.778281908507505\n",
      "train loss:0.954729659407228\n",
      "train loss:0.8326552563411954\n",
      "train loss:0.9685407327524009\n",
      "train loss:0.9075085995800191\n",
      "train loss:0.9654198955164965\n",
      "train loss:0.8172517845212819\n",
      "train loss:0.9297091235677886\n",
      "train loss:0.7383865878515798\n",
      "train loss:0.9648236570675577\n",
      "train loss:0.9281850130734884\n",
      "train loss:0.7320857577437723\n",
      "train loss:0.8615620463203668\n",
      "train loss:0.923345941611773\n",
      "train loss:0.874623479601866\n",
      "train loss:0.7572298966605959\n",
      "train loss:0.9037008642208435\n",
      "train loss:0.8615001399245226\n",
      "train loss:0.9446471944609488\n",
      "train loss:0.6864112017920958\n",
      "train loss:0.8744801647202302\n",
      "train loss:0.8242058962748771\n",
      "train loss:0.9690834402057145\n",
      "train loss:1.0045405598684838\n",
      "train loss:1.0313464946739663\n",
      "train loss:0.8392261224143855\n",
      "train loss:0.9813859092033779\n",
      "train loss:0.8437178929734875\n",
      "train loss:0.936163985502552\n",
      "train loss:0.7977936335868563\n",
      "train loss:0.798579145165252\n",
      "train loss:0.9994049138519899\n",
      "train loss:0.9138026221920879\n",
      "train loss:0.8860723837121054\n",
      "train loss:0.8061842003602087\n",
      "train loss:0.9301961719316807\n",
      "train loss:0.8004449562238435\n",
      "train loss:0.9352598044715781\n",
      "train loss:0.8156174289064946\n",
      "train loss:0.8049170845426512\n",
      "train loss:0.8431728709867046\n",
      "train loss:0.976845665154509\n",
      "train loss:0.66597647348814\n",
      "train loss:0.8936576316734066\n",
      "train loss:0.9833927632421441\n",
      "train loss:1.0318446157124472\n",
      "train loss:0.8636776907814817\n",
      "train loss:0.8913669766724407\n",
      "train loss:0.9085235832833726\n",
      "train loss:0.8065880119002763\n",
      "train loss:0.8812787523998429\n",
      "train loss:1.078011541051837\n",
      "train loss:0.8191396959812666\n",
      "train loss:0.9315478650583553\n",
      "train loss:1.007407873915592\n",
      "train loss:0.7147895962724621\n",
      "train loss:0.9001367341512109\n",
      "train loss:0.9077939403169094\n",
      "train loss:0.7523426214596707\n",
      "train loss:0.9454467582855216\n",
      "train loss:1.0419242691487751\n",
      "train loss:0.8527349876317039\n",
      "train loss:0.9497197191533857\n",
      "train loss:0.7129643848530249\n",
      "train loss:0.9961786283145302\n",
      "train loss:0.8837130785210328\n",
      "train loss:0.8523098907095265\n",
      "train loss:0.8464334727788071\n",
      "train loss:1.0017531653001797\n",
      "train loss:0.8799712499210066\n",
      "train loss:0.8497198758726641\n",
      "train loss:0.7973747705187607\n",
      "train loss:0.8738329865850093\n",
      "train loss:0.9278663144213735\n",
      "train loss:0.8797712020803162\n",
      "train loss:0.8243218494019722\n",
      "train loss:0.9031609098697493\n",
      "train loss:0.9931271773314013\n",
      "train loss:0.8524964067295246\n",
      "train loss:0.8572278231745786\n",
      "train loss:0.9059284930496994\n",
      "train loss:0.802919390427661\n",
      "train loss:0.9016301417058536\n",
      "train loss:0.841315841108741\n",
      "train loss:0.8462807124280467\n",
      "train loss:0.850789754502214\n",
      "train loss:0.8335458367559347\n",
      "train loss:1.0175564847534122\n",
      "train loss:0.8310614198199247\n",
      "train loss:0.8808578057474357\n",
      "train loss:0.9314100433461655\n",
      "train loss:0.759534978707272\n",
      "train loss:0.9522040259533022\n",
      "train loss:0.9968601957860287\n",
      "train loss:0.8110959766744279\n",
      "train loss:0.8181374361800366\n",
      "train loss:0.8048434176530196\n",
      "train loss:0.9229217133581621\n",
      "train loss:0.9363169003130315\n",
      "train loss:0.9091220744905476\n",
      "train loss:0.6969559454450895\n",
      "train loss:0.8821367532243969\n",
      "train loss:0.7033909925430494\n",
      "train loss:1.0923884901642924\n",
      "train loss:0.895716037964524\n",
      "train loss:0.8748644645061954\n",
      "train loss:0.9313710438835555\n",
      "train loss:1.0108568722681897\n",
      "train loss:0.7860138609261393\n",
      "train loss:0.8226574973015554\n",
      "train loss:0.6939876011963593\n",
      "train loss:0.7948915615777844\n",
      "train loss:0.749632481758407\n",
      "train loss:1.067947167326258\n",
      "train loss:0.9534808230230835\n",
      "train loss:0.9151207536381607\n",
      "train loss:0.8909945144135311\n",
      "train loss:0.8398219137598508\n",
      "train loss:0.9791658869683819\n",
      "train loss:0.8304759636830953\n",
      "train loss:0.9158190953875021\n",
      "train loss:0.8436013883895151\n",
      "train loss:0.8258841282386912\n",
      "train loss:0.8632293425216737\n",
      "train loss:0.8034886318928552\n",
      "train loss:0.8521379300008515\n",
      "train loss:0.9834823590089974\n",
      "train loss:0.9701049806133295\n",
      "train loss:0.9576279428821434\n",
      "train loss:1.0247377580140138\n",
      "train loss:0.9697531408800104\n",
      "train loss:0.7856931273757691\n",
      "train loss:0.7562030757566126\n",
      "train loss:0.844098904741391\n",
      "train loss:1.0616595598934582\n",
      "train loss:0.9119996129097246\n",
      "train loss:0.845978221121156\n",
      "train loss:1.04542997502438\n",
      "train loss:0.9317466313543491\n",
      "train loss:0.8808222603004694\n",
      "train loss:0.8863228479057018\n",
      "train loss:0.8875166573346452\n",
      "train loss:0.7710513325544537\n",
      "train loss:0.7857399756206703\n",
      "train loss:0.8388899294755489\n",
      "train loss:0.8031420608807572\n",
      "train loss:1.064965465465137\n",
      "train loss:0.9385999615408592\n",
      "train loss:0.8784756971102666\n",
      "train loss:0.9871432020820596\n",
      "train loss:1.0384249913978434\n",
      "train loss:0.9163298447620929\n",
      "train loss:0.8090923695787765\n",
      "train loss:1.0007435781570875\n",
      "train loss:1.101448485117276\n",
      "train loss:0.9738277019512853\n",
      "train loss:0.7919446860777737\n",
      "train loss:0.9175594554197063\n",
      "train loss:0.9442164827959304\n",
      "train loss:0.9787693365548766\n",
      "train loss:0.8347013055319218\n",
      "train loss:0.8240212822339176\n",
      "train loss:0.9354856650998004\n",
      "train loss:0.8897144166762037\n",
      "train loss:1.0059573486010644\n",
      "train loss:0.8481571396806055\n",
      "train loss:1.0079671986436565\n",
      "train loss:0.9563563837286488\n",
      "train loss:0.7174812651230661\n",
      "train loss:0.9101360954650094\n",
      "train loss:0.852354092309594\n",
      "train loss:0.894632454706827\n",
      "train loss:0.885911714355252\n",
      "train loss:0.8063108131283887\n",
      "train loss:0.8399562230736279\n",
      "train loss:0.7795277732088569\n",
      "train loss:0.8897023987059539\n",
      "train loss:0.7968682725219888\n",
      "train loss:0.8407371704186712\n",
      "train loss:0.870678072430808\n",
      "train loss:0.845836017450613\n",
      "train loss:0.9909195091026258\n",
      "train loss:0.8927517522087642\n",
      "train loss:1.0752763163962433\n",
      "train loss:0.8403884693187225\n",
      "train loss:0.8312788304337111\n",
      "=== epoch:16, train acc:0.997, test acc:0.986 ===\n",
      "train loss:1.0292330875101532\n",
      "train loss:0.747074423707257\n",
      "train loss:0.8227990970412893\n",
      "train loss:0.9535491884173062\n",
      "train loss:0.9776414592408083\n",
      "train loss:0.9515008858448146\n",
      "train loss:0.9245144532131149\n",
      "train loss:0.8701525499034775\n",
      "train loss:0.8572483195801509\n",
      "train loss:0.8897088020946994\n",
      "train loss:0.9982451144216165\n",
      "train loss:0.7847479945372241\n",
      "train loss:0.7761198166118908\n",
      "train loss:0.7306305654022089\n",
      "train loss:0.7458965291475366\n",
      "train loss:0.8004962348083722\n",
      "train loss:0.999241489763089\n",
      "train loss:0.889735706479652\n",
      "train loss:0.6776541890523512\n",
      "train loss:0.7777654166044624\n",
      "train loss:0.7728230028379093\n",
      "train loss:0.8421536517533255\n",
      "train loss:0.886024570880043\n",
      "train loss:0.7981303701772111\n",
      "train loss:0.844751572405039\n",
      "train loss:0.8840258091981774\n",
      "train loss:0.8514275866607973\n",
      "train loss:0.9151203319960521\n",
      "train loss:0.7006727389671434\n",
      "train loss:0.8913076709372446\n",
      "train loss:0.9183598011328098\n",
      "train loss:0.7237843167181466\n",
      "train loss:0.9321759343573328\n",
      "train loss:0.8593456838974047\n",
      "train loss:1.0791589964251134\n",
      "train loss:0.8244677348753615\n",
      "train loss:0.8355204555288597\n",
      "train loss:0.9414269609929533\n",
      "train loss:1.0011474360394004\n",
      "train loss:0.9043353180719476\n",
      "train loss:0.8982191270984811\n",
      "train loss:0.9246313007908378\n",
      "train loss:0.8955157761136634\n",
      "train loss:0.9572666098538601\n",
      "train loss:0.8353288599360448\n",
      "train loss:0.8761581357664363\n",
      "train loss:0.9919334637504238\n",
      "train loss:0.8297890763314836\n",
      "train loss:0.6981991439483538\n",
      "train loss:0.8121872235226085\n",
      "train loss:0.8721146465835514\n",
      "train loss:0.8003280435617018\n",
      "train loss:0.7897212610360863\n",
      "train loss:0.8495598458977446\n",
      "train loss:0.5724173520374075\n",
      "train loss:0.9746529788481065\n",
      "train loss:0.9391341214408441\n",
      "train loss:0.9087190876050658\n",
      "train loss:0.97300942476623\n",
      "train loss:0.743625122402732\n",
      "train loss:0.7883475105484142\n",
      "train loss:0.8458694296602829\n",
      "train loss:0.8051663339843637\n",
      "train loss:0.9202448325732098\n",
      "train loss:1.005437554343914\n",
      "train loss:0.8072955785514881\n",
      "train loss:0.9161904644998206\n",
      "train loss:0.9441267736044903\n",
      "train loss:0.8293064287759937\n",
      "train loss:0.8696182701344957\n",
      "train loss:0.9084655994823488\n",
      "train loss:0.7688377564300077\n",
      "train loss:0.8633129658364465\n",
      "train loss:0.9944426464648608\n",
      "train loss:1.0207489959712404\n",
      "train loss:0.8842258791569513\n",
      "train loss:0.8952694883909527\n",
      "train loss:0.9223141559502863\n",
      "train loss:0.7903592269223233\n",
      "train loss:0.9247241264650465\n",
      "train loss:0.9506281972637044\n",
      "train loss:0.7462771445974706\n",
      "train loss:0.7706894026635218\n",
      "train loss:0.7400496530722097\n",
      "train loss:0.953482608752161\n",
      "train loss:0.885366498608238\n",
      "train loss:1.055566931803153\n",
      "train loss:0.9313515088074655\n",
      "train loss:0.8776546434476539\n",
      "train loss:0.8896836274122778\n",
      "train loss:0.8960345453177593\n",
      "train loss:0.8362806757745989\n",
      "train loss:0.668558328659864\n",
      "train loss:0.9451788575679727\n",
      "train loss:0.6883015285928994\n",
      "train loss:0.7460181423522516\n",
      "train loss:0.9640509786390244\n",
      "train loss:0.9993393768560361\n",
      "train loss:0.9082381956486277\n",
      "train loss:1.0182194118557\n",
      "train loss:0.7961356159873657\n",
      "train loss:0.8933418887465255\n",
      "train loss:0.762655212077089\n",
      "train loss:0.967903892881489\n",
      "train loss:0.876322757155649\n",
      "train loss:0.8603157344360685\n",
      "train loss:0.8893030740336388\n",
      "train loss:1.0082461680957133\n",
      "train loss:0.862916139761324\n",
      "train loss:0.8948269474902614\n",
      "train loss:0.8656829487480602\n",
      "train loss:0.8646646562267832\n",
      "train loss:0.8343133836900739\n",
      "train loss:0.807333586646183\n",
      "train loss:0.935223464291945\n",
      "train loss:0.8393359387883667\n",
      "train loss:1.110072983947037\n",
      "train loss:0.8841931095737895\n",
      "train loss:1.0220612084223892\n",
      "train loss:0.8064297069350527\n",
      "train loss:0.9684531637554754\n",
      "train loss:0.8636254684713481\n",
      "train loss:0.9253650594512469\n",
      "train loss:0.9055121051563836\n",
      "train loss:0.8874025123151624\n",
      "train loss:0.9424899245468823\n",
      "train loss:0.9156653827275352\n",
      "train loss:0.857281990021572\n",
      "train loss:0.8328833108127749\n",
      "train loss:0.7902630538040737\n",
      "train loss:0.884885838850292\n",
      "train loss:1.0023068586300623\n",
      "train loss:0.8689656498118533\n",
      "train loss:0.8627334257748273\n",
      "train loss:0.7786437059286007\n",
      "train loss:0.9856094834977278\n",
      "train loss:0.8455447710341975\n",
      "train loss:0.9625630499724077\n",
      "train loss:1.0840071312353\n",
      "train loss:1.0441984729920943\n",
      "train loss:0.9394438571653351\n",
      "train loss:0.8138956651219569\n",
      "train loss:0.9184048399741961\n",
      "train loss:0.9625059310630318\n",
      "train loss:0.9334365102508552\n",
      "train loss:1.062534687833349\n",
      "train loss:0.8742063406245478\n",
      "train loss:0.8487496212054856\n",
      "train loss:0.7952208207810885\n",
      "train loss:0.9822733761810802\n",
      "train loss:1.015671622144265\n",
      "train loss:0.9438098952106065\n",
      "train loss:0.8397424149537472\n",
      "train loss:1.0188363135373766\n",
      "train loss:0.7447266443309444\n",
      "train loss:0.720591676789615\n",
      "train loss:0.9063521450853469\n",
      "train loss:0.7547294561333938\n",
      "train loss:1.0795050412775826\n",
      "train loss:1.009045812194849\n",
      "train loss:0.9850230209484397\n",
      "train loss:0.6251405499244842\n",
      "train loss:0.9038979035408043\n",
      "train loss:0.9583025331691474\n",
      "train loss:0.908816386987559\n",
      "train loss:1.0010776184345471\n",
      "train loss:0.9105461871840684\n",
      "train loss:1.0001714516834113\n",
      "train loss:0.8477737521006\n",
      "train loss:0.9109426039172425\n",
      "train loss:0.7927478848007561\n",
      "train loss:0.8891823065181087\n",
      "train loss:0.771462657921059\n",
      "train loss:0.9537330922775147\n",
      "train loss:0.9265751228482987\n",
      "train loss:1.006948202786154\n",
      "train loss:0.7734923480273157\n",
      "train loss:0.8609677777746014\n",
      "train loss:0.8210119255425878\n",
      "train loss:0.7926974436631983\n",
      "train loss:0.6868148734998133\n",
      "train loss:0.7327327564568253\n",
      "train loss:1.0415295532035993\n",
      "train loss:0.8464872652932312\n",
      "train loss:1.0356590377435575\n",
      "train loss:1.0460774077265336\n",
      "train loss:0.8342946742552868\n",
      "train loss:0.8356030966024656\n",
      "train loss:0.8931221891089116\n",
      "train loss:0.7069990351147186\n",
      "train loss:0.9773609412471816\n",
      "train loss:0.863266891131681\n",
      "train loss:0.9745431822331558\n",
      "train loss:0.835798322329086\n",
      "train loss:0.812149228960126\n",
      "train loss:0.773320302227638\n",
      "train loss:0.9512058975319826\n",
      "train loss:0.933432431212273\n",
      "train loss:0.8132097870419976\n",
      "train loss:0.8354502514197922\n",
      "train loss:0.7726174800304763\n",
      "train loss:0.8468407025467521\n",
      "train loss:1.005038728376509\n",
      "train loss:0.8449734253166423\n",
      "train loss:0.8799379688691886\n",
      "train loss:0.9585931074971734\n",
      "train loss:0.7995370140593026\n",
      "train loss:0.7546630482815735\n",
      "train loss:0.8139767731118449\n",
      "train loss:0.9864025257985205\n",
      "train loss:0.7267358142498926\n",
      "train loss:0.7450444077727699\n",
      "train loss:0.9277939854302703\n",
      "train loss:1.0089336584416804\n",
      "train loss:0.7322401444187148\n",
      "train loss:0.862083291809497\n",
      "train loss:0.9727856533774165\n",
      "train loss:0.786723325856095\n",
      "train loss:0.904786177449182\n",
      "train loss:0.8325825433214834\n",
      "train loss:0.8661609177936299\n",
      "train loss:0.7971644819880598\n",
      "train loss:0.831816313055957\n",
      "train loss:1.0876675665844082\n",
      "train loss:0.7264955914286148\n",
      "train loss:0.8894918449134388\n",
      "train loss:0.8843557820876202\n",
      "train loss:0.9011712257597303\n",
      "train loss:0.8631063047323397\n",
      "train loss:0.7583510269261048\n",
      "train loss:0.8100018891678933\n",
      "train loss:0.9999361763393628\n",
      "train loss:0.9122562843418554\n",
      "train loss:0.9787216256668375\n",
      "train loss:0.7111412562640231\n",
      "train loss:0.8921466151477014\n",
      "train loss:0.842795661898251\n",
      "train loss:0.7970530399980339\n",
      "train loss:0.8631630828620598\n",
      "train loss:0.9243154403619713\n",
      "train loss:0.8477892280600422\n",
      "train loss:0.834669552484891\n",
      "train loss:0.840970030460102\n",
      "train loss:0.9479445629583584\n",
      "train loss:1.0160195738132236\n",
      "train loss:0.8539836043497218\n",
      "train loss:0.7885628525882489\n",
      "train loss:0.797515848296939\n",
      "train loss:0.8856949128103716\n",
      "train loss:0.7968121411885899\n",
      "train loss:0.8197906855714158\n",
      "train loss:0.8808020433837023\n",
      "train loss:1.0616551069304923\n",
      "train loss:0.843064448500446\n",
      "train loss:0.8097903344527314\n",
      "train loss:0.8358447030870232\n",
      "train loss:0.8665558637055168\n",
      "train loss:0.8208186364520542\n",
      "train loss:0.9419722151638489\n",
      "train loss:0.8477649533033228\n",
      "train loss:0.6337768026533377\n",
      "train loss:0.9268153362173746\n",
      "train loss:0.8558871211949551\n",
      "train loss:0.8623901172073921\n",
      "train loss:0.8062054629111752\n",
      "train loss:0.9382562755007089\n",
      "train loss:0.8210057669352999\n",
      "train loss:0.90579904442925\n",
      "train loss:0.8091629559699881\n",
      "train loss:0.742946696395436\n",
      "train loss:0.9094866026310996\n",
      "train loss:0.8688153909333611\n",
      "train loss:0.9397513318878982\n",
      "train loss:0.8195388222592201\n",
      "train loss:0.9972930125923947\n",
      "train loss:0.8568005406537493\n",
      "train loss:0.7647145705860414\n",
      "train loss:0.8613747128517126\n",
      "train loss:0.8749512413362449\n",
      "train loss:0.8069977735373232\n",
      "train loss:0.9503994270426128\n",
      "train loss:0.9757444808540413\n",
      "train loss:0.909096103495382\n",
      "train loss:0.9062119715358482\n",
      "train loss:0.8541504417984556\n",
      "train loss:0.8879243229712139\n",
      "train loss:0.9826915332927401\n",
      "train loss:0.8326708050617496\n",
      "train loss:0.7512465213325538\n",
      "train loss:0.9058926061403477\n",
      "train loss:0.9674758112250678\n",
      "train loss:0.7142583684377246\n",
      "train loss:0.8229012322982971\n",
      "train loss:0.9549022298257962\n",
      "train loss:0.9384716161162265\n",
      "train loss:0.9730532898530181\n",
      "train loss:0.741776356769729\n",
      "train loss:0.8239590362981463\n",
      "train loss:0.7134688351649359\n",
      "train loss:0.8153484042043013\n",
      "train loss:0.8729182055276393\n",
      "train loss:0.8586380072343062\n",
      "train loss:1.0100431848086413\n",
      "train loss:0.8539899970088801\n",
      "train loss:0.9546460694799679\n",
      "train loss:0.6666440958244452\n",
      "train loss:0.8799830689143902\n",
      "train loss:0.9048459796739252\n",
      "train loss:0.8147795309721134\n",
      "train loss:1.0007045357207713\n",
      "train loss:0.8462112654779841\n",
      "train loss:0.8782801994171553\n",
      "train loss:0.7846369177884186\n",
      "train loss:1.020529083100155\n",
      "train loss:0.8627943937354696\n",
      "train loss:0.8866566781635967\n",
      "train loss:0.8671901547771178\n",
      "train loss:0.7752715245419197\n",
      "train loss:0.7362641822871525\n",
      "train loss:0.8979543716334579\n",
      "train loss:0.8649061577736947\n",
      "train loss:1.0023332489592185\n",
      "train loss:0.7263161102450272\n",
      "train loss:0.8829095651827333\n",
      "train loss:0.8230611231941407\n",
      "train loss:0.9075376146019519\n",
      "train loss:0.90086778977426\n",
      "train loss:0.7361651742553191\n",
      "train loss:0.9194634881210844\n",
      "train loss:0.939922505106182\n",
      "train loss:0.9552287031226944\n",
      "train loss:0.834749291754679\n",
      "train loss:0.9805809260876801\n",
      "train loss:0.8320758788444839\n",
      "train loss:0.7935544527184273\n",
      "train loss:0.7751097799511796\n",
      "train loss:0.8878436527009047\n",
      "train loss:0.7132397098702173\n",
      "train loss:0.8170071898029414\n",
      "train loss:0.8548342800686823\n",
      "train loss:0.8389221535038304\n",
      "train loss:0.8288117606222134\n",
      "train loss:0.9218484321425445\n",
      "train loss:0.9201672764649845\n",
      "train loss:0.8890382607054856\n",
      "train loss:0.9269232534519294\n",
      "train loss:0.7352380076212155\n",
      "train loss:0.8367026402394246\n",
      "train loss:0.9254582285929845\n",
      "train loss:0.8459018554236283\n",
      "train loss:0.7285914571924391\n",
      "train loss:0.9169737443603754\n",
      "train loss:0.8880000303551907\n",
      "train loss:0.9362529771490149\n",
      "train loss:0.9144153586191596\n",
      "train loss:0.8644866188610145\n",
      "train loss:0.8836077640670801\n",
      "train loss:0.9637405330875414\n",
      "train loss:0.7715245843669483\n",
      "train loss:0.8604148842617918\n",
      "train loss:1.1025283353065813\n",
      "train loss:0.7172774002544148\n",
      "train loss:1.0409674157126556\n",
      "train loss:0.7250184665507371\n",
      "train loss:0.7671372512363783\n",
      "train loss:0.9603034356796415\n",
      "train loss:0.8486865673315992\n",
      "train loss:0.9634175786379373\n",
      "train loss:0.7757575674428225\n",
      "train loss:0.908383304956353\n",
      "train loss:0.9844533070204985\n",
      "train loss:0.8652926376618055\n",
      "train loss:1.0039980758019693\n",
      "train loss:0.8463699454221133\n",
      "train loss:0.7607523957706854\n",
      "train loss:0.9888639242882307\n",
      "train loss:0.7626748600503044\n",
      "train loss:0.9230361597410977\n",
      "train loss:0.8534373673313386\n",
      "train loss:0.9853239286214179\n",
      "train loss:0.895359728511697\n",
      "train loss:0.6400245680242415\n",
      "train loss:0.7959829133703233\n",
      "train loss:0.7837637239621855\n",
      "train loss:0.8884693222137551\n",
      "train loss:0.8361267287743032\n",
      "train loss:0.7013452363196011\n",
      "train loss:0.7595294633840795\n",
      "train loss:0.8091021862689317\n",
      "train loss:0.8038047813053104\n",
      "train loss:0.7921941885244899\n",
      "train loss:0.7326469181223552\n",
      "train loss:0.8978496538771368\n",
      "train loss:0.8298583284762985\n",
      "train loss:0.8334375111253303\n",
      "train loss:0.7996024297573184\n",
      "train loss:0.8575823034387529\n",
      "train loss:0.7805207116174248\n",
      "train loss:0.9846461381663498\n",
      "train loss:0.6152365940082462\n",
      "train loss:1.0494222596790284\n",
      "train loss:1.0398969628246046\n",
      "train loss:0.6432132719828216\n",
      "train loss:1.1372757034672218\n",
      "train loss:0.9501087500161874\n",
      "train loss:0.8708913588077561\n",
      "train loss:0.9195679699835974\n",
      "train loss:1.0784992430215443\n",
      "train loss:0.8310941830683878\n",
      "train loss:0.772495841668187\n",
      "train loss:0.9619921900694883\n",
      "train loss:0.9331182700962743\n",
      "train loss:0.7962350997706712\n",
      "train loss:0.8456083823476266\n",
      "train loss:0.9011648017070809\n",
      "train loss:0.7995442678364519\n",
      "train loss:0.8132078018111819\n",
      "train loss:0.8170832947849089\n",
      "train loss:0.8843138915607257\n",
      "train loss:0.9554300547473682\n",
      "train loss:0.838190714964239\n",
      "train loss:0.8075783333209892\n",
      "train loss:0.8390123815195877\n",
      "train loss:0.7711071849321322\n",
      "train loss:0.756828961542265\n",
      "train loss:0.9794550909556068\n",
      "train loss:0.9426011800378836\n",
      "train loss:0.7826179070284698\n",
      "train loss:0.8240616938805703\n",
      "train loss:0.815599182946881\n",
      "train loss:0.8349963326140155\n",
      "train loss:0.8030676623555193\n",
      "train loss:1.0516081142679525\n",
      "train loss:0.8714617247343809\n",
      "train loss:0.8165114135192023\n",
      "train loss:0.9478130788365423\n",
      "train loss:0.7125262276405366\n",
      "train loss:1.126591553144917\n",
      "train loss:0.7852034891038688\n",
      "train loss:0.6836419708570186\n",
      "train loss:0.9534366118778427\n",
      "train loss:0.7699067410609308\n",
      "train loss:0.8206938436472428\n",
      "train loss:0.8997003652273824\n",
      "train loss:1.0255906249286526\n",
      "train loss:0.9230812647866231\n",
      "train loss:0.7402207264831148\n",
      "train loss:1.0124429352182331\n",
      "train loss:0.9954945990128417\n",
      "train loss:0.9986957900687206\n",
      "train loss:0.9386319750148197\n",
      "train loss:0.8914505801980954\n",
      "train loss:0.9075357216708546\n",
      "train loss:0.7657987161797543\n",
      "train loss:0.921676722689977\n",
      "train loss:0.9010588709610122\n",
      "train loss:0.8535793021651665\n",
      "train loss:0.921970805809341\n",
      "train loss:0.8441916600871012\n",
      "train loss:0.6594112074567233\n",
      "train loss:0.8145640803542338\n",
      "train loss:0.943485835856574\n",
      "train loss:0.9710892197239854\n",
      "train loss:0.8709328554478375\n",
      "train loss:0.9833374277553806\n",
      "train loss:0.8580866674595078\n",
      "train loss:0.8389056604575954\n",
      "train loss:0.9198779670423989\n",
      "train loss:0.7186567316798346\n",
      "train loss:1.0648993482864035\n",
      "train loss:0.9274910536825238\n",
      "train loss:0.9968813458234098\n",
      "train loss:0.7229594275823821\n",
      "train loss:0.9764053076109227\n",
      "train loss:0.9634953247174362\n",
      "train loss:0.9487234013470395\n",
      "train loss:0.9392315360062564\n",
      "train loss:0.9494806251231667\n",
      "train loss:0.9065569104353264\n",
      "train loss:0.8898163133093342\n",
      "train loss:1.0687121603182523\n",
      "train loss:0.8529192650933137\n",
      "train loss:0.7975918224357967\n",
      "train loss:0.8820524474137912\n",
      "train loss:0.8954142236474327\n",
      "train loss:0.8455460342323343\n",
      "train loss:1.0186769184094657\n",
      "train loss:0.7963920582228781\n",
      "train loss:0.7441922538360447\n",
      "train loss:0.7978080829782138\n",
      "train loss:0.778575772970714\n",
      "train loss:0.7634535397249776\n",
      "train loss:0.8537567386315317\n",
      "train loss:0.795154749535557\n",
      "train loss:0.8044816595288861\n",
      "train loss:0.947945667559221\n",
      "train loss:0.8074613776787721\n",
      "train loss:0.8041555325238278\n",
      "train loss:0.907115842632136\n",
      "train loss:0.9677504277537555\n",
      "train loss:0.9156360798894793\n",
      "train loss:0.8161978665778051\n",
      "train loss:0.7720051775674199\n",
      "train loss:0.7255353965710454\n",
      "train loss:0.9537691870576682\n",
      "train loss:0.9816824605924696\n",
      "train loss:0.8373932246495579\n",
      "train loss:0.823111253916506\n",
      "train loss:0.7242279022740016\n",
      "train loss:0.9433760921346243\n",
      "train loss:0.8910790246908334\n",
      "train loss:0.9173967674324001\n",
      "train loss:0.961944432171501\n",
      "train loss:0.820086847925294\n",
      "train loss:0.9070948276642623\n",
      "train loss:0.926485851108128\n",
      "train loss:0.8510669669849578\n",
      "train loss:0.8664342628059346\n",
      "train loss:0.8457590304292251\n",
      "train loss:0.9510835546488429\n",
      "train loss:0.5936410017510845\n",
      "train loss:0.9415491942407545\n",
      "train loss:0.8871697339047161\n",
      "train loss:0.852632522348369\n",
      "train loss:0.7883923615092405\n",
      "train loss:0.8482670098703702\n",
      "train loss:0.7370173969610909\n",
      "train loss:0.9040836851577148\n",
      "train loss:0.9275783514113811\n",
      "train loss:0.9595341264830075\n",
      "train loss:1.0511539033518154\n",
      "train loss:0.7567773072991851\n",
      "train loss:0.8168766688846846\n",
      "train loss:1.049544895801927\n",
      "train loss:0.730480692022346\n",
      "train loss:0.8431590378624062\n",
      "train loss:0.9938822086053039\n",
      "train loss:0.8339535937079559\n",
      "train loss:0.8077652363624178\n",
      "train loss:0.8289831373852024\n",
      "train loss:0.8303313165636582\n",
      "train loss:0.8058058029389918\n",
      "train loss:0.7758884488795361\n",
      "train loss:0.9105348796553475\n",
      "train loss:0.7550721547993057\n",
      "train loss:0.863658649183739\n",
      "train loss:0.9270882991390793\n",
      "train loss:0.7921308559890383\n",
      "train loss:1.0025444612300765\n",
      "train loss:0.8452230015365378\n",
      "train loss:1.001056323740617\n",
      "train loss:0.8749578993676842\n",
      "train loss:0.8177259815152681\n",
      "train loss:1.0326266325508668\n",
      "train loss:0.8793199874557209\n",
      "train loss:0.9332069005685409\n",
      "train loss:0.9043550501035793\n",
      "train loss:0.9602538047946786\n",
      "train loss:0.8090604300792438\n",
      "train loss:0.7698576163016427\n",
      "train loss:1.0033624447542964\n",
      "train loss:0.8034813393978085\n",
      "train loss:1.0321641884760384\n",
      "train loss:0.7738109826207014\n",
      "train loss:0.9359359375645135\n",
      "train loss:0.7874728216693352\n",
      "train loss:0.890045631242787\n",
      "train loss:1.0312798790764253\n",
      "train loss:1.1640550972786656\n",
      "train loss:0.7626319651013833\n",
      "train loss:0.7757841767273935\n",
      "train loss:0.8097892980427366\n",
      "train loss:0.8666837247715954\n",
      "train loss:0.9009994343695081\n",
      "train loss:0.8914279444542293\n",
      "train loss:0.9558976353380966\n",
      "train loss:0.9458638065556545\n",
      "train loss:0.6718956684280303\n",
      "train loss:0.7883232521227131\n",
      "train loss:0.8348040788574754\n",
      "train loss:0.8156303175671864\n",
      "train loss:0.8212427800738175\n",
      "train loss:1.0025792155996995\n",
      "train loss:0.8065714808991529\n",
      "train loss:0.8315731846643076\n",
      "train loss:0.9487391965820673\n",
      "train loss:0.827573568415206\n",
      "train loss:0.9322552320073154\n",
      "train loss:0.8608555744043523\n",
      "train loss:1.0716819669721425\n",
      "train loss:0.7562775100318722\n",
      "train loss:1.067088294528373\n",
      "train loss:0.8658037781112625\n",
      "train loss:0.8173635239694899\n",
      "train loss:0.853067943615112\n",
      "train loss:0.8970241114242586\n",
      "train loss:0.7919300562240876\n",
      "train loss:0.7264314350182479\n",
      "train loss:0.8932535673701507\n",
      "train loss:0.8543719236038133\n",
      "=== epoch:17, train acc:0.995, test acc:0.99 ===\n",
      "train loss:0.7655845301975955\n",
      "train loss:0.8025578798740614\n",
      "train loss:0.7714384567936596\n",
      "train loss:1.0436245075772381\n",
      "train loss:1.0538292214171912\n",
      "train loss:0.8064858191260016\n",
      "train loss:0.8793572592423753\n",
      "train loss:0.9375810242091386\n",
      "train loss:0.738658209207844\n",
      "train loss:0.898153469012061\n",
      "train loss:0.838775088738397\n",
      "train loss:0.9063145607063887\n",
      "train loss:0.9802558733947063\n",
      "train loss:0.883838215929961\n",
      "train loss:0.9346779141654491\n",
      "train loss:0.8614259528943028\n",
      "train loss:0.8103157687909261\n",
      "train loss:0.7896951179681985\n",
      "train loss:0.7959090377113529\n",
      "train loss:0.7747195500541899\n",
      "train loss:0.9547105266950077\n",
      "train loss:0.9138099179049652\n",
      "train loss:0.8804212774230119\n",
      "train loss:0.9514419136528306\n",
      "train loss:0.921276671667089\n",
      "train loss:0.995384261694943\n",
      "train loss:0.924056806866015\n",
      "train loss:0.9342282283812468\n",
      "train loss:0.8849681055840266\n",
      "train loss:0.78490249453497\n",
      "train loss:0.9853077249996244\n",
      "train loss:0.7299282639960115\n",
      "train loss:0.8920427963477127\n",
      "train loss:0.9649360238650155\n",
      "train loss:0.8908907508846707\n",
      "train loss:0.7856307342164315\n",
      "train loss:0.8905484265646127\n",
      "train loss:0.9531957508011547\n",
      "train loss:0.8079889451116441\n",
      "train loss:0.7371239930195476\n",
      "train loss:0.8987054946837734\n",
      "train loss:0.7737981554230936\n",
      "train loss:0.914310752428895\n",
      "train loss:0.8367942147222377\n",
      "train loss:0.9608792764684816\n",
      "train loss:0.896326367285581\n",
      "train loss:0.8815841031972766\n",
      "train loss:0.7635720894653276\n",
      "train loss:0.8558198283831888\n",
      "train loss:1.1178107689658787\n",
      "train loss:1.0426263767750195\n",
      "train loss:0.7562462128566486\n",
      "train loss:0.873379777661104\n",
      "train loss:0.9356620563113992\n",
      "train loss:0.80446282907074\n",
      "train loss:0.7921965679413522\n",
      "train loss:0.7518455215150343\n",
      "train loss:0.8457842114112587\n",
      "train loss:0.8226466967886179\n",
      "train loss:0.8491379270653867\n",
      "train loss:0.8949346250040985\n",
      "train loss:0.7959293040868575\n",
      "train loss:0.9270820891913609\n",
      "train loss:0.8265148107991764\n",
      "train loss:0.9352119279245585\n",
      "train loss:0.8852335737084739\n",
      "train loss:0.8958460561196209\n",
      "train loss:0.9251672251538655\n",
      "train loss:0.7844633595122482\n",
      "train loss:0.9621882850878621\n",
      "train loss:0.8132073333887226\n",
      "train loss:0.8910641964761435\n",
      "train loss:0.9275294190506739\n",
      "train loss:0.8000218023390236\n",
      "train loss:0.8360931459174765\n",
      "train loss:0.9864792509975422\n",
      "train loss:0.9361527625618968\n",
      "train loss:0.8544715611085947\n",
      "train loss:0.6667526822762379\n",
      "train loss:0.8572702749956741\n",
      "train loss:0.7673044674535562\n",
      "train loss:0.9001283094062374\n",
      "train loss:0.8896426594733284\n",
      "train loss:0.933889500856933\n",
      "train loss:0.9473697548495766\n",
      "train loss:0.756942321722791\n",
      "train loss:0.8324893230613956\n",
      "train loss:0.8159202875004755\n",
      "train loss:0.8105242855179398\n",
      "train loss:0.7902395277874643\n",
      "train loss:0.8819357421992913\n",
      "train loss:0.6937553669633018\n",
      "train loss:1.0348212378675075\n",
      "train loss:0.932165907757417\n",
      "train loss:0.8223980902752176\n",
      "train loss:0.8011318926603309\n",
      "train loss:0.8817292054083099\n",
      "train loss:0.8391138264405481\n",
      "train loss:0.9482879592151674\n",
      "train loss:0.8068717298555995\n",
      "train loss:0.9256277296077685\n",
      "train loss:0.8936563314275178\n",
      "train loss:0.8621192527869839\n",
      "train loss:0.8056452337452013\n",
      "train loss:0.9431577715648042\n",
      "train loss:1.0021834470449202\n",
      "train loss:1.1748964234119232\n",
      "train loss:0.7547993808843683\n",
      "train loss:0.9723723509461193\n",
      "train loss:0.9420441972632076\n",
      "train loss:0.8982474224550282\n",
      "train loss:0.9255036248380921\n",
      "train loss:0.8261085858651022\n",
      "train loss:0.9595792704189412\n",
      "train loss:0.8168673884916581\n",
      "train loss:0.7876954823227765\n",
      "train loss:0.6682728675107859\n",
      "train loss:0.8375820605140329\n",
      "train loss:0.8725246390266759\n",
      "train loss:0.9601474490376286\n",
      "train loss:0.8884494565749317\n",
      "train loss:0.7472474813715994\n",
      "train loss:0.8105385923438984\n",
      "train loss:0.8880203351094891\n",
      "train loss:0.7745700691186268\n",
      "train loss:0.8595623391494692\n",
      "train loss:0.993052387209136\n",
      "train loss:1.0300936019121258\n",
      "train loss:0.9350807992842479\n",
      "train loss:0.9081293395290356\n",
      "train loss:0.7230450260362298\n",
      "train loss:1.0769422792849548\n",
      "train loss:1.0432602896913774\n",
      "train loss:0.8610822542166445\n",
      "train loss:0.9427701421412005\n",
      "train loss:0.7660685650290199\n",
      "train loss:0.9373926892918091\n",
      "train loss:0.6742058791077936\n",
      "train loss:0.9199499392466489\n",
      "train loss:0.8124033569006406\n",
      "train loss:0.9194558976783789\n",
      "train loss:0.9228084995011804\n",
      "train loss:0.9716896236056272\n",
      "train loss:0.7085016882919232\n",
      "train loss:0.8170549949354874\n",
      "train loss:1.0290216797024254\n",
      "train loss:0.8266532433582683\n",
      "train loss:0.736344818031244\n",
      "train loss:0.8810836878776273\n",
      "train loss:0.7813236879010522\n",
      "train loss:0.8618564739945529\n",
      "train loss:0.8039153875265336\n",
      "train loss:0.9827888630228491\n",
      "train loss:0.8605678072893131\n",
      "train loss:0.7960067482289428\n",
      "train loss:0.7227047721220817\n",
      "train loss:0.9196333448684303\n",
      "train loss:0.8612456407083563\n",
      "train loss:0.8360104936798275\n",
      "train loss:0.8127210407650857\n",
      "train loss:0.9220444460989765\n",
      "train loss:0.7711769837562612\n",
      "train loss:0.7684688118768325\n",
      "train loss:0.7379692397214889\n",
      "train loss:0.8052839930280257\n",
      "train loss:0.9732738807860852\n",
      "train loss:1.006671443859062\n",
      "train loss:0.8575420282757519\n",
      "train loss:0.8685848579568034\n",
      "train loss:0.8867054919875946\n",
      "train loss:0.7440951712320019\n",
      "train loss:0.8067994055713933\n",
      "train loss:1.0065234517646666\n",
      "train loss:1.0784804610060332\n",
      "train loss:0.7396495883898675\n",
      "train loss:0.9608241458595667\n",
      "train loss:0.8332628125262328\n",
      "train loss:0.7979473892860236\n",
      "train loss:0.7620167850678798\n",
      "train loss:0.825051366241671\n",
      "train loss:0.819744090124184\n",
      "train loss:0.7043517754280602\n",
      "train loss:0.9010047880687422\n",
      "train loss:0.8856314636732584\n",
      "train loss:0.7694947041142548\n",
      "train loss:1.0275202710698363\n",
      "train loss:0.8804120358348583\n",
      "train loss:1.016387979397015\n",
      "train loss:0.887964202037887\n",
      "train loss:0.886094502979402\n",
      "train loss:0.8072939493357706\n",
      "train loss:0.745128882861535\n",
      "train loss:0.8726788217870451\n",
      "train loss:0.9284348658643453\n",
      "train loss:0.9864266187466599\n",
      "train loss:0.8852140543304496\n",
      "train loss:0.8722153622271047\n",
      "train loss:0.9432325641546473\n",
      "train loss:0.9509019133642996\n",
      "train loss:0.8969406840460872\n",
      "train loss:0.8730202021345344\n",
      "train loss:0.8861983205382983\n",
      "train loss:0.8977356260302335\n",
      "train loss:0.9949650281265577\n",
      "train loss:0.8297657700690422\n",
      "train loss:0.7714958994193885\n",
      "train loss:0.8055228326552222\n",
      "train loss:0.9377958826167523\n",
      "train loss:0.8709347701996499\n",
      "train loss:0.9094002748452131\n",
      "train loss:0.7480239833651737\n",
      "train loss:0.9349046439795187\n",
      "train loss:0.7723611855023573\n",
      "train loss:1.0137220206701492\n",
      "train loss:0.9417613512209466\n",
      "train loss:0.9422080369483362\n",
      "train loss:1.006594626098032\n",
      "train loss:0.8320062717442513\n",
      "train loss:0.9142190398536927\n",
      "train loss:0.6942462201315661\n",
      "train loss:0.8085100002580247\n",
      "train loss:0.7855632347294436\n",
      "train loss:0.8421020477187835\n",
      "train loss:0.7603986113048405\n",
      "train loss:0.8465804728392711\n",
      "train loss:0.8816876682111645\n",
      "train loss:0.8017295134514026\n",
      "train loss:0.9346867912160279\n",
      "train loss:0.882995505108169\n",
      "train loss:0.8324997937814858\n",
      "train loss:0.8420189130812312\n",
      "train loss:0.8419367297229416\n",
      "train loss:0.7232832331837993\n",
      "train loss:1.0516018388498325\n",
      "train loss:0.7408925928491673\n",
      "train loss:0.7344715180766629\n",
      "train loss:0.7892347739673765\n",
      "train loss:0.8892214081761974\n",
      "train loss:0.795548436894311\n",
      "train loss:0.9243881226136521\n",
      "train loss:0.672062238120596\n",
      "train loss:0.897964288979464\n",
      "train loss:0.8986100132273569\n",
      "train loss:0.6173862258544728\n",
      "train loss:0.8117864669127789\n",
      "train loss:0.9182958699776022\n",
      "train loss:0.9473367614453335\n",
      "train loss:0.8395190084340136\n",
      "train loss:0.8707869657770922\n",
      "train loss:0.8421098336621706\n",
      "train loss:0.8888225541084154\n",
      "train loss:0.8843969438613065\n",
      "train loss:0.8691311477843535\n",
      "train loss:0.935398320599261\n",
      "train loss:0.9096320599799057\n",
      "train loss:0.8838076076757821\n",
      "train loss:0.7260794923208426\n",
      "train loss:0.7237507196723688\n",
      "train loss:0.9163325052016127\n",
      "train loss:0.8372274382952487\n",
      "train loss:0.6663390936643363\n",
      "train loss:0.8650465626547106\n",
      "train loss:0.8909047029411389\n",
      "train loss:0.7816468968930762\n",
      "train loss:0.834417289387466\n",
      "train loss:0.8772423528595092\n",
      "train loss:0.9032066555779504\n",
      "train loss:0.8917663635803076\n",
      "train loss:0.8182802550781892\n",
      "train loss:0.923416459182993\n",
      "train loss:0.9839353271825615\n",
      "train loss:0.9006367117309797\n",
      "train loss:0.8918637800250453\n",
      "train loss:0.866534456185549\n",
      "train loss:0.8904881442298536\n",
      "train loss:0.708217120907227\n",
      "train loss:0.8445261821894544\n",
      "train loss:0.8252482182377452\n",
      "train loss:0.7949096703394319\n",
      "train loss:0.8264440294784714\n",
      "train loss:0.9306115179964025\n",
      "train loss:0.9295902027771331\n",
      "train loss:0.9657529398274144\n",
      "train loss:0.7682235162309372\n",
      "train loss:0.8356369423045941\n",
      "train loss:0.940523957431744\n",
      "train loss:0.9397373876715887\n",
      "train loss:0.7354294091194176\n",
      "train loss:0.847712837381396\n",
      "train loss:0.9249306681107092\n",
      "train loss:0.8286669438759734\n",
      "train loss:0.9170593008130357\n",
      "train loss:0.9578684436153769\n",
      "train loss:0.673266536300196\n",
      "train loss:1.0080087383356067\n",
      "train loss:0.9085918551836798\n",
      "train loss:0.9592009756007311\n",
      "train loss:0.9684747986155621\n",
      "train loss:0.8913446719979098\n",
      "train loss:0.8319966004283379\n",
      "train loss:0.982641443311527\n",
      "train loss:0.9774653077145256\n",
      "train loss:0.6962574462653873\n",
      "train loss:0.8342300095147442\n",
      "train loss:1.0226033179397438\n",
      "train loss:0.9130567516441769\n",
      "train loss:0.8176105320340206\n",
      "train loss:0.8363610930410321\n",
      "train loss:0.751237990512936\n",
      "train loss:0.9056633885021828\n",
      "train loss:0.8344704218323171\n",
      "train loss:0.8637328963904354\n",
      "train loss:0.8421929172511501\n",
      "train loss:0.8571209286851665\n",
      "train loss:0.7014439562984011\n",
      "train loss:0.6945220492487334\n",
      "train loss:1.0305772221499194\n",
      "train loss:0.9555426988103812\n",
      "train loss:0.8376257310304527\n",
      "train loss:0.9068811267821691\n",
      "train loss:0.8853360047509886\n",
      "train loss:0.8570259968827854\n",
      "train loss:0.9837560503007049\n",
      "train loss:1.0450244309077303\n",
      "train loss:0.9935273111525683\n",
      "train loss:0.8043247863636396\n",
      "train loss:0.8481666351725782\n",
      "train loss:0.8136641487247825\n",
      "train loss:1.106844065238372\n",
      "train loss:0.9744527303353356\n",
      "train loss:0.8931454569872018\n",
      "train loss:0.8764386545551461\n",
      "train loss:0.7241846141890708\n",
      "train loss:0.9176674472868644\n",
      "train loss:0.8942163977124318\n",
      "train loss:0.8780727796512819\n",
      "train loss:0.816612473544688\n",
      "train loss:0.9317265010893766\n",
      "train loss:1.028781641683178\n",
      "train loss:0.7910032732110569\n",
      "train loss:0.9344102809183265\n",
      "train loss:0.8852175253446682\n",
      "train loss:0.8475021319263069\n",
      "train loss:0.9030237753366067\n",
      "train loss:0.8005480642896271\n",
      "train loss:0.864301723915893\n",
      "train loss:0.9024986276934867\n",
      "train loss:0.7690916647353138\n",
      "train loss:0.9052255161130851\n",
      "train loss:0.8092101772541378\n",
      "train loss:0.9259029336307542\n",
      "train loss:0.8111104814313974\n",
      "train loss:0.9357728632476774\n",
      "train loss:0.9873718480544327\n",
      "train loss:0.8012014741783264\n",
      "train loss:0.9287702350829483\n",
      "train loss:0.9490036368402943\n",
      "train loss:0.791899026645195\n",
      "train loss:0.9360548178032555\n",
      "train loss:0.891127764324279\n",
      "train loss:0.9740359777299937\n",
      "train loss:0.8297210318289683\n",
      "train loss:0.8226246868762549\n",
      "train loss:0.9087409888432835\n",
      "train loss:0.7248094808327538\n",
      "train loss:0.9536825937971538\n",
      "train loss:0.9299175421998689\n",
      "train loss:0.7601928013324577\n",
      "train loss:0.8518615456654611\n",
      "train loss:0.9206792477593302\n",
      "train loss:0.9346757168094381\n",
      "train loss:0.9224460802451142\n",
      "train loss:0.9814609658612973\n",
      "train loss:0.9090354843997099\n",
      "train loss:0.9444704922214097\n",
      "train loss:0.8167612567928896\n",
      "train loss:0.710666919259638\n",
      "train loss:0.8608934266568391\n",
      "train loss:0.9995881591478636\n",
      "train loss:0.7950194796561523\n",
      "train loss:0.9194603369116959\n",
      "train loss:0.8039793399338268\n",
      "train loss:1.0777423983651717\n",
      "train loss:0.9041602580086667\n",
      "train loss:0.7366905364969822\n",
      "train loss:1.1118103149135716\n",
      "train loss:0.9166861073530785\n",
      "train loss:0.8944787110263865\n",
      "train loss:0.8878658269976145\n",
      "train loss:0.8327660650943222\n",
      "train loss:1.0157682307349283\n",
      "train loss:0.7675818395018051\n",
      "train loss:0.9174862569386297\n",
      "train loss:0.904810990704172\n",
      "train loss:1.011245172640875\n",
      "train loss:0.9049888862137044\n",
      "train loss:0.9148006018101097\n",
      "train loss:0.9311738659804333\n",
      "train loss:0.9284685544774902\n",
      "train loss:0.8539344848826153\n",
      "train loss:0.8399167245586999\n",
      "train loss:0.9721358735274602\n",
      "train loss:1.0216637424422403\n",
      "train loss:1.005586852771148\n",
      "train loss:1.0371187038613445\n",
      "train loss:0.9289944853320184\n",
      "train loss:0.8744587903103769\n",
      "train loss:0.748698563452722\n",
      "train loss:0.9760152201984512\n",
      "train loss:0.9462721621305553\n",
      "train loss:0.7702228365042401\n",
      "train loss:0.9616147252537971\n",
      "train loss:0.8504043940705156\n",
      "train loss:0.8639274529782535\n",
      "train loss:0.8771051474487359\n",
      "train loss:0.738847773209678\n",
      "train loss:0.8554133701755583\n",
      "train loss:0.9774368606248255\n",
      "train loss:0.8904918418385208\n",
      "train loss:0.9120458319225173\n",
      "train loss:0.8703549314369233\n",
      "train loss:0.8155955594587386\n",
      "train loss:0.8541258199843013\n",
      "train loss:1.0049156051422083\n",
      "train loss:0.8212925256760303\n",
      "train loss:0.776273312910272\n",
      "train loss:0.9654919180768826\n",
      "train loss:0.8753687799512754\n",
      "train loss:0.9099361807604985\n",
      "train loss:0.8967448959885238\n",
      "train loss:0.9709718502790469\n",
      "train loss:0.7708944872651908\n",
      "train loss:0.8457940667247716\n",
      "train loss:0.945174242159476\n",
      "train loss:0.8465456947013631\n",
      "train loss:0.8798212909072255\n",
      "train loss:0.8717021684555928\n",
      "train loss:0.8916897262720276\n",
      "train loss:0.9181386300564127\n",
      "train loss:0.8373817972462996\n",
      "train loss:0.9031614413357606\n",
      "train loss:0.8396050091985786\n",
      "train loss:0.856915151355747\n",
      "train loss:0.7522784764104419\n",
      "train loss:0.7993892005559702\n",
      "train loss:0.8224921818990559\n",
      "train loss:0.8117384547785322\n",
      "train loss:0.8470511687309026\n",
      "train loss:0.9148356509883357\n",
      "train loss:0.956992499972896\n",
      "train loss:0.8828371608053608\n",
      "train loss:0.8913953472746541\n",
      "train loss:0.8495849013025917\n",
      "train loss:1.1845843043117896\n",
      "train loss:0.8616636384163263\n",
      "train loss:0.8587677982668626\n",
      "train loss:0.8129823433628265\n",
      "train loss:0.8702936548348761\n",
      "train loss:0.8896102059825475\n",
      "train loss:0.9149737065329357\n",
      "train loss:0.7712513359786438\n",
      "train loss:0.857678782303009\n",
      "train loss:0.8544816428172984\n",
      "train loss:0.7752920343823659\n",
      "train loss:0.6861363867712464\n",
      "train loss:0.8325808876655885\n",
      "train loss:0.9477572809748195\n",
      "train loss:0.8316549821708007\n",
      "train loss:0.6699654460659076\n",
      "train loss:0.99189237898181\n",
      "train loss:1.0596396458430144\n",
      "train loss:0.766025292950658\n",
      "train loss:0.8665383887375938\n",
      "train loss:0.880177891663593\n",
      "train loss:0.913731654888265\n",
      "train loss:0.9264361761241315\n",
      "train loss:0.7655778851623056\n",
      "train loss:1.0017577281339134\n",
      "train loss:0.9702910096692886\n",
      "train loss:0.9126552215923894\n",
      "train loss:1.0326243400767752\n",
      "train loss:0.9431351610207007\n",
      "train loss:0.7598606393223294\n",
      "train loss:0.7645427333524516\n",
      "train loss:0.9915779170805691\n",
      "train loss:0.9574714006833871\n",
      "train loss:0.8273645477581646\n",
      "train loss:0.7777099689799343\n",
      "train loss:0.8936604761726019\n",
      "train loss:0.8422373874963618\n",
      "train loss:0.9148519069283223\n",
      "train loss:0.8208847030345038\n",
      "train loss:0.898769229380071\n",
      "train loss:1.0209678475903556\n",
      "train loss:0.8583996635103988\n",
      "train loss:0.914126344116615\n",
      "train loss:0.8967449801044048\n",
      "train loss:0.8642754620599219\n",
      "train loss:1.0814575283082852\n",
      "train loss:0.8257550512505283\n",
      "train loss:0.901978178419282\n",
      "train loss:0.8772426133449253\n",
      "train loss:1.0098655680708437\n",
      "train loss:0.8343131983524718\n",
      "train loss:0.5624703326667616\n",
      "train loss:0.7283405399520285\n",
      "train loss:0.7972946072358654\n",
      "train loss:0.9654929720909968\n",
      "train loss:0.7734483158980775\n",
      "train loss:0.789185055672633\n",
      "train loss:0.8399688447092744\n",
      "train loss:0.9184345735423658\n",
      "train loss:0.9316875410491251\n",
      "train loss:0.8821557040462554\n",
      "train loss:0.7094408979758703\n",
      "train loss:0.8681996372319868\n",
      "train loss:0.9174367312404915\n",
      "train loss:0.8753478921274255\n",
      "train loss:0.9339100132515763\n",
      "train loss:1.0073834919047346\n",
      "train loss:0.8148616998401147\n",
      "train loss:0.9315398043911496\n",
      "train loss:0.9125949644044873\n",
      "train loss:0.8556097447911051\n",
      "train loss:0.8602933915437307\n",
      "train loss:0.8449500633685862\n",
      "train loss:0.6922548364736499\n",
      "train loss:0.9658721127214416\n",
      "train loss:0.9784230212810169\n",
      "train loss:1.0365813745276673\n",
      "train loss:0.8971657236420449\n",
      "train loss:0.8127846111856682\n",
      "train loss:0.8741548110184263\n",
      "train loss:1.015806309005872\n",
      "train loss:0.7983546138327513\n",
      "train loss:1.0023801447973364\n",
      "train loss:0.8765155402961524\n",
      "train loss:0.8409786360004519\n",
      "train loss:0.8601637413900279\n",
      "train loss:0.9696476511361557\n",
      "train loss:0.8635282145970777\n",
      "train loss:0.8805790024892576\n",
      "train loss:0.7153914230372987\n",
      "train loss:0.8247935058562811\n",
      "train loss:0.9586354023441653\n",
      "train loss:0.8974984545920839\n",
      "train loss:0.8190011887540861\n",
      "train loss:0.8532703692779959\n",
      "train loss:0.8764001875852074\n",
      "train loss:0.7993594590679871\n",
      "train loss:0.9184800340736884\n",
      "train loss:0.9359322225696094\n",
      "train loss:0.9508314007886511\n",
      "train loss:0.9263841139993005\n",
      "train loss:0.9215990657481805\n",
      "train loss:0.803221942303061\n",
      "train loss:0.8146806993307343\n",
      "train loss:0.9123483443292919\n",
      "train loss:0.7959950286070684\n",
      "train loss:0.8633093129462374\n",
      "train loss:0.8995231721326732\n",
      "train loss:0.9305255835860975\n",
      "train loss:0.891934490606428\n",
      "train loss:0.9082416296488024\n",
      "train loss:0.9381511138015299\n",
      "train loss:0.9203069390755609\n",
      "train loss:0.9240723217561189\n",
      "train loss:0.8605264274961355\n",
      "train loss:0.8753319808180001\n",
      "train loss:0.9135445286620038\n",
      "train loss:0.8058829755787079\n",
      "train loss:0.8948921410389898\n",
      "train loss:0.90575833724207\n",
      "train loss:0.7814024790016816\n",
      "train loss:0.782905491266016\n",
      "train loss:0.8779319997073713\n",
      "train loss:0.8774099208296441\n",
      "train loss:0.9080528018845083\n",
      "train loss:0.7746533458706196\n",
      "train loss:0.880339580205922\n",
      "train loss:0.941336000287763\n",
      "train loss:0.8611204794091768\n",
      "train loss:1.08247610667983\n",
      "train loss:0.9567766754694612\n",
      "train loss:0.792106619600745\n",
      "train loss:0.9375498979117651\n",
      "train loss:0.9067585578376302\n",
      "train loss:0.8018394304320681\n",
      "train loss:0.9617337715951965\n",
      "train loss:0.8574184718359972\n",
      "train loss:0.903366805011142\n",
      "train loss:0.8689759108212691\n",
      "train loss:0.8994359271203052\n",
      "train loss:0.7725585239291022\n",
      "train loss:1.0280177115727656\n",
      "train loss:0.8864278398168851\n",
      "train loss:0.8267712244987376\n",
      "train loss:0.9459171730834328\n",
      "train loss:0.8548407111520666\n",
      "train loss:0.8420264866655396\n",
      "=== epoch:18, train acc:0.999, test acc:0.991 ===\n",
      "train loss:0.7878240513311441\n",
      "train loss:0.9044544230127876\n",
      "train loss:0.8770438548057976\n",
      "train loss:0.9493306177035186\n",
      "train loss:0.7915123459967088\n",
      "train loss:0.8467480425483219\n",
      "train loss:0.7923322286186102\n",
      "train loss:0.965225485753892\n",
      "train loss:0.825134057963921\n",
      "train loss:0.7777138661823448\n",
      "train loss:1.0604071196483105\n",
      "train loss:0.9967610270781131\n",
      "train loss:0.8119921669138028\n",
      "train loss:0.9447727004981493\n",
      "train loss:0.7298336876967624\n",
      "train loss:0.8535171822976447\n",
      "train loss:0.8977627344293624\n",
      "train loss:0.8068358869189463\n",
      "train loss:1.0127934173432\n",
      "train loss:0.8445593924615529\n",
      "train loss:0.9033035957504617\n",
      "train loss:0.892102012970014\n",
      "train loss:0.8835481176567971\n",
      "train loss:0.8337111200029758\n",
      "train loss:0.7686147576954525\n",
      "train loss:1.0570994022902824\n",
      "train loss:0.7685192812476764\n",
      "train loss:0.8784060268639419\n",
      "train loss:1.0283659898782014\n",
      "train loss:0.8466555111544564\n",
      "train loss:0.7997933343574342\n",
      "train loss:0.9047462334415015\n",
      "train loss:0.675267201989428\n",
      "train loss:0.6700914558098954\n",
      "train loss:0.752484609925479\n",
      "train loss:0.753398269750751\n",
      "train loss:0.8232168277564805\n",
      "train loss:0.9018675298220508\n",
      "train loss:0.8462108809165518\n",
      "train loss:0.7780068667788407\n",
      "train loss:0.8462793812106483\n",
      "train loss:0.8459962389801993\n",
      "train loss:0.8401006146662536\n",
      "train loss:0.8999437738423208\n",
      "train loss:0.8882952347693034\n",
      "train loss:0.7306729567079779\n",
      "train loss:0.85536797713812\n",
      "train loss:0.9474515275552531\n",
      "train loss:0.8946939173430947\n",
      "train loss:0.899300116399714\n",
      "train loss:0.9305121946008913\n",
      "train loss:0.8662719660371487\n",
      "train loss:0.9878051510613749\n",
      "train loss:0.7202237505543974\n",
      "train loss:0.8329538804637403\n",
      "train loss:0.7645006153286503\n",
      "train loss:0.8169104652160896\n",
      "train loss:0.830160717641833\n",
      "train loss:0.9841001267077809\n",
      "train loss:0.9788907099905418\n",
      "train loss:0.8887038908406053\n",
      "train loss:0.8620214122372238\n",
      "train loss:0.9000092460283708\n",
      "train loss:0.9551662472276361\n",
      "train loss:0.8788002159557203\n",
      "train loss:0.8570361822832945\n",
      "train loss:0.9199063313624396\n",
      "train loss:0.8502051508906935\n",
      "train loss:0.8362845483178439\n",
      "train loss:0.7905743444779499\n",
      "train loss:0.9039303103138191\n",
      "train loss:0.9587760559445345\n",
      "train loss:0.8379709090220131\n",
      "train loss:0.868683179622142\n",
      "train loss:0.7562587109801242\n",
      "train loss:0.9435113565892449\n",
      "train loss:0.7923134762993881\n",
      "train loss:0.92928327397093\n",
      "train loss:0.8341919181048726\n",
      "train loss:0.748290368212293\n",
      "train loss:0.8533340857615391\n",
      "train loss:0.8604273958011833\n",
      "train loss:0.8601426584546753\n",
      "train loss:0.8538007698760974\n",
      "train loss:0.7890878357273485\n",
      "train loss:0.9095990718112131\n",
      "train loss:0.8575502088956196\n",
      "train loss:0.8412110352014375\n",
      "train loss:0.9396784571558985\n",
      "train loss:0.8846653652698663\n",
      "train loss:0.8103745760939718\n",
      "train loss:0.8622446680833248\n",
      "train loss:0.9155022662651868\n",
      "train loss:0.7408204999789398\n",
      "train loss:0.9916732502499968\n",
      "train loss:0.7086166725803481\n",
      "train loss:0.8167745901803564\n",
      "train loss:0.8821870592358491\n",
      "train loss:0.8293441864276181\n",
      "train loss:0.7808746869875053\n",
      "train loss:0.9224007077017977\n",
      "train loss:0.8649003366074698\n",
      "train loss:0.8358878258178032\n",
      "train loss:0.8463095551312732\n",
      "train loss:0.8880858079167347\n",
      "train loss:0.8455252739808431\n",
      "train loss:0.8430686047077001\n",
      "train loss:0.8313375567077113\n",
      "train loss:0.8393402668974608\n",
      "train loss:0.7815487458031359\n",
      "train loss:0.8367489321372656\n",
      "train loss:1.0761530822337888\n",
      "train loss:0.7489490731326324\n",
      "train loss:0.8725854214846391\n",
      "train loss:0.8182291613244018\n",
      "train loss:0.8928385919205317\n",
      "train loss:0.7742332253575693\n",
      "train loss:0.8168642177157142\n",
      "train loss:0.9044828429912748\n",
      "train loss:0.90559615228694\n",
      "train loss:1.1186620938440268\n",
      "train loss:0.7690922746320744\n",
      "train loss:0.8876151138794117\n",
      "train loss:0.9276601506706793\n",
      "train loss:1.0059501514476248\n",
      "train loss:0.8153245838186879\n",
      "train loss:0.7578703096552397\n",
      "train loss:0.8567021038442648\n",
      "train loss:1.0100728788814026\n",
      "train loss:0.7960445297009623\n",
      "train loss:0.6646717531053173\n",
      "train loss:0.9911445349900292\n",
      "train loss:0.7750018496434339\n",
      "train loss:0.7592724176160592\n",
      "train loss:0.8363017093980095\n",
      "train loss:0.8761562483313174\n",
      "train loss:0.9748877491013702\n",
      "train loss:0.7895445700043175\n",
      "train loss:0.8917977658761265\n",
      "train loss:0.9592665009703039\n",
      "train loss:0.7591968677273933\n",
      "train loss:0.6947497561066938\n",
      "train loss:0.8071784751736583\n",
      "train loss:0.9279308751343994\n",
      "train loss:1.0776129656782993\n",
      "train loss:0.6903721006121054\n",
      "train loss:0.7496479456923049\n",
      "train loss:0.9795597295352573\n",
      "train loss:0.8862330774215528\n",
      "train loss:0.8633610141963135\n",
      "train loss:0.7235532091944674\n",
      "train loss:0.988208501797235\n",
      "train loss:0.8423678900093985\n",
      "train loss:0.8481301551478676\n",
      "train loss:0.8724887689389956\n",
      "train loss:1.0034544736895412\n",
      "train loss:1.0208739829055604\n",
      "train loss:0.8460647405979536\n",
      "train loss:0.9210823637930339\n",
      "train loss:0.8530639077910592\n",
      "train loss:0.8412351762751453\n",
      "train loss:0.8311125156089796\n",
      "train loss:0.7542161740385148\n",
      "train loss:0.8532945979678631\n",
      "train loss:0.9546898064549455\n",
      "train loss:0.751791012668755\n",
      "train loss:0.8424648603905358\n",
      "train loss:0.8508915494490991\n",
      "train loss:0.9159394221928173\n",
      "train loss:0.8415207987126964\n",
      "train loss:1.016804074123017\n",
      "train loss:0.9066557614919988\n",
      "train loss:0.9356111241680672\n",
      "train loss:0.8696156620929665\n",
      "train loss:0.9224391885931343\n",
      "train loss:0.9526776685110525\n",
      "train loss:0.8626468709992062\n",
      "train loss:0.9180637569165394\n",
      "train loss:0.7562152222217737\n",
      "train loss:0.8428723610869975\n",
      "train loss:0.865126034496518\n",
      "train loss:0.8692995307855054\n",
      "train loss:0.8979210788244119\n",
      "train loss:0.7365267278164102\n",
      "train loss:0.9323193699979552\n",
      "train loss:0.8850405471176984\n",
      "train loss:1.077688543114768\n",
      "train loss:0.8524006362794411\n",
      "train loss:0.8583044692666781\n",
      "train loss:0.8919302130718141\n",
      "train loss:0.8603089874561445\n",
      "train loss:0.6136875175878793\n",
      "train loss:0.950791401894218\n",
      "train loss:0.9498448177411077\n",
      "train loss:0.8269809370296239\n",
      "train loss:0.7172237501423525\n",
      "train loss:1.065197817833513\n",
      "train loss:0.867265264222921\n",
      "train loss:0.9312180310225205\n",
      "train loss:0.8538066485400919\n",
      "train loss:0.8082910143133568\n",
      "train loss:0.7085386121483666\n",
      "train loss:0.8193540328993834\n",
      "train loss:0.8244000116097548\n",
      "train loss:0.9203350815763761\n",
      "train loss:0.9860418908602469\n",
      "train loss:0.827542263232491\n",
      "train loss:0.8554902144419806\n",
      "train loss:0.7731779271895236\n",
      "train loss:0.700324538620106\n",
      "train loss:0.9494686442175906\n",
      "train loss:0.8751242003239347\n",
      "train loss:0.8878565404055325\n",
      "train loss:0.8690642653916975\n",
      "train loss:0.8020540709591504\n",
      "train loss:0.8837109349790475\n",
      "train loss:0.788862395235111\n",
      "train loss:0.9599421344164858\n",
      "train loss:0.935639013022517\n",
      "train loss:0.9000468182352964\n",
      "train loss:0.805165718583689\n",
      "train loss:0.7713717582520812\n",
      "train loss:0.940948759102794\n",
      "train loss:0.9926086742017459\n",
      "train loss:0.7535853849793646\n",
      "train loss:0.7205842884029758\n",
      "train loss:0.7950532488782632\n",
      "train loss:0.8968322720681844\n",
      "train loss:0.7600746730083898\n",
      "train loss:0.8355875936353268\n",
      "train loss:0.9125877084640246\n",
      "train loss:0.7805159259543984\n",
      "train loss:1.120489232372285\n",
      "train loss:0.8898134515301459\n",
      "train loss:0.9237084011250605\n",
      "train loss:0.9808080342114252\n",
      "train loss:0.9366213689501812\n",
      "train loss:0.8845921183933632\n",
      "train loss:0.8245757467628306\n",
      "train loss:0.7813433991418919\n",
      "train loss:0.9524491480153255\n",
      "train loss:0.8537267205871427\n",
      "train loss:0.8422677698916161\n",
      "train loss:0.8929777553455922\n",
      "train loss:0.8949453456091438\n",
      "train loss:0.6815150687515049\n",
      "train loss:0.8064722960908898\n",
      "train loss:1.0004140660367293\n",
      "train loss:0.7134975513009582\n",
      "train loss:0.8988179896798156\n",
      "train loss:0.8732447736667754\n",
      "train loss:0.7878935095158854\n",
      "train loss:1.0687451338486789\n",
      "train loss:0.8661461847579656\n",
      "train loss:1.0067360698500278\n",
      "train loss:0.8758138350280084\n",
      "train loss:0.9279890819305582\n",
      "train loss:0.7423691912469239\n",
      "train loss:0.8202035690908096\n",
      "train loss:0.9534363309199594\n",
      "train loss:0.8066881103660802\n",
      "train loss:0.7814724685008576\n",
      "train loss:0.9185730889802664\n",
      "train loss:0.9123305190562533\n",
      "train loss:0.9375791197021763\n",
      "train loss:0.8451012103290487\n",
      "train loss:0.8307333806434976\n",
      "train loss:0.8435974195113825\n",
      "train loss:0.8957865992558639\n",
      "train loss:0.8447071927100507\n",
      "train loss:0.9343939283819236\n",
      "train loss:0.8737365389725799\n",
      "train loss:0.8095059992400393\n",
      "train loss:1.0469742850966748\n",
      "train loss:0.9350581604631375\n",
      "train loss:0.8291941593849138\n",
      "train loss:0.7833676444687231\n",
      "train loss:0.8997340485853391\n",
      "train loss:1.043535185388778\n",
      "train loss:0.9033467825510294\n",
      "train loss:0.731728295578219\n",
      "train loss:0.8376230635216276\n",
      "train loss:0.9987673453178154\n",
      "train loss:0.8927771202842542\n",
      "train loss:0.9202582305490388\n",
      "train loss:0.838659379319199\n",
      "train loss:0.9838132416047429\n",
      "train loss:1.008549459650602\n",
      "train loss:0.9408617065834878\n",
      "train loss:0.7583187334236599\n",
      "train loss:1.0483676178486905\n",
      "train loss:0.9066555963563929\n",
      "train loss:0.8518173994657191\n",
      "train loss:1.1077461469119065\n",
      "train loss:0.7248697760797466\n",
      "train loss:0.9199652164512725\n",
      "train loss:0.7510416894638946\n",
      "train loss:0.9319864506463043\n",
      "train loss:0.8800626878389837\n",
      "train loss:0.8643656690873356\n",
      "train loss:0.7586941031429403\n",
      "train loss:0.855378657894575\n",
      "train loss:0.7207888445110713\n",
      "train loss:0.8543394341673677\n",
      "train loss:0.8179529025549518\n",
      "train loss:0.8761437629244504\n",
      "train loss:0.8317594965278107\n",
      "train loss:0.8915404623194054\n",
      "train loss:0.8222279745016559\n",
      "train loss:0.8642997217161832\n",
      "train loss:0.8228532589825744\n",
      "train loss:0.7873701905428451\n",
      "train loss:0.9842023489617343\n",
      "train loss:0.8215546154820683\n",
      "train loss:0.963932302295027\n",
      "train loss:0.8570444340540202\n",
      "train loss:0.8982373831027374\n",
      "train loss:0.8860784897417548\n",
      "train loss:0.702006587082794\n",
      "train loss:0.8172209916747762\n",
      "train loss:0.7935688978413796\n",
      "train loss:0.9136995946633271\n",
      "train loss:0.8917488153947568\n",
      "train loss:0.73388817453766\n",
      "train loss:0.7664735429422929\n",
      "train loss:0.7097109425552024\n",
      "train loss:0.793626394400715\n",
      "train loss:0.8831513450852977\n",
      "train loss:0.951096750322597\n",
      "train loss:0.7648073074895178\n",
      "train loss:0.9011906383197477\n",
      "train loss:0.900185224109198\n",
      "train loss:1.0552698767985857\n",
      "train loss:0.8431154562214264\n",
      "train loss:0.9588028582435822\n",
      "train loss:0.8640284629062512\n",
      "train loss:0.8938586442812578\n",
      "train loss:0.9995995149383756\n",
      "train loss:0.7824810222348317\n",
      "train loss:0.8250271853170205\n",
      "train loss:0.8612375513231114\n",
      "train loss:0.9186232337853859\n",
      "train loss:0.8969831064553425\n",
      "train loss:1.053340319923893\n",
      "train loss:0.9624001994474013\n",
      "train loss:0.7964984931134106\n",
      "train loss:0.8145021340080555\n",
      "train loss:0.9025388326152028\n",
      "train loss:0.8609623211228076\n",
      "train loss:0.8692572656483692\n",
      "train loss:0.901459326375414\n",
      "train loss:0.7672556298110184\n",
      "train loss:0.9678213539454024\n",
      "train loss:0.7728490776340783\n",
      "train loss:1.0008148915101198\n",
      "train loss:0.794780763024063\n",
      "train loss:0.9042006383787127\n",
      "train loss:0.9772652664544681\n",
      "train loss:0.9299199821771156\n",
      "train loss:0.6378618895549674\n",
      "train loss:0.8462754335683473\n",
      "train loss:0.7371821309583844\n",
      "train loss:1.0156125742925193\n",
      "train loss:0.8344715512021188\n",
      "train loss:0.9352244793209639\n",
      "train loss:0.9313965703128071\n",
      "train loss:0.7811213666645683\n",
      "train loss:0.9614529800777681\n",
      "train loss:0.9099292379602231\n",
      "train loss:0.8954065390829051\n",
      "train loss:0.8627698948870267\n",
      "train loss:0.8872484677267161\n",
      "train loss:0.7136197208101113\n",
      "train loss:0.9313832890907149\n",
      "train loss:0.86720781655915\n",
      "train loss:0.923988467028015\n",
      "train loss:1.009932204164017\n",
      "train loss:0.7443006810377975\n",
      "train loss:0.902512823172603\n",
      "train loss:1.0029041994013423\n",
      "train loss:0.8432475357788884\n",
      "train loss:0.8340735573320055\n",
      "train loss:0.8661363580915667\n",
      "train loss:0.6559407391326194\n",
      "train loss:0.8356278908429721\n",
      "train loss:0.9254054042464042\n",
      "train loss:0.9509510980323168\n",
      "train loss:0.8292980834822545\n",
      "train loss:1.0039425381119846\n",
      "train loss:0.718511857296831\n",
      "train loss:0.7211695482951125\n",
      "train loss:0.9186310499107134\n",
      "train loss:0.9009460838723692\n",
      "train loss:0.9685090637392453\n",
      "train loss:0.7478885795725002\n",
      "train loss:0.9136587415036966\n",
      "train loss:0.7976670400648304\n",
      "train loss:0.8648985986354011\n",
      "train loss:0.773959967640501\n",
      "train loss:0.9500396491323885\n",
      "train loss:0.8554882991686686\n",
      "train loss:0.9080687846299582\n",
      "train loss:0.8799650801733285\n",
      "train loss:0.7503919442301342\n",
      "train loss:0.8238227868744075\n",
      "train loss:0.9637914830647172\n",
      "train loss:0.8669600204878258\n",
      "train loss:0.8179051021446466\n",
      "train loss:0.9036537792913957\n",
      "train loss:0.9700539303897913\n",
      "train loss:0.7695816278014834\n",
      "train loss:0.8196410352060507\n",
      "train loss:0.9492489415985912\n",
      "train loss:0.7492838640296547\n",
      "train loss:0.9599455617925641\n",
      "train loss:0.7712221307449333\n",
      "train loss:0.8048957621243967\n",
      "train loss:0.8927658245128854\n",
      "train loss:0.858111441135554\n",
      "train loss:0.8632810062075126\n",
      "train loss:0.8774901380270897\n",
      "train loss:0.8769240459270349\n",
      "train loss:0.9063841501677525\n",
      "train loss:0.9881100262143724\n",
      "train loss:0.9888700439209276\n",
      "train loss:0.9515614409838171\n",
      "train loss:0.898299207092488\n",
      "train loss:0.9356954725070019\n",
      "train loss:0.7220326730968125\n",
      "train loss:0.9848078895523394\n",
      "train loss:0.8768810158591832\n",
      "train loss:0.9611591684221072\n",
      "train loss:0.8971530418549886\n",
      "train loss:0.8876978661536787\n",
      "train loss:0.8600820578198747\n",
      "train loss:0.872557215603459\n",
      "train loss:0.8016284432269747\n",
      "train loss:0.7836650335289622\n",
      "train loss:1.0511547373491568\n",
      "train loss:0.9070822942035859\n",
      "train loss:0.9512363112396136\n",
      "train loss:0.9334998407421767\n",
      "train loss:0.925741160132625\n",
      "train loss:0.7485831005896729\n",
      "train loss:0.6985228778480344\n",
      "train loss:0.8865335141678615\n",
      "train loss:1.0003087318248118\n",
      "train loss:0.789310516367927\n",
      "train loss:0.7479568459273264\n",
      "train loss:0.8977860452847302\n",
      "train loss:0.9121768766699969\n",
      "train loss:0.8822186552783946\n",
      "train loss:0.8399230381687169\n",
      "train loss:0.7271032039435168\n",
      "train loss:0.8026164797195154\n",
      "train loss:0.6533572947663474\n",
      "train loss:0.880297172146675\n",
      "train loss:0.7646385848006518\n",
      "train loss:0.808761459805769\n",
      "train loss:0.8810330596270584\n",
      "train loss:0.7295146382218607\n",
      "train loss:0.90303384238745\n",
      "train loss:0.8581990051051974\n",
      "train loss:0.8445806564845652\n",
      "train loss:0.9364511933667705\n",
      "train loss:0.8621734713056957\n",
      "train loss:0.8843960106666507\n",
      "train loss:0.6820668001675881\n",
      "train loss:0.8475544226754518\n",
      "train loss:0.9126680838628094\n",
      "train loss:0.7756186276597848\n",
      "train loss:0.8754588971798701\n",
      "train loss:0.7437689649203844\n",
      "train loss:0.8804824872972017\n",
      "train loss:0.8900347913561248\n",
      "train loss:0.7803916568813908\n",
      "train loss:0.6620314481155615\n",
      "train loss:0.8440096568806065\n",
      "train loss:0.8761176376150184\n",
      "train loss:0.8388186567987306\n",
      "train loss:0.9345589262125106\n",
      "train loss:0.9633446128486995\n",
      "train loss:0.9182889092736963\n",
      "train loss:0.8800667229097827\n",
      "train loss:0.8274939083164311\n",
      "train loss:0.8831579599426074\n",
      "train loss:0.9554951194009685\n",
      "train loss:1.0932231596763626\n",
      "train loss:0.6327892299990108\n",
      "train loss:0.830558753440193\n",
      "train loss:0.9352358060701653\n",
      "train loss:0.8830981724458502\n",
      "train loss:0.8169354366701072\n",
      "train loss:0.8510101490766324\n",
      "train loss:0.780837351847063\n",
      "train loss:1.033794055415824\n",
      "train loss:0.8487791919584269\n",
      "train loss:0.9403504193385352\n",
      "train loss:0.908338651451726\n",
      "train loss:0.8491987052173724\n",
      "train loss:0.9239125705543885\n",
      "train loss:0.8560675581904911\n",
      "train loss:0.7862500394808045\n",
      "train loss:0.9685752669570263\n",
      "train loss:0.6685270496281771\n",
      "train loss:0.708754389184642\n",
      "train loss:0.748077391380096\n",
      "train loss:1.0401573705999956\n",
      "train loss:0.8304112923836765\n",
      "train loss:0.8560109992283222\n",
      "train loss:0.7802448434019253\n",
      "train loss:1.0193727596910858\n",
      "train loss:0.8319755899634309\n",
      "train loss:0.8108399932354621\n",
      "train loss:0.9587119446552863\n",
      "train loss:0.829401791962994\n",
      "train loss:0.8169035073130335\n",
      "train loss:0.8205386725824338\n",
      "train loss:0.7893568770457671\n",
      "train loss:0.8977022910027128\n",
      "train loss:0.8769310092997651\n",
      "train loss:0.8076153552683413\n",
      "train loss:0.9272096445838907\n",
      "train loss:0.8613083180495907\n",
      "train loss:1.0637054719358994\n",
      "train loss:0.9947131573437241\n",
      "train loss:0.8109275352421561\n",
      "train loss:0.7920033846958183\n",
      "train loss:0.9652434529604293\n",
      "train loss:0.876852929534346\n",
      "train loss:0.797661391581988\n",
      "train loss:0.8524376261740813\n",
      "train loss:0.9981918153236957\n",
      "train loss:0.752707264234071\n",
      "train loss:0.8269314677001236\n",
      "train loss:0.7507189548922352\n",
      "train loss:0.9362637480943699\n",
      "train loss:0.9449355331239737\n",
      "train loss:0.771736853850338\n",
      "train loss:0.8678280484539418\n",
      "train loss:0.7600300859472797\n",
      "train loss:1.0554092372703485\n",
      "train loss:0.9454406646806749\n",
      "train loss:0.9457879230097985\n",
      "train loss:1.006375846069364\n",
      "train loss:0.8667949057047699\n",
      "train loss:0.9598280206276527\n",
      "train loss:0.8752824295030015\n",
      "train loss:0.8223165931842084\n",
      "train loss:1.0547136612139014\n",
      "train loss:0.9360655198183951\n",
      "train loss:0.8661699310593405\n",
      "train loss:0.6836454702555049\n",
      "train loss:0.7711641147724057\n",
      "train loss:0.940987411884685\n",
      "train loss:0.9229703277957552\n",
      "train loss:0.8575530406944316\n",
      "train loss:0.9066801398521279\n",
      "train loss:0.9330333316175676\n",
      "train loss:0.73422837742711\n",
      "train loss:0.7513046149634629\n",
      "train loss:0.8896000570863752\n",
      "train loss:0.7805268211351941\n",
      "train loss:0.9689662464591592\n",
      "train loss:0.8900550597106093\n",
      "train loss:0.83841580885765\n",
      "train loss:0.8230404355182825\n",
      "train loss:0.9189104519931555\n",
      "train loss:0.7934047457210984\n",
      "train loss:1.0115274876820162\n",
      "train loss:0.748221577646507\n",
      "train loss:0.8195125186451152\n",
      "train loss:0.82421280142257\n",
      "train loss:1.0351025704464987\n",
      "train loss:0.8799724724820216\n",
      "train loss:0.7705287285303549\n",
      "train loss:0.9789572988609754\n",
      "train loss:0.7313950998181948\n",
      "train loss:0.9162037382611902\n",
      "train loss:0.7815458093917949\n",
      "train loss:0.8518111131022947\n",
      "train loss:1.0097173912755755\n",
      "train loss:0.8910372059012636\n",
      "train loss:0.7864197359207517\n",
      "train loss:0.9077347189825024\n",
      "train loss:0.7990223983719895\n",
      "train loss:0.8888483907911062\n",
      "train loss:0.747090400756208\n",
      "train loss:0.7184746348002409\n",
      "train loss:0.9458853708953007\n",
      "train loss:0.9071449769086624\n",
      "train loss:0.8624723208946108\n",
      "train loss:0.8912149717628276\n",
      "train loss:0.9318684427661355\n",
      "train loss:0.8640025262228894\n",
      "train loss:0.8696456760585558\n",
      "train loss:0.7726143220980312\n",
      "train loss:0.81582216014801\n",
      "train loss:0.890161305535671\n",
      "train loss:0.8809969103299784\n",
      "=== epoch:19, train acc:0.997, test acc:0.991 ===\n",
      "train loss:0.7871020649324794\n",
      "train loss:0.8585876687700771\n",
      "train loss:0.9286631037440776\n",
      "train loss:0.8623473757384622\n",
      "train loss:0.7077611277883894\n",
      "train loss:0.8823696863223099\n",
      "train loss:0.9180827259753523\n",
      "train loss:0.8940624192392707\n",
      "train loss:0.8452113895489367\n",
      "train loss:0.887459069773659\n",
      "train loss:0.9195946113940364\n",
      "train loss:0.8326156887025404\n",
      "train loss:0.8564503629220147\n",
      "train loss:0.8509350210915758\n",
      "train loss:0.8441202880107032\n",
      "train loss:0.8568379181477801\n",
      "train loss:0.8706909494855155\n",
      "train loss:0.8230631376603718\n",
      "train loss:0.9089927659260266\n",
      "train loss:1.0215417615544493\n",
      "train loss:0.987529277371167\n",
      "train loss:0.88634502793496\n",
      "train loss:0.7659555580066152\n",
      "train loss:0.9826669354697724\n",
      "train loss:0.8974869703474059\n",
      "train loss:0.9203093910598317\n",
      "train loss:0.965071924678684\n",
      "train loss:0.790058046955058\n",
      "train loss:0.9117594556914094\n",
      "train loss:0.8058471761140074\n",
      "train loss:0.9339390409176239\n",
      "train loss:0.9650061365493275\n",
      "train loss:0.7007909156847636\n",
      "train loss:0.8072449847239853\n",
      "train loss:0.7882436388302062\n",
      "train loss:0.7050308928557084\n",
      "train loss:0.9639503716313885\n",
      "train loss:0.8378564232375151\n",
      "train loss:0.7340144193093784\n",
      "train loss:0.9209386080095563\n",
      "train loss:0.973220476584478\n",
      "train loss:0.7772582003752407\n",
      "train loss:0.8805825887652596\n",
      "train loss:0.7905616175860655\n",
      "train loss:0.8049754373626183\n",
      "train loss:0.9722207025523324\n",
      "train loss:0.9693165250547622\n",
      "train loss:0.8884674033431\n",
      "train loss:0.8322862162789855\n",
      "train loss:0.9505058633132711\n",
      "train loss:0.9957490291927891\n",
      "train loss:0.8005650472853613\n",
      "train loss:0.6955397240367699\n",
      "train loss:0.8722152761661505\n",
      "train loss:0.8463336114271367\n",
      "train loss:0.8394545206539036\n",
      "train loss:0.8290724137212976\n",
      "train loss:1.0086466202580702\n",
      "train loss:0.8261797978087757\n",
      "train loss:0.6952924377998103\n",
      "train loss:0.7589401879741345\n",
      "train loss:0.946597569233474\n",
      "train loss:0.7925122337366522\n",
      "train loss:1.016019820763636\n",
      "train loss:0.8914310542166342\n",
      "train loss:0.8868861215440726\n",
      "train loss:1.0249483597186242\n",
      "train loss:0.8585585642406593\n",
      "train loss:0.6644663072687409\n",
      "train loss:0.8376093073895932\n",
      "train loss:0.8364560780140152\n",
      "train loss:0.9729699608328604\n",
      "train loss:0.7021381108247816\n",
      "train loss:0.7322778484121395\n",
      "train loss:0.85234158000846\n",
      "train loss:0.8815571083147653\n",
      "train loss:0.8878796270785917\n",
      "train loss:0.9312096271242808\n",
      "train loss:1.0082046069062707\n",
      "train loss:0.945544621058432\n",
      "train loss:0.76595910997637\n",
      "train loss:0.8791538346001856\n",
      "train loss:0.7662310991534723\n",
      "train loss:0.8593358654712364\n",
      "train loss:0.8156733667609779\n",
      "train loss:0.8318315022835696\n",
      "train loss:0.9451584013086213\n",
      "train loss:0.9525718684078818\n",
      "train loss:0.8489216149164482\n",
      "train loss:0.8006926706181962\n",
      "train loss:0.8479706432997085\n",
      "train loss:0.8518916053108828\n",
      "train loss:0.8616376383106065\n",
      "train loss:0.8955237287700751\n",
      "train loss:0.845371109448084\n",
      "train loss:0.8355958731315719\n",
      "train loss:0.9644972971363681\n",
      "train loss:1.0229785076382572\n",
      "train loss:0.9664783348765585\n",
      "train loss:0.8480412203030522\n",
      "train loss:0.9989012812933663\n",
      "train loss:0.8635803425284785\n",
      "train loss:1.0514719813279798\n",
      "train loss:0.9849143522180402\n",
      "train loss:0.8271237564441176\n",
      "train loss:0.7969259778964682\n",
      "train loss:1.1266609763431328\n",
      "train loss:0.8495843472336162\n",
      "train loss:0.8596291348530763\n",
      "train loss:0.9330865845149973\n",
      "train loss:0.8881414891052184\n",
      "train loss:0.7913721464364294\n",
      "train loss:0.8238380643709682\n",
      "train loss:0.8236819420923434\n",
      "train loss:0.8242815333954252\n",
      "train loss:0.7652825306870679\n",
      "train loss:0.884052940021434\n",
      "train loss:0.7170218697808886\n",
      "train loss:0.920792472129059\n",
      "train loss:0.7964786833391585\n",
      "train loss:0.9195524372274333\n",
      "train loss:0.7417304829009369\n",
      "train loss:0.7883311914734495\n",
      "train loss:0.8396060473011877\n",
      "train loss:0.9808905428556656\n",
      "train loss:0.7548927790872658\n",
      "train loss:0.9258619382179387\n",
      "train loss:0.8562804098698769\n",
      "train loss:0.7867883857133183\n",
      "train loss:0.752119932040384\n",
      "train loss:0.9134673483363749\n",
      "train loss:0.8535976084126188\n",
      "train loss:0.9139537377486353\n",
      "train loss:0.7868159751339854\n",
      "train loss:0.8378320232593895\n",
      "train loss:0.8999897481010715\n",
      "train loss:0.8498102504628335\n",
      "train loss:0.702364090734674\n",
      "train loss:0.8358515948897086\n",
      "train loss:0.9443208375922167\n",
      "train loss:0.7474574486704675\n",
      "train loss:0.8803873949668136\n",
      "train loss:0.7968023538925868\n",
      "train loss:0.9940974745024107\n",
      "train loss:0.8212299056300761\n",
      "train loss:0.9155855265793262\n",
      "train loss:0.8185474928707355\n",
      "train loss:0.9825382313616099\n",
      "train loss:0.7876314933339108\n",
      "train loss:0.9576081892946665\n",
      "train loss:0.7544222605166365\n",
      "train loss:0.6205958710675425\n",
      "train loss:0.8884653701676\n",
      "train loss:0.8867930848806038\n",
      "train loss:0.7420224786640145\n",
      "train loss:0.7972279159102402\n",
      "train loss:0.8552076643432883\n",
      "train loss:0.8053399525937363\n",
      "train loss:0.7151072826295145\n",
      "train loss:0.9193516343037443\n",
      "train loss:0.7255727879365496\n",
      "train loss:0.872956698823354\n",
      "train loss:0.9120437628729171\n",
      "train loss:1.0179431556269933\n",
      "train loss:0.9305317291984808\n",
      "train loss:0.9789540588416726\n",
      "train loss:0.8164306024010457\n",
      "train loss:0.8568864802854342\n",
      "train loss:0.8997135968041208\n",
      "train loss:0.86932811389875\n",
      "train loss:0.9038729636603969\n",
      "train loss:1.019904494218017\n",
      "train loss:1.0460792003167387\n",
      "train loss:0.97622720970968\n",
      "train loss:0.9950843645514673\n",
      "train loss:0.8382853133718555\n",
      "train loss:0.8086712743821417\n",
      "train loss:0.8420628209225278\n",
      "train loss:0.988560930821082\n",
      "train loss:0.9291795018228693\n",
      "train loss:0.9036396360294185\n",
      "train loss:0.9101307083280723\n",
      "train loss:0.6855675221058849\n",
      "train loss:0.9643384691022652\n",
      "train loss:1.0975455036052222\n",
      "train loss:0.9771356841720779\n",
      "train loss:0.721101378418555\n",
      "train loss:0.9214536944030318\n",
      "train loss:0.8561235000433931\n",
      "train loss:0.8812237996209146\n",
      "train loss:0.9126849830296648\n",
      "train loss:0.9087439135354286\n",
      "train loss:0.7232755927483474\n",
      "train loss:0.8944261726092627\n",
      "train loss:0.9617034090389464\n",
      "train loss:0.8304840043263779\n",
      "train loss:0.9335253352801911\n",
      "train loss:1.0597217840557691\n",
      "train loss:0.8755201201835702\n",
      "train loss:0.9955105003605905\n",
      "train loss:0.7923530588154883\n",
      "train loss:0.921321356090857\n",
      "train loss:1.000769812189339\n",
      "train loss:0.8260082417235692\n",
      "train loss:1.0522632409933628\n",
      "train loss:0.9404719793223788\n",
      "train loss:0.8164054537686541\n",
      "train loss:0.7972237922098122\n",
      "train loss:0.7669087492171601\n",
      "train loss:0.968421558157798\n",
      "train loss:0.7959911785664902\n",
      "train loss:0.9732925314680111\n",
      "train loss:0.9883723245710715\n",
      "train loss:0.8575215976874854\n",
      "train loss:0.9817057652216866\n",
      "train loss:0.8888257399281716\n",
      "train loss:0.8262555773366155\n",
      "train loss:0.8617385580071577\n",
      "train loss:0.7801220938755332\n",
      "train loss:0.8448789528759127\n",
      "train loss:0.7815056240459505\n",
      "train loss:0.8702985044692553\n",
      "train loss:1.0443190066828416\n",
      "train loss:0.8840697983023051\n",
      "train loss:0.8498672244785948\n",
      "train loss:0.6896052565443874\n",
      "train loss:0.800488855443292\n",
      "train loss:1.0094414037034831\n",
      "train loss:0.9780592820704521\n",
      "train loss:1.0075194963428604\n",
      "train loss:0.8029206024544212\n",
      "train loss:0.70865573827575\n",
      "train loss:0.8816224169933423\n",
      "train loss:0.8120541943042112\n",
      "train loss:0.8372660731050978\n",
      "train loss:0.8980607035032064\n",
      "train loss:0.8056138747804966\n",
      "train loss:0.8815531033943316\n",
      "train loss:0.9593677688998318\n",
      "train loss:0.9212875645994294\n",
      "train loss:0.8533900148099738\n",
      "train loss:0.8189073396357972\n",
      "train loss:0.9348916477303528\n",
      "train loss:0.9532948965308133\n",
      "train loss:0.9098035602279534\n",
      "train loss:0.8629423541369938\n",
      "train loss:0.8166668475140832\n",
      "train loss:0.9464887958093651\n",
      "train loss:0.8105514051981817\n",
      "train loss:0.8110355952726941\n",
      "train loss:0.9099657534280563\n",
      "train loss:0.8131245388143367\n",
      "train loss:0.8571419707006863\n",
      "train loss:0.9386489279565621\n",
      "train loss:0.9599010274964158\n",
      "train loss:0.863864531299019\n",
      "train loss:0.8157664395842886\n",
      "train loss:0.8470379796662227\n",
      "train loss:0.9697603619164341\n",
      "train loss:0.7739190595423904\n",
      "train loss:0.9448197828330593\n",
      "train loss:1.0146988780570765\n",
      "train loss:0.8854448968889987\n",
      "train loss:0.9122970340475178\n",
      "train loss:0.9015078774663907\n",
      "train loss:0.9261556519541689\n",
      "train loss:0.805370681097469\n",
      "train loss:0.9571133984466879\n",
      "train loss:0.771923012561812\n",
      "train loss:0.8685240117633044\n",
      "train loss:0.8048360161637247\n",
      "train loss:0.9728583279978834\n",
      "train loss:0.7799213597576987\n",
      "train loss:0.6585654121086633\n",
      "train loss:0.7436848441597823\n",
      "train loss:0.9778046390511124\n",
      "train loss:0.7502557290725584\n",
      "train loss:1.0655810907451218\n",
      "train loss:0.9084991458820783\n",
      "train loss:0.7223396876831463\n",
      "train loss:0.8250075771524092\n",
      "train loss:0.9884879437868953\n",
      "train loss:0.9697426837424465\n",
      "train loss:0.7663680908424224\n",
      "train loss:0.6852073228685708\n",
      "train loss:0.7713929844706725\n",
      "train loss:0.7383243222180563\n",
      "train loss:0.9291979125751426\n",
      "train loss:0.7556243913042903\n",
      "train loss:0.740363460284807\n",
      "train loss:0.8125478002381172\n",
      "train loss:0.8663027260120341\n",
      "train loss:0.794106115344211\n",
      "train loss:0.8875864935190938\n",
      "train loss:0.9295340834883693\n",
      "train loss:0.9105542688002386\n",
      "train loss:0.800525815649594\n",
      "train loss:0.7878916565491204\n",
      "train loss:0.7716146530676565\n",
      "train loss:0.8041844338605745\n",
      "train loss:0.829829261642317\n",
      "train loss:0.8926871729101129\n",
      "train loss:0.8015116391562209\n",
      "train loss:0.7632432166731907\n",
      "train loss:0.9590395466519572\n",
      "train loss:0.8315349679183777\n",
      "train loss:0.9818891599777103\n",
      "train loss:0.9627558308145442\n",
      "train loss:0.9603141804243601\n",
      "train loss:0.7958587796192211\n",
      "train loss:0.8766089971442226\n",
      "train loss:0.8302976296498771\n",
      "train loss:0.9974342303535145\n",
      "train loss:0.7255765987038761\n",
      "train loss:0.9832133136868948\n",
      "train loss:0.8552487226455052\n",
      "train loss:0.825234385164039\n",
      "train loss:0.6719668643034616\n",
      "train loss:0.8519108080641835\n",
      "train loss:0.9292322527706269\n",
      "train loss:0.8701915977021519\n",
      "train loss:0.8912365706383284\n",
      "train loss:0.7669498507675088\n",
      "train loss:0.8068151476320512\n",
      "train loss:0.9072976104968847\n",
      "train loss:0.7766508724251459\n",
      "train loss:0.8519099207127744\n",
      "train loss:0.73147349488424\n",
      "train loss:0.8393774930409628\n",
      "train loss:0.8742169354726521\n",
      "train loss:0.8982253762612796\n",
      "train loss:0.9536531045638352\n",
      "train loss:0.6359825821245554\n",
      "train loss:0.8189723296897087\n",
      "train loss:0.7783497307971173\n",
      "train loss:0.8273676342561143\n",
      "train loss:0.8348540395802204\n",
      "train loss:0.9782935391291093\n",
      "train loss:0.8287290201465376\n",
      "train loss:0.9145130267927258\n",
      "train loss:0.7728558410849629\n",
      "train loss:1.0454198869365063\n",
      "train loss:0.9814451615607003\n",
      "train loss:0.7885186463929824\n",
      "train loss:0.9629135580163293\n",
      "train loss:0.8677954122838797\n",
      "train loss:0.7915881304078753\n",
      "train loss:0.8690186546940162\n",
      "train loss:0.7970665139332709\n",
      "train loss:0.8996684434209989\n",
      "train loss:0.9270598782015597\n",
      "train loss:0.8023602728767054\n",
      "train loss:0.8192254866188615\n",
      "train loss:0.9378393306049098\n",
      "train loss:0.979474560315027\n",
      "train loss:0.8412089355156128\n",
      "train loss:0.8896561726264421\n",
      "train loss:0.8056579122952818\n",
      "train loss:0.9338250935205743\n",
      "train loss:0.9945101890876137\n",
      "train loss:0.8604749954460279\n",
      "train loss:0.762682408508918\n",
      "train loss:0.8625735285282553\n",
      "train loss:0.8946880665273648\n",
      "train loss:0.7009814000855686\n",
      "train loss:0.8513680022177452\n",
      "train loss:0.8634219151082224\n",
      "train loss:0.8060776750535694\n",
      "train loss:0.933965288444969\n",
      "train loss:0.8806292899427617\n",
      "train loss:0.8536079416291783\n",
      "train loss:0.8702128491087754\n",
      "train loss:0.9217848785938878\n",
      "train loss:0.8332015680718043\n",
      "train loss:0.7150812436449613\n",
      "train loss:0.889554578663641\n",
      "train loss:0.9115531293049642\n",
      "train loss:0.9138851032266522\n",
      "train loss:0.8362933935140076\n",
      "train loss:0.8765144924857496\n",
      "train loss:0.9025681103859219\n",
      "train loss:0.8824237060589343\n",
      "train loss:0.7319558755291424\n",
      "train loss:0.8322052902438963\n",
      "train loss:0.842408554491418\n",
      "train loss:0.8582189624602288\n",
      "train loss:0.9041649140825089\n",
      "train loss:0.996767549548147\n",
      "train loss:0.7107207488037501\n",
      "train loss:0.8923072177067126\n",
      "train loss:0.8738664686730684\n",
      "train loss:1.0549215858546843\n",
      "train loss:1.0101810514589193\n",
      "train loss:0.6658770198146535\n",
      "train loss:0.8039766637151723\n",
      "train loss:0.8160160155658981\n",
      "train loss:0.9335812740854432\n",
      "train loss:0.8176431275481919\n",
      "train loss:0.9324583057532558\n",
      "train loss:0.9598486513895239\n",
      "train loss:0.8554041605124731\n",
      "train loss:0.8644152142173729\n",
      "train loss:0.8207566716439588\n",
      "train loss:0.845941055148082\n",
      "train loss:0.7345892592613219\n",
      "train loss:0.9249903509182361\n",
      "train loss:0.9264508054589595\n",
      "train loss:0.831893551568236\n",
      "train loss:0.9456779908581201\n",
      "train loss:0.9266716893471283\n",
      "train loss:0.9843651471437372\n",
      "train loss:1.0169774821259336\n",
      "train loss:0.8160926680870847\n",
      "train loss:0.7885895115247484\n",
      "train loss:0.8438056208731958\n",
      "train loss:0.864494538316317\n",
      "train loss:0.928242848355072\n",
      "train loss:0.8088125128361674\n",
      "train loss:0.5700839353032517\n",
      "train loss:0.7681728386213045\n",
      "train loss:0.7877895990724333\n",
      "train loss:0.9637405203391954\n",
      "train loss:0.8280288639737932\n",
      "train loss:0.880609337083819\n",
      "train loss:0.8655785014226836\n",
      "train loss:1.0197406509585745\n",
      "train loss:0.8695718759414873\n",
      "train loss:0.9465570172030879\n",
      "train loss:0.7818277636222065\n",
      "train loss:0.8521191939063754\n",
      "train loss:0.7727255340966818\n",
      "train loss:0.9532203492554604\n",
      "train loss:0.8766092362945876\n",
      "train loss:0.8553418690912197\n",
      "train loss:0.7391232368987489\n",
      "train loss:0.9243287481474556\n",
      "train loss:0.8872511203449068\n",
      "train loss:0.849141913716153\n",
      "train loss:0.7685392732103995\n",
      "train loss:0.8095225538241485\n",
      "train loss:0.8282635366862943\n",
      "train loss:0.8107677619348166\n",
      "train loss:0.8237625964313464\n",
      "train loss:0.8954674859461749\n",
      "train loss:1.0122608685987953\n",
      "train loss:0.7987933170604795\n",
      "train loss:1.0688793592350232\n",
      "train loss:0.8195647432794674\n",
      "train loss:0.9362283034984903\n",
      "train loss:0.8290123658190629\n",
      "train loss:1.0066927374691752\n",
      "train loss:0.749097039619114\n",
      "train loss:0.7722799079845706\n",
      "train loss:0.9251042618618331\n",
      "train loss:0.6275435730162369\n",
      "train loss:0.7672771875252725\n",
      "train loss:0.8547402618758818\n",
      "train loss:0.7927211135815891\n",
      "train loss:0.8628589868048411\n",
      "train loss:0.9098177422015299\n",
      "train loss:0.7866153655739894\n",
      "train loss:0.9700350924464106\n",
      "train loss:0.924565903163681\n",
      "train loss:0.9238163307585989\n",
      "train loss:0.9430809234602542\n",
      "train loss:0.839963040492224\n",
      "train loss:0.8835990305882064\n",
      "train loss:0.8567280482137559\n",
      "train loss:0.9408834694469274\n",
      "train loss:0.7520616585232637\n",
      "train loss:1.0894675107139242\n",
      "train loss:0.8716420696389197\n",
      "train loss:0.8117277719070753\n",
      "train loss:0.8604979309875948\n",
      "train loss:0.807214771428699\n",
      "train loss:0.9707815148667241\n",
      "train loss:0.7973356268920151\n",
      "train loss:0.9503935489958212\n",
      "train loss:0.8465986192565115\n",
      "train loss:0.9236149895005716\n",
      "train loss:0.7966366228178451\n",
      "train loss:0.8982562289555958\n",
      "train loss:0.8696650591626549\n",
      "train loss:0.8682613977864417\n",
      "train loss:0.887509293634654\n",
      "train loss:0.870764243613106\n",
      "train loss:0.912387009475845\n",
      "train loss:0.9935287460144067\n",
      "train loss:0.8903905014222784\n",
      "train loss:0.9597649460985263\n",
      "train loss:0.9522398366805342\n",
      "train loss:0.8826861848003996\n",
      "train loss:0.8676998186949393\n",
      "train loss:0.9657157266496691\n",
      "train loss:0.9249980475408626\n",
      "train loss:0.8840598112661173\n",
      "train loss:0.9109623561805813\n",
      "train loss:0.9913735192739337\n",
      "train loss:0.7424131443029702\n",
      "train loss:0.7126321862745679\n",
      "train loss:0.8843899041159459\n",
      "train loss:0.8481560919059037\n",
      "train loss:0.8172830160407174\n",
      "train loss:0.7839420562887318\n",
      "train loss:0.8403675891733187\n",
      "train loss:0.8909061923828115\n",
      "train loss:0.6239201585822172\n",
      "train loss:0.927478443556677\n",
      "train loss:0.8901066992082568\n",
      "train loss:0.8067444717246776\n",
      "train loss:1.0550701677686158\n",
      "train loss:0.8406370239003838\n",
      "train loss:0.8587689855823456\n",
      "train loss:0.8829070589177954\n",
      "train loss:0.7884243010748345\n",
      "train loss:0.9029852433715804\n",
      "train loss:0.9471981214444948\n",
      "train loss:0.8145271534310372\n",
      "train loss:0.7888812099885169\n",
      "train loss:0.8148104854189829\n",
      "train loss:0.8229088171477261\n",
      "train loss:0.7925386722306972\n",
      "train loss:0.9786176964942116\n",
      "train loss:0.8399351281418239\n",
      "train loss:1.1206632522963151\n",
      "train loss:0.8600784120326413\n",
      "train loss:0.9130232218003208\n",
      "train loss:0.9604455095256891\n",
      "train loss:0.7864954343957945\n",
      "train loss:0.8649888497495614\n",
      "train loss:0.9811295302335107\n",
      "train loss:0.7174372211329358\n",
      "train loss:0.9980565448007885\n",
      "train loss:0.9614475379703926\n",
      "train loss:0.8492361531701718\n",
      "train loss:0.9619008452152477\n",
      "train loss:0.9195842524558933\n",
      "train loss:0.9851595384603502\n",
      "train loss:0.8735862203462371\n",
      "train loss:0.7207520098319198\n",
      "train loss:0.8383698482343075\n",
      "train loss:0.8712655784210778\n",
      "train loss:0.9916309753691259\n",
      "train loss:0.7582599533132591\n",
      "train loss:0.802156155170151\n",
      "train loss:0.9771939655694233\n",
      "train loss:0.72265217391593\n",
      "train loss:0.9421166047778577\n",
      "train loss:0.718787526276381\n",
      "train loss:0.7842354617661169\n",
      "train loss:0.8953283360134903\n",
      "train loss:0.9297978073395957\n",
      "train loss:0.7378572768141991\n",
      "train loss:0.8897004642519751\n",
      "train loss:0.9339719119413132\n",
      "train loss:0.795156584074113\n",
      "train loss:0.9611805805833222\n",
      "train loss:0.8538289745084606\n",
      "train loss:0.955862864313502\n",
      "train loss:0.8124278890535611\n",
      "train loss:1.000876091761933\n",
      "train loss:0.9330642803616312\n",
      "train loss:0.7233062333760788\n",
      "train loss:0.9620221260319866\n",
      "train loss:0.8128892554951155\n",
      "train loss:0.8244115331256263\n",
      "train loss:0.7356118544513169\n",
      "train loss:0.8792220641387865\n",
      "train loss:0.816471075611856\n",
      "train loss:0.8596713918316665\n",
      "train loss:0.9093166599412011\n",
      "train loss:0.6768684396037798\n",
      "train loss:0.891925606681629\n",
      "train loss:0.9548972482262381\n",
      "train loss:0.9112457669617084\n",
      "train loss:0.7951664566943467\n",
      "train loss:0.9621321692296319\n",
      "train loss:0.9470275537623563\n",
      "train loss:1.038701908519423\n",
      "train loss:0.7770257550297996\n",
      "train loss:0.7700815726088491\n",
      "train loss:1.0096288239068207\n",
      "train loss:0.9274553201747877\n",
      "train loss:0.8638531585692164\n",
      "train loss:0.7729870187044835\n",
      "train loss:0.7593369043452651\n",
      "train loss:1.0599919763577947\n",
      "train loss:0.9713503245067695\n",
      "train loss:0.8155086667433257\n",
      "train loss:0.8785876440159882\n",
      "train loss:0.876897752786457\n",
      "train loss:0.9734107036610965\n",
      "train loss:0.7768738266661624\n",
      "train loss:0.9325034944842447\n",
      "train loss:0.9899787090878663\n",
      "train loss:0.8343091356304533\n",
      "train loss:0.8319575050255256\n",
      "train loss:0.8377772392818345\n",
      "train loss:0.7236660592885295\n",
      "train loss:0.9107825871256646\n",
      "=== epoch:20, train acc:0.998, test acc:0.992 ===\n",
      "train loss:1.0340891700914911\n",
      "train loss:0.9226543430727153\n",
      "train loss:0.8347195630826088\n",
      "train loss:0.9742885304351532\n",
      "train loss:0.8798309690930818\n",
      "train loss:0.8214702015082085\n",
      "train loss:0.7389835741162964\n",
      "train loss:0.827397998592138\n",
      "train loss:0.9045398874956123\n",
      "train loss:0.9165101316901577\n",
      "train loss:0.8553578171870115\n",
      "train loss:0.8177483157986629\n",
      "train loss:0.7543487309231333\n",
      "train loss:0.9296131222963673\n",
      "train loss:0.7752169147588813\n",
      "train loss:0.9409336055880206\n",
      "train loss:0.5610250936280213\n",
      "train loss:1.1144336679860205\n",
      "train loss:1.0205685268355011\n",
      "train loss:0.9182469575656994\n",
      "train loss:0.6994354072700268\n",
      "train loss:0.8902162352944604\n",
      "train loss:0.6556211669788703\n",
      "train loss:0.8984034363985347\n",
      "train loss:0.946243268511231\n",
      "train loss:0.7359803174812969\n",
      "train loss:0.9922716211896224\n",
      "train loss:1.0574212925555815\n",
      "train loss:0.897005365957519\n",
      "train loss:0.6395700913226456\n",
      "train loss:0.9464408075817594\n",
      "train loss:0.6799709814970547\n",
      "train loss:0.9240633744945693\n",
      "train loss:1.0058153849369937\n",
      "train loss:0.8749565367402607\n",
      "train loss:0.6830374204073069\n",
      "train loss:0.966558066801637\n",
      "train loss:0.8899823697090179\n",
      "train loss:0.821569202194955\n",
      "train loss:0.8874324857786725\n",
      "train loss:0.8484353477143008\n",
      "train loss:0.8644149139179624\n",
      "train loss:0.804289046551449\n",
      "train loss:0.9949842897840021\n",
      "train loss:0.871110721724388\n",
      "train loss:0.9774637643975669\n",
      "train loss:0.8645719740378772\n",
      "train loss:0.9329102838565104\n",
      "train loss:0.9243036217979284\n",
      "train loss:0.8101803298505084\n",
      "train loss:0.9620062830585481\n",
      "train loss:0.8483350220249422\n",
      "train loss:0.8784134548569323\n",
      "train loss:0.779095107611935\n",
      "train loss:0.5980880039782084\n",
      "train loss:0.7827038410273203\n",
      "train loss:0.8095261861512039\n",
      "train loss:0.9360076316078783\n",
      "train loss:0.9535077927519632\n",
      "train loss:0.7632095657019484\n",
      "train loss:0.8390355762523066\n",
      "train loss:0.9759482576930459\n",
      "train loss:0.936199913749329\n",
      "train loss:0.9347576862046881\n",
      "train loss:0.7840568191072664\n",
      "train loss:0.8892824234832247\n",
      "train loss:0.7787540565811766\n",
      "train loss:0.6774703701231456\n",
      "train loss:0.8247686837837697\n",
      "train loss:0.8961284020507041\n",
      "train loss:0.6796786309093639\n",
      "train loss:0.9147802154867851\n",
      "train loss:0.788441469645246\n",
      "train loss:0.9952155010563294\n",
      "train loss:0.8363134547924556\n",
      "train loss:0.8642350104364354\n",
      "train loss:0.8994465378277684\n",
      "train loss:0.9757065633068044\n",
      "train loss:0.9224475914841489\n",
      "train loss:0.6844351913206346\n",
      "train loss:0.9240898688094883\n",
      "train loss:0.7953501793146384\n",
      "train loss:0.9048485358141504\n",
      "train loss:0.8935316646565638\n",
      "train loss:0.861997990388723\n",
      "train loss:0.8747962576374603\n",
      "train loss:0.8080257252378458\n",
      "train loss:0.8663362688594056\n",
      "train loss:0.894018508945699\n",
      "train loss:1.0267028489418544\n",
      "train loss:0.8399821745946445\n",
      "train loss:0.827711801796558\n",
      "train loss:0.9397538980493434\n",
      "train loss:0.8466343117044204\n",
      "train loss:0.8850837196232807\n",
      "train loss:0.9708954138485427\n",
      "train loss:0.7308005548906972\n",
      "train loss:0.7568742902121233\n",
      "train loss:0.9009508709155515\n",
      "train loss:0.8609491598468223\n",
      "train loss:0.9796748470932479\n",
      "train loss:0.853693523723704\n",
      "train loss:0.7017943810670785\n",
      "train loss:0.8365806976204861\n",
      "train loss:1.0048311039375548\n",
      "train loss:0.9491715432079255\n",
      "train loss:0.9133651891640036\n",
      "train loss:0.8976402840448426\n",
      "train loss:0.8596913842587877\n",
      "train loss:0.8520313066478912\n",
      "train loss:0.8132220843320895\n",
      "train loss:0.9025110102312217\n",
      "train loss:0.9233920073121412\n",
      "train loss:0.8907015108244262\n",
      "train loss:0.7965105481010386\n",
      "train loss:0.8079872249852413\n",
      "train loss:0.7588924415795999\n",
      "train loss:0.9272580248416376\n",
      "train loss:0.7438191019092713\n",
      "train loss:0.8608101978902769\n",
      "train loss:0.9247947335915638\n",
      "train loss:0.847589583458709\n",
      "train loss:0.9421934215382595\n",
      "train loss:0.8666823587238158\n",
      "train loss:0.8050039751315288\n",
      "train loss:0.7879070738609043\n",
      "train loss:0.7934435971041457\n",
      "train loss:0.9144177270351809\n",
      "train loss:0.9590085082486691\n",
      "train loss:0.8324733847633463\n",
      "train loss:0.8690127465465348\n",
      "train loss:0.9194182665592627\n",
      "train loss:0.7794657484091496\n",
      "train loss:0.8473764258288715\n",
      "train loss:1.0190606652442815\n",
      "train loss:0.7889375508732372\n",
      "train loss:0.8101724169794955\n",
      "train loss:0.7305056701991188\n",
      "train loss:0.9519945901894331\n",
      "train loss:0.8858249375688206\n",
      "train loss:0.8675358319935542\n",
      "train loss:1.0052671222340637\n",
      "train loss:0.8748481322882989\n",
      "train loss:0.8763753368702428\n",
      "train loss:0.8417294379221238\n",
      "train loss:0.8831939502246413\n",
      "train loss:0.8252407066314802\n",
      "train loss:0.9788223931807275\n",
      "train loss:0.8461984819388277\n",
      "train loss:1.0097808958036099\n",
      "train loss:0.952420027028392\n",
      "train loss:1.0250734121381766\n",
      "train loss:0.7711556314314362\n",
      "train loss:0.7935032772261877\n",
      "train loss:0.781120803433953\n",
      "train loss:0.9754833052782584\n",
      "train loss:0.871884263239595\n",
      "train loss:0.9115441754253828\n",
      "train loss:0.8500183145729007\n",
      "train loss:0.7535723329161962\n",
      "train loss:0.8885975347485572\n",
      "train loss:0.9240412562755924\n",
      "train loss:0.723051296866391\n",
      "train loss:0.8451386728122741\n",
      "train loss:0.8622613796992852\n",
      "train loss:0.9240361597031516\n",
      "train loss:0.9699309896982576\n",
      "train loss:0.806272911374468\n",
      "train loss:0.9115993949891441\n",
      "train loss:0.7789643390560401\n",
      "train loss:0.8753366625517632\n",
      "train loss:0.9150470563744064\n",
      "train loss:0.9002745905276635\n",
      "train loss:1.0264743449359177\n",
      "train loss:0.7543008697524293\n",
      "train loss:0.8084237811812146\n",
      "train loss:0.8790855038937174\n",
      "train loss:0.7865504677286785\n",
      "train loss:0.8593697736240041\n",
      "train loss:0.9689352580891182\n",
      "train loss:0.7254209485084749\n",
      "train loss:0.8404581882250228\n",
      "train loss:0.8208943119916792\n",
      "train loss:0.9891151104988843\n",
      "train loss:0.6898314174204322\n",
      "train loss:0.9280123044464049\n",
      "train loss:0.8393114795954969\n",
      "train loss:0.7643605620830918\n",
      "train loss:0.9108790602417787\n",
      "train loss:0.9247865176695501\n",
      "train loss:0.8070520755108995\n",
      "train loss:0.8228120723254232\n",
      "train loss:0.8297296149927985\n",
      "train loss:0.7775504541847473\n",
      "train loss:0.7458182829762195\n",
      "train loss:1.0252211353228853\n",
      "train loss:0.8444663566065195\n",
      "train loss:0.9100334709819627\n",
      "train loss:1.0352625772585307\n",
      "train loss:1.1203113313592388\n",
      "train loss:0.9857493839065609\n",
      "train loss:0.9976327883811092\n",
      "train loss:0.9252589228728896\n",
      "train loss:0.9752184788322397\n",
      "train loss:0.8769556477130658\n",
      "train loss:0.8961059421617762\n",
      "train loss:0.950848183574523\n",
      "train loss:0.9316718002814172\n",
      "train loss:0.7213960815617578\n",
      "train loss:0.736857821603102\n",
      "train loss:0.7845622449900993\n",
      "train loss:0.9879760191146185\n",
      "train loss:0.9043485323737458\n",
      "train loss:0.957649161886334\n",
      "train loss:0.9873322859974892\n",
      "train loss:0.7710744267587724\n",
      "train loss:1.0508450213290828\n",
      "train loss:0.7589508736466775\n",
      "train loss:0.9687893323795298\n",
      "train loss:0.8896575647958607\n",
      "train loss:0.8703530026013463\n",
      "train loss:0.7868942499103935\n",
      "train loss:0.8875383056322877\n",
      "train loss:0.8796098950960548\n",
      "train loss:0.9039917979762785\n",
      "train loss:0.8714937552409273\n",
      "train loss:0.8059120789943863\n",
      "train loss:0.9933451569962461\n",
      "train loss:0.7454613167447386\n",
      "train loss:1.0013671536306166\n",
      "train loss:0.8790881615873455\n",
      "train loss:0.9778562988112042\n",
      "train loss:1.009889725337825\n",
      "train loss:0.8304124421813374\n",
      "train loss:0.7943821149873159\n",
      "train loss:0.9361728997945764\n",
      "train loss:0.8843110598635071\n",
      "train loss:0.9730879245238933\n",
      "train loss:0.9614513332536133\n",
      "train loss:0.7895539704752309\n",
      "train loss:0.7393301637190847\n",
      "train loss:1.0452166019952\n",
      "train loss:0.8619446186530005\n",
      "train loss:0.6225406737027073\n",
      "train loss:0.8427220951995013\n",
      "train loss:0.9443956802349754\n",
      "train loss:0.9419119518746537\n",
      "train loss:0.9915138039656268\n",
      "train loss:0.8607261805678101\n",
      "train loss:0.8291351097782149\n",
      "train loss:0.9692185795957432\n",
      "train loss:0.7690454136614296\n",
      "train loss:0.8771743078004033\n",
      "train loss:0.7681562130983965\n",
      "train loss:1.0737350950580884\n",
      "train loss:0.8782670701411491\n",
      "train loss:0.7732963520324851\n",
      "train loss:0.7460139737990431\n",
      "train loss:0.9145833508241442\n",
      "train loss:1.0939143635829958\n",
      "train loss:1.0927930005978255\n",
      "train loss:0.9268724398821542\n",
      "train loss:0.6686255507309372\n",
      "train loss:0.8899968206185259\n",
      "train loss:0.7953100817142931\n",
      "train loss:0.7188654330896092\n",
      "train loss:0.8155984165169243\n",
      "train loss:0.8643569138775572\n",
      "train loss:0.960521723867959\n",
      "train loss:0.7931237447038645\n",
      "train loss:0.7078857591775534\n",
      "train loss:0.8823569478246014\n",
      "train loss:0.9765623422737083\n",
      "train loss:0.818597119676474\n",
      "train loss:0.8573373420159863\n",
      "train loss:0.7925456297456124\n",
      "train loss:0.8548994356929288\n",
      "train loss:0.9883927721895218\n",
      "train loss:0.8805041589541197\n",
      "train loss:0.6704221167310839\n",
      "train loss:0.824706919100491\n",
      "train loss:0.8219416581659809\n",
      "train loss:0.7302736375661384\n",
      "train loss:0.7877121389620683\n",
      "train loss:0.8706355307737919\n",
      "train loss:0.9861566946440962\n",
      "train loss:0.7289911619537732\n",
      "train loss:0.7629448488904\n",
      "train loss:0.745379354005157\n",
      "train loss:0.9104868636789629\n",
      "train loss:0.9960861736383987\n",
      "train loss:0.7733138966200347\n",
      "train loss:0.8031609301698363\n",
      "train loss:0.9607239502239048\n",
      "train loss:0.9021873979323451\n",
      "train loss:0.8141720431996973\n",
      "train loss:0.7968312888735032\n",
      "train loss:0.9145565846129794\n",
      "train loss:0.9807693542940717\n",
      "train loss:0.6891657354409492\n",
      "train loss:0.7857745169110453\n",
      "train loss:0.9725957135660365\n",
      "train loss:0.8100282256422133\n",
      "train loss:0.7881435416200631\n",
      "train loss:0.7607725119188454\n",
      "train loss:0.8341012473927853\n",
      "train loss:1.0419916830948486\n",
      "train loss:0.8396244438274212\n",
      "train loss:0.7836357775682632\n",
      "train loss:0.8120382457448482\n",
      "train loss:0.7856781201454207\n",
      "train loss:0.8413915634917519\n",
      "train loss:0.7918627112821816\n",
      "train loss:0.8447001754052001\n",
      "train loss:1.139458589951876\n",
      "train loss:0.9036267660579422\n",
      "train loss:0.8818105538509458\n",
      "train loss:0.9236298704909284\n",
      "train loss:0.8745424131411785\n",
      "train loss:0.6944795620864275\n",
      "train loss:0.9855175332127432\n",
      "train loss:0.9125928667617214\n",
      "train loss:0.9831720404308721\n",
      "train loss:0.8243160894478472\n",
      "train loss:0.982554353945731\n",
      "train loss:0.7218285835475037\n",
      "train loss:1.102789148337573\n",
      "train loss:0.8555022396124756\n",
      "train loss:0.7561250135548722\n",
      "train loss:0.7309002235698341\n",
      "train loss:0.8513841137758998\n",
      "train loss:0.8343857676486327\n",
      "train loss:0.8712714468713608\n",
      "train loss:0.8352196324668529\n",
      "train loss:0.7505297973533517\n",
      "train loss:0.6803626086554613\n",
      "train loss:0.8434097730219389\n",
      "train loss:0.939324357282174\n",
      "train loss:0.8418471471045605\n",
      "train loss:0.7530691891039188\n",
      "train loss:0.8431981008572559\n",
      "train loss:0.8299413273365321\n",
      "train loss:0.9056306843440131\n",
      "train loss:0.8301155004151148\n",
      "train loss:0.7788557586601247\n",
      "train loss:0.8177706267712064\n",
      "train loss:1.0248452532831012\n",
      "train loss:0.807688694030023\n",
      "train loss:0.8021334634278152\n",
      "train loss:0.6749556818796304\n",
      "train loss:0.7570733683880516\n",
      "train loss:0.9636789150913146\n",
      "train loss:0.9256669117727959\n",
      "train loss:0.8496217186647776\n",
      "train loss:0.6245930688885006\n",
      "train loss:0.8173825585745729\n",
      "train loss:0.7442626433203139\n",
      "train loss:0.7698888883928546\n",
      "train loss:0.9295213515773864\n",
      "train loss:0.6350906665149781\n",
      "train loss:0.7457481977589252\n",
      "train loss:1.0178582172882213\n",
      "train loss:0.8243587361170196\n",
      "train loss:0.8122519346268452\n",
      "train loss:0.6249691424931946\n",
      "train loss:0.9636972293234832\n",
      "train loss:0.8007815798221647\n",
      "train loss:0.9678679383244463\n",
      "train loss:0.8417587996239722\n",
      "train loss:0.8069748154016115\n",
      "train loss:0.8739276061560305\n",
      "train loss:0.9006412040480335\n",
      "train loss:0.7924315500259642\n",
      "train loss:0.9547918769773481\n",
      "train loss:0.7178033181262855\n",
      "train loss:0.9409397434927322\n",
      "train loss:0.9129836499662259\n",
      "train loss:0.669954059287852\n",
      "train loss:0.8113927150844796\n",
      "train loss:0.995357827816695\n",
      "train loss:0.7823055377711112\n",
      "train loss:0.7298400824257866\n",
      "train loss:0.709660348048069\n",
      "train loss:0.8892588452159693\n",
      "train loss:0.9043707549290096\n",
      "train loss:0.8414503486337505\n",
      "train loss:0.8649202275063133\n",
      "train loss:0.922599231440847\n",
      "train loss:0.8877060132492776\n",
      "train loss:0.8070829740037169\n",
      "train loss:0.8080000203482165\n",
      "train loss:0.9300898037158286\n",
      "train loss:1.0086021194232133\n",
      "train loss:0.8320844976260059\n",
      "train loss:0.9938942462350419\n",
      "train loss:0.7892241696163044\n",
      "train loss:0.7784708394585\n",
      "train loss:0.8213466962832132\n",
      "train loss:0.7743471594216832\n",
      "train loss:0.8528175711044871\n",
      "train loss:0.8699067842357558\n",
      "train loss:0.8731538669619505\n",
      "train loss:0.8779490685083909\n",
      "train loss:0.8707578609269717\n",
      "train loss:0.8302456846965225\n",
      "train loss:0.8334032400391507\n",
      "train loss:0.9642258091712533\n",
      "train loss:0.8951875703036544\n",
      "train loss:0.9337242452830837\n",
      "train loss:0.8173828346001801\n",
      "train loss:0.812743215040597\n",
      "train loss:0.7194717554473066\n",
      "train loss:0.7959795412355462\n",
      "train loss:0.8238214324543739\n",
      "train loss:0.9350270437370075\n",
      "train loss:0.7991744424991561\n",
      "train loss:0.9161605818399733\n",
      "train loss:0.8791008293525477\n",
      "train loss:0.9565067372867372\n",
      "train loss:0.8966801908570177\n",
      "train loss:0.975335594505768\n",
      "train loss:0.8365121356626077\n",
      "train loss:0.8559340897903018\n",
      "train loss:0.8782976634995145\n",
      "train loss:0.8630168593894139\n",
      "train loss:0.865110538242031\n",
      "train loss:0.8306386045204558\n",
      "train loss:0.7077904530172883\n",
      "train loss:0.7749431152332723\n",
      "train loss:0.9778635224128511\n",
      "train loss:0.8401840831797422\n",
      "train loss:0.845540143471706\n",
      "train loss:0.9204960504966259\n",
      "train loss:0.7085367955414215\n",
      "train loss:0.8464404821706758\n",
      "train loss:0.9078465751124776\n",
      "train loss:0.7996915380934451\n",
      "train loss:0.9821343973041858\n",
      "train loss:0.751697146110932\n",
      "train loss:0.8016575057094183\n",
      "train loss:0.8325046967690761\n",
      "train loss:0.8610491115643688\n",
      "train loss:0.7761766359755685\n",
      "train loss:0.8514286376489811\n",
      "train loss:0.7633455552152365\n",
      "train loss:0.9006158113229666\n",
      "train loss:0.7835012381161802\n",
      "train loss:0.8529853481478011\n",
      "train loss:0.9020478675174303\n",
      "train loss:0.9170272579778938\n",
      "train loss:0.9015431408060276\n",
      "train loss:0.9176711625186661\n",
      "train loss:0.947633961629172\n",
      "train loss:0.8291367885715134\n",
      "train loss:0.7841037484457164\n",
      "train loss:0.8212783401623579\n",
      "train loss:0.8765858971491163\n",
      "train loss:0.8471212091093656\n",
      "train loss:1.1280372050339194\n",
      "train loss:0.9192039342125264\n",
      "train loss:1.046022551738208\n",
      "train loss:0.9251924426673841\n",
      "train loss:0.8857908251661897\n",
      "train loss:0.9258269718745875\n",
      "train loss:0.7967933046619399\n",
      "train loss:0.8654771323289843\n",
      "train loss:0.8639105651595984\n",
      "train loss:0.8215662864731865\n",
      "train loss:0.9439327224053784\n",
      "train loss:0.8623428768092561\n",
      "train loss:0.9040088484116195\n",
      "train loss:0.9168733868168992\n",
      "train loss:0.9625425705438191\n",
      "train loss:0.9524929027882658\n",
      "train loss:0.7686115098181887\n",
      "train loss:0.8149860590410221\n",
      "train loss:0.8086508722451984\n",
      "train loss:0.8677827417299971\n",
      "train loss:0.8561650519445639\n",
      "train loss:0.9490307599382309\n",
      "train loss:0.9107690210898572\n",
      "train loss:0.7069791409556249\n",
      "train loss:0.8365713185595927\n",
      "train loss:0.8218553731465487\n",
      "train loss:0.8514595183367866\n",
      "train loss:0.9315525086311454\n",
      "train loss:0.7900746032688757\n",
      "train loss:0.931489947828812\n",
      "train loss:0.9063625578668413\n",
      "train loss:1.0533372771084326\n",
      "train loss:0.8852620038914728\n",
      "train loss:0.7467667308860706\n",
      "train loss:0.8780214449985894\n",
      "train loss:0.9109109075094018\n",
      "train loss:0.9912700433847798\n",
      "train loss:0.7705312993072695\n",
      "train loss:0.8125963585150313\n",
      "train loss:0.6844350481209056\n",
      "train loss:0.863092136379163\n",
      "train loss:0.9552301620261398\n",
      "train loss:0.7230044149037408\n",
      "train loss:0.9128249704257752\n",
      "train loss:0.9173639808726928\n",
      "train loss:0.7518306000697114\n",
      "train loss:0.8332844734031052\n",
      "train loss:0.8265750659857596\n",
      "train loss:0.8694353834009467\n",
      "train loss:0.8618057206293153\n",
      "train loss:0.9481107555584692\n",
      "train loss:0.9079962533188349\n",
      "train loss:0.819238363637755\n",
      "train loss:0.9820915242280261\n",
      "train loss:0.9672709218631411\n",
      "train loss:0.811327736755581\n",
      "train loss:0.8496030599598279\n",
      "train loss:0.9227121170733767\n",
      "train loss:0.9467405233266656\n",
      "train loss:0.9058469699089499\n",
      "train loss:0.859196777830383\n",
      "train loss:0.7380836623013773\n",
      "train loss:0.9093521628976687\n",
      "train loss:0.9389216996841518\n",
      "train loss:0.8232061363098043\n",
      "train loss:0.9283671411214329\n",
      "train loss:0.9548724738659334\n",
      "train loss:0.9701025097557041\n",
      "train loss:0.9753050530856195\n",
      "train loss:0.903632235146295\n",
      "train loss:0.9782964640739881\n",
      "train loss:0.7847253536922536\n",
      "train loss:0.7946388121134039\n",
      "train loss:0.8461612513386184\n",
      "train loss:1.0263151245140791\n",
      "train loss:0.830310334366395\n",
      "train loss:0.9433461557150582\n",
      "train loss:0.7873188212698677\n",
      "train loss:0.968980281984206\n",
      "train loss:0.7985149223083386\n",
      "train loss:0.6191648052630075\n",
      "train loss:0.762075192965913\n",
      "train loss:1.009186678284176\n",
      "train loss:0.8596586738168719\n",
      "train loss:0.925165141529315\n",
      "train loss:0.7908028544204351\n",
      "train loss:0.9500661367070223\n",
      "train loss:0.8556897537318823\n",
      "train loss:0.9835169481642181\n",
      "train loss:0.8732232584619178\n",
      "train loss:0.9237072433387883\n",
      "train loss:0.841723023563798\n",
      "train loss:0.890882156339633\n",
      "train loss:0.8279870088589166\n",
      "train loss:0.981053864503646\n",
      "train loss:0.6962690151855148\n",
      "train loss:0.8739977134469079\n",
      "train loss:0.8160436064425254\n",
      "train loss:0.9069268143313929\n",
      "train loss:0.8838142660856296\n",
      "train loss:0.8962944787570283\n",
      "train loss:0.8721136332326597\n",
      "train loss:0.7615437750863998\n",
      "train loss:0.862409691907802\n",
      "train loss:0.8032720199283356\n",
      "train loss:0.8622969145973576\n",
      "train loss:0.8984438835410984\n",
      "train loss:0.8195708765881149\n",
      "train loss:0.8105188500503442\n",
      "train loss:0.8113924507851137\n",
      "train loss:1.0077434139493722\n",
      "train loss:0.8920441079233445\n",
      "train loss:0.7653571005293329\n",
      "train loss:0.7006448763575487\n",
      "train loss:0.7235078730079804\n",
      "train loss:0.8712265323284104\n",
      "train loss:0.7981650865649484\n",
      "train loss:0.9753510740307755\n",
      "train loss:0.9187388881367277\n",
      "train loss:0.6490249761870855\n",
      "train loss:0.8376091621695515\n",
      "train loss:0.7599685472701931\n",
      "train loss:0.8422422863607265\n",
      "train loss:0.7474355380164249\n",
      "train loss:0.9224636825261371\n",
      "train loss:0.7497998867603667\n",
      "train loss:0.8463133226783154\n",
      "train loss:1.018270361110569\n",
      "train loss:0.9555414588324892\n",
      "train loss:0.7805539808913331\n",
      "train loss:1.045150292760489\n",
      "train loss:0.922507644527202\n",
      "train loss:0.8948715039181242\n",
      "train loss:0.7476794487093531\n",
      "train loss:0.8318957343863126\n",
      "train loss:0.8561308316510342\n",
      "train loss:1.0365232911796962\n",
      "train loss:0.8728452879160647\n",
      "train loss:0.9287928749915073\n",
      "train loss:0.9276715350434592\n",
      "train loss:0.9662884295343166\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.9932\n",
      "Saved Network Parameters!\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from deep_convnet import DeepConvNet\n",
    "from common.trainer import Trainer\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "network = DeepConvNet()  \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=20, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr':0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# パラメータの保存\n",
    "network.save_params(\"deep_convnet_params.pkl\")\n",
    "print(\"Saved Network Parameters!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d7b278",
   "metadata": {},
   "source": [
    "# 結果まとめ\n",
    "\n",
    "**final accracy: 99.32%**  \n",
    "**running time: 89m 16.1s**  \n",
    "\n",
    "epoch7で達成されている。\n",
    "\n",
    "=== epoch:1, train acc:0.099, test acc:0.104 ===\n",
    "=== epoch:2, train acc:0.974, test acc:0.972 ===\n",
    "=== epoch:3, train acc:0.985, test acc:0.981 ===\n",
    "=== epoch:4, train acc:0.989, test acc:0.987 ===\n",
    "=== epoch:5, train acc:0.991, test acc:0.988 ===\n",
    "=== epoch:6, train acc:0.991, test acc:0.989 ===\n",
    "=== epoch:7, train acc:0.992, test acc:0.99 ===\n",
    "=== epoch:8, train acc:0.991, test acc:0.986 ===\n",
    "=== epoch:9, train acc:0.994, test acc:0.984 ===\n",
    "=== epoch:10, train acc:0.993, test acc:0.985 ===\n",
    "=== epoch:11, train acc:0.997, test acc:0.989 ===\n",
    "=== epoch:12, train acc:0.993, test acc:0.991 ===\n",
    "=== epoch:13, train acc:0.996, test acc:0.987 ===\n",
    "=== epoch:14, train acc:0.995, test acc:0.988 ===\n",
    "=== epoch:15, train acc:0.995, test acc:0.994 ===\n",
    "=== epoch:16, train acc:0.997, test acc:0.986 ===\n",
    "=== epoch:17, train acc:0.995, test acc:0.99 ===\n",
    "=== epoch:18, train acc:0.999, test acc:0.991 ===\n",
    "=== epoch:19, train acc:0.997, test acc:0.991 ===\n",
    "=== epoch:20, train acc:0.998, test acc:0.992 ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19a9fb14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# グラフの描画\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(20) #max epochs = 20\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=1)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=1)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylim(0, 21.0)\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763ab7c7",
   "metadata": {},
   "source": [
    "> MNISTデータセットに対しては、層をそこまで深くせずに（現時点では）最高精度の結果が得られています。  \n",
    "これは、手書き数字という比較的単純な問題に対しては、ネットワークの表現力をそこまで高める必要がないからだと考えられます。  \n",
    "そのため、層を深くすることの恩恵が少ないと言えるでしょう。  \n",
    "この後に紹介する大規模な一般物体認識では、問題が複雑になるため、層を深くすることが認識精度の向上に大いに貢献することが分かります。\n",
    "\n",
    "p.245のカラス"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572d9135",
   "metadata": {},
   "source": [
    "# さらに認識制度を高めるには\n",
    "rankingやtrendingを追うサイト:  \n",
    "Paper with code -> Hagging face. \n",
    "\n",
    "* アンサンブル学習(p.197)：複数の異なるモデルを組み合わせて、より高精度な予測を行う手法（過学習を回避）\n",
    "* 学習係数の減衰（learning rate decay）：初期は大きな学習率で素早く最適解に近づく→学習が進むにつれて学習率を減衰させ、細かい調整を行う\n",
    "* Data Augmentation（データ拡張）：既存の学習データに変換を加えて、実質的にデータ量を増やす手法\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8fca66",
   "metadata": {},
   "source": [
    "# 層を深くするモチベーション\n",
    "* 重要性：（経験的に）層を深くすることに比例して、認識性能も向上している\n",
    "* 利点（CNNを例に）\n",
    "    * 層を深くしたネットワークは、層を深くしなかった場合に比べて、より少ないパラメータで同レベル（もしくはそれ以上）の表現力を達成できる\n",
    "        * 例えば、5×5の畳み込み演算1回 VS 3×3の畳み込み演算を2回 の比較では、パラメータ数（フィルターの要素数の合計）は25（5×5） VS 18（2×3×3）\n",
    "        * 小さなフィルターでも受容野をカバーできる\n",
    "    * 層を重ねることで、畳み込み層の間にReLUなどの活性化関数を挟むことができ、ネットワークの表現力がさらに向上する\n",
    "    * ネットワークを深くすれば、学習すべき問題を階層的に分解することができる\n",
    "        * 層を深くすることで階層的に情報を渡していくことができる\n",
    "        * 各層が学習すべき問題は、より単純な問題として取り組むことができる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c0a2ce",
   "metadata": {},
   "source": [
    "# ディープラーニングの小歴史\n",
    "## ImageNet\n",
    "* データセットのこと\n",
    "* ILSVRCは2017年で終了（精度向上の余地がなくなったため）\n",
    "* 2012年のAlexnet登場前までは、SIFT（Scale-Invariant Feature Transform）やHOG（Histogram of Oriented Gradients）などの手工芸特徴量（hand-crafted features）を用いた手法が中心\n",
    "## VGG\n",
    "* 基本的なCNN\n",
    "* 3×3の小さなフィルターによる畳み込み層を連続して行う\n",
    "## GoogLeNet\n",
    "* インセプション構造（図8-11）：サイズの異なるフィルター（とプーリング）を複数適用しその結果を結合する\n",
    "## ResNet (Residual Network: 残差ネットワーク)\n",
    "* \"スキップ構造\"はTransformerでも応用されている。\n",
    "\n",
    "# GPUによる高速化\n",
    "* GPUは元々、グラフィックのための専用のボードとして利用されてきた\n",
    "* 並列的な数値演算を高速に行うことができるため、汎用的な数値計算にも活用\n",
    "\n",
    "# 分散学習\n",
    "* 大量のデータや計算処理を複数のマシンやプロセッサに分散して並列処理する手法\n",
    "* アンサンブル学習(p.198)は、複数の学習モデルを組み合わせて予測精度を向上させる手法\n",
    "\n",
    "# 演算精度のビット削減\n",
    "**データのビット数はできるだけ小さい方がいい**\n",
    "* メモリ容量：大量の重みパラメータや中間データをメモリに収めらるか\n",
    "* バス帯域（CPU・GPUとメモリの間の道を流れるデータ量の上限値）：GPU（もしくはCPU）のバスを流れるデータが増加に耐えうるか\n",
    "**経験的にディープラーニングのロバスト性（頑健性）がわかっている**\n",
    "* ディープラーニングでは、数値精度（何ビットのデータで数値を表現するかということ）のビット数をそこまで必要としないことがわかっている\n",
    "* ロバスト性のおかげで、ネットワークを流れるデータを“劣化”させても、出力結果に与える影響は少ない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75728eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caluculate accuracy (float64) ... \n",
      "0.9932\n",
      "caluculate accuracy (float16) ... \n",
      "0.9932\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from deep_convnet import DeepConvNet\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "network = DeepConvNet()\n",
    "network.load_params(\"deep_convnet_params.pkl\")\n",
    "\n",
    "sampled = 10000 # 高速化のため\n",
    "x_test = x_test[:sampled]\n",
    "t_test = t_test[:sampled]\n",
    "\n",
    "print(\"caluculate accuracy (float64) ... \")\n",
    "print(network.accuracy(x_test, t_test))\n",
    "\n",
    "# float16に型変換\n",
    "x_test = x_test.astype(np.float16)\n",
    "for param in network.params.values():\n",
    "    param[...] = param.astype(np.float16)\n",
    "\n",
    "print(\"caluculate accuracy (float16) ... \")\n",
    "print(network.accuracy(x_test, t_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b17290",
   "metadata": {},
   "source": [
    "15s 14s\n",
    "⇧ float16でもaccuracyが維持されている。\n",
    "\n",
    "BitNet b1.58まで到達（2024年）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ba2eda",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.13.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
